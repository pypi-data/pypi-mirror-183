Metadata-Version: 2.1
Name: wagtail-robots
Version: 0.4.0
Summary: Robots.txt exclusion for Wagtail, complementing Sitemaps.
Home-page: https://github.com/adrian-turjak/wagtail-robots/
Author: Adrian Turjak
Author-email: adriant@catalyst.net.nz
Classifier: Development Status :: 3 - Alpha
Classifier: Environment :: Web Environment
Classifier: Framework :: Django
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: BSD License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python
Classifier: Topic :: Internet :: WWW/HTTP :: Dynamic Content
Classifier: Topic :: Software Development
Classifier: Topic :: Software Development :: Libraries :: Application Frameworks
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Framework :: Django
Classifier: Framework :: Django :: 3.2
Classifier: Framework :: Django :: 4.0
Classifier: Framework :: Django :: 4.1
Classifier: Framework :: Wagtail :: 2
Classifier: Framework :: Wagtail :: 3
Classifier: Framework :: Wagtail :: 4
License-File: LICENSE.txt

Wagtail Robots
==============

This is a basic Django application for Wagtail to manage robots.txt files
following the `robots exclusion protocol`_, complementing the Django_
`Sitemap contrib app`_.

This started as a fork of `Django Robots`_ but because of the differences
between the Django Admin and the Wagtail Admin, and other project requirements
git history has not been retained.

For installation and configuration instructions,
`check out the docs`_.

.. _robots exclusion protocol: http://en.wikipedia.org/wiki/Robots_exclusion_standard
.. _Django: http://www.djangoproject.com/
.. _Sitemap contrib app: http://docs.djangoproject.com/en/dev/ref/contrib/sitemaps/
.. _Django Robots: https://github.com/jazzband/django-robots
.. _check out the docs: https://wagtail-robots.readthedocs.io
