# coding: utf-8

"""
    Onepanel

    Onepanel API  # noqa: E501

    The version of the OpenAPI document: 1.0.2
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from onepanel.core.api.configuration import Configuration


class InferenceServicePredictor(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'name': 'str',
        'runtime_version': 'str',
        'storage_uri': 'str',
        'node_selector': 'str',
        'min_cpu': 'str',
        'min_memory': 'str',
        'max_cpu': 'str',
        'max_memory': 'str'
    }

    attribute_map = {
        'name': 'name',
        'runtime_version': 'runtimeVersion',
        'storage_uri': 'storageUri',
        'node_selector': 'nodeSelector',
        'min_cpu': 'minCpu',
        'min_memory': 'minMemory',
        'max_cpu': 'maxCpu',
        'max_memory': 'maxMemory'
    }

    def __init__(self, name=None, runtime_version=None, storage_uri=None, node_selector=None, min_cpu=None, min_memory=None, max_cpu=None, max_memory=None, local_vars_configuration=None):  # noqa: E501
        """InferenceServicePredictor - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._name = None
        self._runtime_version = None
        self._storage_uri = None
        self._node_selector = None
        self._min_cpu = None
        self._min_memory = None
        self._max_cpu = None
        self._max_memory = None
        self.discriminator = None

        if name is not None:
            self.name = name
        if runtime_version is not None:
            self.runtime_version = runtime_version
        if storage_uri is not None:
            self.storage_uri = storage_uri
        if node_selector is not None:
            self.node_selector = node_selector
        if min_cpu is not None:
            self.min_cpu = min_cpu
        if min_memory is not None:
            self.min_memory = min_memory
        if max_cpu is not None:
            self.max_cpu = max_cpu
        if max_memory is not None:
            self.max_memory = max_memory

    @property
    def name(self):
        """Gets the name of this InferenceServicePredictor.  # noqa: E501


        :return: The name of this InferenceServicePredictor.  # noqa: E501
        :rtype: str
        """
        return self._name

    @name.setter
    def name(self, name):
        """Sets the name of this InferenceServicePredictor.


        :param name: The name of this InferenceServicePredictor.  # noqa: E501
        :type: str
        """

        self._name = name

    @property
    def runtime_version(self):
        """Gets the runtime_version of this InferenceServicePredictor.  # noqa: E501


        :return: The runtime_version of this InferenceServicePredictor.  # noqa: E501
        :rtype: str
        """
        return self._runtime_version

    @runtime_version.setter
    def runtime_version(self, runtime_version):
        """Sets the runtime_version of this InferenceServicePredictor.


        :param runtime_version: The runtime_version of this InferenceServicePredictor.  # noqa: E501
        :type: str
        """

        self._runtime_version = runtime_version

    @property
    def storage_uri(self):
        """Gets the storage_uri of this InferenceServicePredictor.  # noqa: E501


        :return: The storage_uri of this InferenceServicePredictor.  # noqa: E501
        :rtype: str
        """
        return self._storage_uri

    @storage_uri.setter
    def storage_uri(self, storage_uri):
        """Sets the storage_uri of this InferenceServicePredictor.


        :param storage_uri: The storage_uri of this InferenceServicePredictor.  # noqa: E501
        :type: str
        """

        self._storage_uri = storage_uri

    @property
    def node_selector(self):
        """Gets the node_selector of this InferenceServicePredictor.  # noqa: E501


        :return: The node_selector of this InferenceServicePredictor.  # noqa: E501
        :rtype: str
        """
        return self._node_selector

    @node_selector.setter
    def node_selector(self, node_selector):
        """Sets the node_selector of this InferenceServicePredictor.


        :param node_selector: The node_selector of this InferenceServicePredictor.  # noqa: E501
        :type: str
        """

        self._node_selector = node_selector

    @property
    def min_cpu(self):
        """Gets the min_cpu of this InferenceServicePredictor.  # noqa: E501


        :return: The min_cpu of this InferenceServicePredictor.  # noqa: E501
        :rtype: str
        """
        return self._min_cpu

    @min_cpu.setter
    def min_cpu(self, min_cpu):
        """Sets the min_cpu of this InferenceServicePredictor.


        :param min_cpu: The min_cpu of this InferenceServicePredictor.  # noqa: E501
        :type: str
        """

        self._min_cpu = min_cpu

    @property
    def min_memory(self):
        """Gets the min_memory of this InferenceServicePredictor.  # noqa: E501


        :return: The min_memory of this InferenceServicePredictor.  # noqa: E501
        :rtype: str
        """
        return self._min_memory

    @min_memory.setter
    def min_memory(self, min_memory):
        """Sets the min_memory of this InferenceServicePredictor.


        :param min_memory: The min_memory of this InferenceServicePredictor.  # noqa: E501
        :type: str
        """

        self._min_memory = min_memory

    @property
    def max_cpu(self):
        """Gets the max_cpu of this InferenceServicePredictor.  # noqa: E501


        :return: The max_cpu of this InferenceServicePredictor.  # noqa: E501
        :rtype: str
        """
        return self._max_cpu

    @max_cpu.setter
    def max_cpu(self, max_cpu):
        """Sets the max_cpu of this InferenceServicePredictor.


        :param max_cpu: The max_cpu of this InferenceServicePredictor.  # noqa: E501
        :type: str
        """

        self._max_cpu = max_cpu

    @property
    def max_memory(self):
        """Gets the max_memory of this InferenceServicePredictor.  # noqa: E501


        :return: The max_memory of this InferenceServicePredictor.  # noqa: E501
        :rtype: str
        """
        return self._max_memory

    @max_memory.setter
    def max_memory(self, max_memory):
        """Sets the max_memory of this InferenceServicePredictor.


        :param max_memory: The max_memory of this InferenceServicePredictor.  # noqa: E501
        :type: str
        """

        self._max_memory = max_memory

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, InferenceServicePredictor):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, InferenceServicePredictor):
            return True

        return self.to_dict() != other.to_dict()
