<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>redvox.api900.timesync.api900_timesync API documentation</title>
<meta name="description" content="Modules for extracting time synchronization statistics for API 900 data.
Also includes functions for correcting time arrays." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>redvox.api900.timesync.api900_timesync</code></h1>
</header>
<section id="section-intro">
<p>Modules for extracting time synchronization statistics for API 900 data.
Also includes functions for correcting time arrays.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Modules for extracting time synchronization statistics for API 900 data.
Also includes functions for correcting time arrays.
&#34;&#34;&#34;

from typing import List, Optional, Tuple

# noinspection Mypy
import numpy as np

from redvox.api900.reader import WrappedRedvoxPacket
from redvox.api900.reader_utils import empty_array
from redvox.api900.timesync import tri_message_stats
from redvox.common import date_time_utils as dt
from redvox.common import file_statistics as fh
from redvox.common import stats_helper


class TimeSyncData:
    &#34;&#34;&#34;
    Stores latencies, revised start times, time sync server offsets, and difference in adjusted machine time and
    acquisition server time
    Note that inputs to this must be continuous data; any change in sensor mach_time_zero or sample_rate
    requires a new TimeSyncData object
    ALL times in microseconds
    properties:
        rev_start_times: revised machine start times (per packet)
        server_acquisition_times: time packet arrived at server (per packet)
        latencies: latencies (per packet)
        best_latency: the lowest latency among packets
        best_latency_index: index in latencies array that contains the best latency
        latency_stats: StatsContainer for latencies
        offsets: list of calculated offsets (per packet)
        best_offset: the offset that is paired with the lowest latency
        offset_stats: StatsContainer for offsets
        num_packets: the number of packets being analyzed
        sample_rate_hz: the sample rate in Hz of all packets
        packet_duration: the duration of all packets
        mach_time_zero: the start time of the app in machine time
        num_tri_messages: number of tri-message exchanges (per packet)
        tri_message_coeffs: list of 6-tuples containing the tri-message exchange coefficients (up to 1 tuple per packet)
        best_tri_msg_indices: the index of the best tri-message for each of the tri_message_coeffs tuples
        acquire_travel_time: calculated time it took packet to reach server (up to 1 per packet)
        bad_packets: indices of packets with an undefined or 0 latency
    &#34;&#34;&#34;

    def __init__(self, wrapped_packets: List[WrappedRedvoxPacket] = None):
        &#34;&#34;&#34;
        Initialize properties, assume all packets share the same sample rate and are continuous
        :param wrapped_packets: list of data packets
        &#34;&#34;&#34;
        self.latency_stats: stats_helper.StatsContainer = stats_helper.StatsContainer(&#34;latency&#34;)
        self.offset_stats: stats_helper.StatsContainer = stats_helper.StatsContainer(&#34;offset&#34;)
        if wrapped_packets is None or len(wrapped_packets) &lt; 1:
            self.rev_start_times: np.ndarray = np.ndarray((0, 0))
            self.server_acquisition_times: np.ndarray = np.ndarray((0, 0))
            self.latencies: np.ndarray = np.ndarray((0, 0))
            self.best_latency: Optional[float] = None
            self.best_latency_index: Optional[int] = None
            self.offsets: np.ndarray = np.ndarray((0, 0))
            self.best_offset: float = 0.0
            self.num_packets: int = 0
            self.sample_rate_hz: Optional[float] = None
            self.packet_duration: int = 0
            self.mach_time_zero: Optional[float] = None
            self.num_tri_messages: np.ndarray = np.ndarray((0, 0))
            self.tri_message_coeffs: List[Tuple] = []
            self.best_tri_msg_indices: List[int] = []
            self.acquire_travel_time: np.ndarray = np.ndarray((0, 0))
            self.bad_packets: List[int] = []
        else:
            self.get_time_sync_data(wrapped_packets)

    def get_time_sync_data(self, wrapped_packets: List[WrappedRedvoxPacket]):
        &#34;&#34;&#34;
        Sets the time statistics between machine, time server, and acquisition server for the packets given.
        :param wrapped_packets: wrapped packets with same sample rate
        &#34;&#34;&#34;
        self.server_acquisition_times = np.zeros(len(wrapped_packets))  # array of server acquisition times
        self.rev_start_times = np.zeros(len(wrapped_packets))   # array of app start times
        self.num_tri_messages = np.zeros(len(wrapped_packets))  # number of tri-message exchanges per packet
        self.latencies = np.zeros(len(wrapped_packets))  # array of minimum latencies
        self.offsets = np.zeros(len(wrapped_packets))  # array of offset applied to machine time to get sync time
        self.num_packets = len(wrapped_packets)  # number of packets in list
        self.tri_message_coeffs = []    # a list of tri-message coefficients
        self.best_tri_msg_indices = []  # a list of the best latency index in each set of tri-message coefficients
        self.bad_packets = []   # list of packets that contain invalid data
        sample_rates = np.zeros(len(wrapped_packets))       # list of sample rates, should all be the same
        mach_time_zeros = np.zeros(len(wrapped_packets))    # list of mach time zeros, should all the be same

        # get the server acquisition time, app start time, and tri message stats
        for i, wrapped_packet in enumerate(wrapped_packets):
            # pass the mach_time_zero and sample_rate into arrays
            sample_rates[i] = wrapped_packet.microphone_sensor().sample_rate_hz()
            mach_time_zeros[i] = wrapped_packet.mach_time_zero()
            self.server_acquisition_times[i] = wrapped_packet.server_timestamp_epoch_microseconds_utc()
            self.rev_start_times[i] = wrapped_packet.app_file_start_timestamp_epoch_microseconds_utc()
            self._compute_tri_message_stats(wrapped_packet, i)

        # check sample rate and mach time zero (if it exists) for changes.  if it changed, sync will not work.
        if not self._validate_sensor_settings(sample_rates, mach_time_zeros):
            raise Exception(&#34;ERROR: Sensor settings changed; separate data based on changes and re-analyze&#34;)
        self.find_bad_packets()
        self.evaluate_latencies_and_offsets()
        # set the packet duration
        self.packet_duration = dt.seconds_to_microseconds(fh.get_duration_seconds_from_sample_rate(
            int(self.sample_rate_hz)))
        # apply duration to app start to get packet end time, then subtract
        # that from server acquire time to get travel time to acquisition server
        # ASSUMING that acquisition and time-sync server have the same time source
        self.acquire_travel_time = self.server_acquisition_times - (self.rev_start_times + self.packet_duration)

    def evaluate_latencies_and_offsets(self):
        &#34;&#34;&#34;
        evaluates the goodness of latencies and offsets.
        adjusts rev_start_times if there is a best offset
        &#34;&#34;&#34;
        # if no decoders synced properly, all latencies are NaNs or all indices are bad
        if np.isnan(self.latencies).all() or len(self.bad_packets) == self.num_packets:
            # make everything empty or None, and best offset is 0 (no change)
            self.latencies = []
            self.offsets = []
            self.best_latency = None
            self.best_latency_index = None
            self.best_offset = 0.0
        else:
            # convert all NaN and negative values from latencies into zero
            self.latencies = np.nan_to_num(self.latencies)
            self.latencies[self.latencies &lt; 0] = 0.0
            # find and set minimum latency based on non-zero latencies
            self.best_latency = np.min(self.get_valid_latencies())
            self.latency_stats.best_value = self.best_latency
            self.best_latency_index = np.where(self.latencies == self.best_latency)[0][0]
            # find all non-NaN, non-zero offsets
            good_offsets = self.get_valid_offsets()

            if good_offsets is not None and len(good_offsets) &gt; 0:
                # there must be some good offsets; convert all NaN offsets to 0
                self.offsets = np.nan_to_num(self.offsets)
                # set best offset based on best latency
                self.best_offset = self.offsets[self.best_latency_index]
                self.offset_stats.best_value = self.best_offset
                # fix all packet start times by adding the packet&#39;s offset
                self.rev_start_times += self.best_offset
            else:
                # set offset properties to empty or None
                self.offsets = []

    def _compute_tri_message_stats(self, packet: WrappedRedvoxPacket, index: int):
        &#34;&#34;&#34;
        helper function to compute tri message stats of the time sync data
        :param packet: a packet to compute tri message stats from
        :param index: the index to add the data to
        &#34;&#34;&#34;
        # if there is a time sync channel with payload, find the minimum latency and its corresponding offset
        if packet.has_time_synchronization_sensor():
            timesync_channel = packet.time_synchronization_sensor()
            coeffs = timesync_channel.payload_values()
            # set the number of tri-message exchanges in the packet
            self.num_tri_messages[index] = int(len(coeffs) / 6)
            coeffs_tuple: Tuple[
                np.ndarray,
                np.ndarray,
                np.ndarray,
                np.ndarray,
                np.ndarray,
                np.ndarray] = tri_message_stats.transmit_receive_timestamps_microsec(coeffs)
            self.tri_message_coeffs.append(coeffs_tuple)  # save the tri-message exchanges for later
            a1_coeffs: np.ndarray = coeffs_tuple[0]
            a2_coeffs: np.ndarray = coeffs_tuple[1]
            a3_coeffs: np.ndarray = coeffs_tuple[2]
            b1_coeffs: np.ndarray = coeffs_tuple[3]
            b2_coeffs: np.ndarray = coeffs_tuple[4]
            b3_coeffs: np.ndarray = coeffs_tuple[5]
            # get tri message data via TriMessageStats class
            tms = tri_message_stats.TriMessageStats(packet.redvox_id(),
                                                    a1_coeffs,
                                                    a2_coeffs,
                                                    a3_coeffs,
                                                    b1_coeffs,
                                                    b2_coeffs,
                                                    b3_coeffs)
            # check if we actually have exchanges to evaluate
            if self.num_tri_messages[index] &gt; 0:
                # Concatenate d1 and d3 arrays, and o1 and o3 arrays when passing values into stats class
                #  note the last parameter multiplies the number of exchanges by 2, as there are two latencies
                #  and offsets calculated per exchange
                # noinspection PyTypeChecker
                self.latency_stats.add(np.mean([*tms.latency1, *tms.latency3]), np.std([*tms.latency1, *tms.latency3]),
                                       self.num_tri_messages[index] * 2)
                # noinspection PyTypeChecker
                self.offset_stats.add(np.mean([*tms.offset1, *tms.offset3]), np.std([*tms.offset1, *tms.offset3]),
                                      self.num_tri_messages[index] * 2)
                # set the best latency and offset based on the packet&#39;s metadata, or tri-message stats if no metadata
                latency: Optional[float] = packet.best_latency()
                # pass the location of the best calculated latency
                self.best_tri_msg_indices.append(tms.best_latency_index)
                if latency is None:
                    # no metadata
                    self.latencies[index] = tms.best_latency
                else:
                    self.latencies[index] = latency
                offset: Optional[float] = packet.best_offset()
                if offset is None:
                    # no metadata
                    self.offsets[index] = tms.best_offset
                else:
                    self.offsets[index] = offset
                # everything has been computed, time to return
                return
        # If here, there are no exchanges to read or there is no sync channel.
        # write default or empty values to the correct properties
        self.latencies[index] = 0.0
        self.offsets[index] = 0.0
        self.tri_message_coeffs.append((empty_array(), empty_array(), empty_array(),
                                        empty_array(), empty_array(), empty_array()))
        # pass the location of the best latency
        self.best_tri_msg_indices.append(-1)
        # noinspection PyTypeChecker
        self.latency_stats.add(0, 0, 0)
        # noinspection PyTypeChecker
        self.offset_stats.add(0, 0, 0)

    def _validate_sensor_settings(self, sample_rates: np.array, mach_time_zeros: np.array) -&gt; bool:
        &#34;&#34;&#34;
        Examine all sample rates and mach time zeros to ensure that sensor settings do not change
        Sets the sample rate and mach time zero if there is no change
        :param sample_rates: sample rates of all packets from sensor
        :param mach_time_zeros: machine time zero of all packets from sensor
        :return: True if sensor settings do not change
        &#34;&#34;&#34;
        # set the sample rate and mach time zero
        self.sample_rate_hz = sample_rates[0]
        self.mach_time_zero = mach_time_zeros[0]
        if len(sample_rates) &gt; 1:
            # if there&#39;s more than 1 value, we need to compare them
            for i in range(1, len(sample_rates)):
                if self.sample_rate_hz != sample_rates[i]:
                    print(&#34;ERROR: sample rate in data packets has changed.&#34;)
                    return False
                # process only non-nan mach time zeros
                if not np.isnan(self.mach_time_zero) and self.mach_time_zero != mach_time_zeros[i]:
                    print(&#34;ERROR: mach time zero in data packets has changed.&#34;)
                    return False
        return True

    def find_bad_packets(self):
        &#34;&#34;&#34;
        Find bad packets and mark them using the bad_packets property
        Assuming all packets have been processed and all bad packets are marked with a 0 (or are negative)
        &#34;&#34;&#34;
        for idx in range(len(self.latencies)):  # mark bad indices (they have a 0 or less value)
            if self.latencies[idx] &lt;= 0:
                self.bad_packets.append(idx)

    def get_ratio_bad_packets(self) -&gt; float:
        &#34;&#34;&#34;
        Return the ratio of packets with bad latency calculations over total packets
        :return: num packets with bad latency calculations / total packets
        &#34;&#34;&#34;
        if self.num_packets &lt; 1:
            return 0
        return len(self.bad_packets) / float(self.num_packets)

    def get_latency_mean(self) -&gt; Optional[float]:
        &#34;&#34;&#34;
        return the mean of all latencies, and None if the latencies are invalid.
        :return: the mean of all latencies
        &#34;&#34;&#34;
        if self.best_latency is None:
            return None
        else:
            return self.latency_stats.mean_of_means()

    def get_latency_std_dev(self) -&gt; Optional[float]:
        &#34;&#34;&#34;
        return the standard deviation (std_dev) of all latencies, and None if the latencies are invalid.
        :return: the std dev of all latencies
        &#34;&#34;&#34;
        if self.best_latency is None:
            return None
        else:
            return self.latency_stats.total_std_dev()

    def get_valid_latencies(self, latency_array: np.array = None) -&gt; np.array:
        &#34;&#34;&#34;
        takes latencies, converts NaNs and negatives to 0, then returns non-zero latencies
        :param latency_array: optional array to clean instead of self.latencies; default None
        :return: non-NaN, non-zero latencies
        &#34;&#34;&#34;
        if latency_array is None:
            clean_latencies = np.nan_to_num(self.latencies)  # replace NaNs with zeros
        else:
            clean_latencies = np.nan_to_num(latency_array)  # replace NaNs with zeros
        clean_latencies[clean_latencies &lt; 0] = 0  # replace negative latencies with 0
        return clean_latencies[clean_latencies != 0]  # return only non-zero latencies

    def get_offset_mean(self) -&gt; Optional[float]:
        &#34;&#34;&#34;
        return the mean of all offsets, and 0.0 if the offsets or latencies are invalid.
        :return: the mean of all offsets
        &#34;&#34;&#34;
        if self.best_latency is None or self.best_offset == 0.0:
            return 0.0
        else:
            return self.offset_stats.mean_of_means()

    def get_offset_std_dev(self) -&gt; Optional[float]:
        &#34;&#34;&#34;
        return the standard deviation (std_dev) of all offsets, and 0.0 if the offsets or latencies are invalid.
        :return: the std dev of all offsets
        &#34;&#34;&#34;
        if self.best_latency is None or self.best_offset == 0.0:
            return 0.0
        else:
            return self.offset_stats.total_std_dev()

    def get_valid_offsets(self, offset_array: np.array = None) -&gt; np.array:
        &#34;&#34;&#34;
        takes valid offsets (based on bad_packets), converts NaNs to 0, then returns non-zero offsets
        :param offset_array: optional array to clean; default None
        :return: non-NaN, non-zero offsets
        &#34;&#34;&#34;
        if offset_array is None:
            if len(self.bad_packets) &gt; 0:
                valids = []
                for i in range(len(self.offsets)):
                    if i not in self.bad_packets:
                        valids.append(self.offsets[i])
                clean_offsets = np.nan_to_num(valids)  # replace NaNs with zeros
            else:
                clean_offsets = np.nan_to_num(self.offsets)
        else:
            clean_offsets = np.nan_to_num(offset_array)
        return clean_offsets[clean_offsets != 0]  # return only non-zero offsets

    def get_valid_rev_start_times(self) -&gt; np.array:
        &#34;&#34;&#34;
        return the array of valid (based on bad_packets) revised start times
        :return: array of valid revised start times
        &#34;&#34;&#34;
        if len(self.bad_packets) &gt; 0:  # return only the start times not associated with a bad packet
            valids = []
            for i in range(len(self.rev_start_times)):
                if i not in self.bad_packets:  # this is a good packet
                    valids.append(self.rev_start_times[i])
            return np.array(valids)
        else:
            return self.rev_start_times

    def get_best_rev_start_time(self) -&gt; int:
        &#34;&#34;&#34;
        return the revised start time associated with the lowest latency
        :return: revised start time in microseconds associated with the lowest latency
        &#34;&#34;&#34;
        return self.rev_start_times[self.best_latency_index]


def validate_sensors(wrapped_packets: List[WrappedRedvoxPacket]) -&gt; bool:
    &#34;&#34;&#34;
    Examine all sample rates and mach time zeros to ensure that sensor settings do not change
    :param wrapped_packets: a list of wrapped redvox packets to read
    :return: True if sensor settings do not change
    &#34;&#34;&#34;
    # check that we have packets to read
    num_packets = len(wrapped_packets)
    if num_packets &lt; 1:
        print(&#34;ERROR: no data to validate.&#34;)
        return False
    # if we have more than one packet, we need to validate the data
    elif num_packets &gt; 1:
        sample_rates = np.zeros(num_packets)
        mach_time_zeros = np.zeros(num_packets)
        for j, wrapped_packet in enumerate(wrapped_packets):
            sample_rates[j] = wrapped_packet.microphone_sensor().sample_rate_hz()
            mach_time_zeros[j] = wrapped_packet.mach_time_zero()
        for i in range(1, len(sample_rates)):
            if sample_rates[0] != sample_rates[i]:
                print(&#34;ERROR: sample rate in data packets has changed.&#34;)
                return False
            # process only non-nan mach time zeros
            if not np.isnan(mach_time_zeros[0]) and mach_time_zeros[0] != mach_time_zeros[i]:
                print(&#34;ERROR: mach time zero in data packets has changed.&#34;)
                return False
    # we get here if all packets have the same sample rate and mach time zero
    return True


def update_evenly_sampled_time_array(tsd: TimeSyncData, num_samples: float = None,
                                     time_start_array: np.array = None) -&gt; np.ndarray:
    &#34;&#34;&#34;
    Correct evenly sampled times using updated time_start_array values as the focal point.
    Expects tsd to have the same number of packets as elements in time_start_array
    Inserts data gaps where necessary before building array.
    Throws an exception if the number of packets in tsd does not match the length of time_start_array

    :param tsd: TimeSyncData object that contains the information needed to update the time array
    :param num_samples: number of samples in one file; optional, uses number based on sample rate if not given
    :param time_start_array: the list of timestamps to correct in seconds; optional, uses the start times in the
                             TimeSyncData object if not given
    :return: Revised time array in epoch seconds
    &#34;&#34;&#34;
    if time_start_array is None:
        # replace the time_start_array with values from tsd; convert tsd times to seconds
        time_start_array = tsd.rev_start_times / dt.MICROSECONDS_IN_SECOND
    num_files = tsd.num_packets
    # the TimeSyncData must have the same number of packets as the number of elements in time_start_array
    if num_files != len(time_start_array):
        # alert the user, then quit
        raise Exception(&#34;ERROR: Attempted to update a time array that doesn&#39;t contain &#34;
                        &#34;the same number of elements as the TimeSyncData!&#34;)

    if num_samples is None:
        num_samples = fh.get_num_points_from_sample_rate(tsd.sample_rate_hz)
    t_dt = 1.0 / tsd.sample_rate_hz

    # Use TimeSyncData object to find best start index.
    # Samples before will be the number of decoders before a0 times the number of samples in a file.
    # Samples after will be the number of decoders after a0 times the number of samples in a file minus 1;
    # the minus one represents the best a0.
    decoder_idx = tsd.best_latency_index
    samples_before = int(decoder_idx * num_samples)
    samples_after = round((num_files - decoder_idx) * num_samples) - 1
    best_start_sec = time_start_array[decoder_idx]

    # build the time arrays separately in epoch seconds, then join into one
    # add 1 to include the actual a0 sample, then add 1 again to skip the a0 sample; this avoids repetition
    timesec_before = np.vectorize(lambda t: best_start_sec - t * t_dt)(list(range(int(samples_before + 1))))
    timesec_before = timesec_before[::-1]  # reverse &#39;before&#39; times so they increase from earliest start time
    timesec_after = np.vectorize(lambda t: best_start_sec + t * t_dt)(list(range(1, int(samples_after + 1))))
    timesec_rev = np.concatenate([timesec_before, timesec_after])

    return timesec_rev


def update_time_array(tsd: TimeSyncData, time_array: np.array) -&gt; np.ndarray:
    &#34;&#34;&#34;
    Correct timestamps in time_array using information from TimeSyncData
    :param tsd: TimeSyncData object that contains the information needed to update the time array
    :param time_array: the list of timestamps to correct in seconds
    :return: Revised time array in epoch seconds
    &#34;&#34;&#34;
    return time_array + (tsd.best_offset / dt.MICROSECONDS_IN_SECOND)


def sync_packet_time_900(wrapped_packets_fs: list, verbose: bool = False):
    &#34;&#34;&#34;
    Correct the timestamps for api900 data based on minimum latency and best offset of the ensemble.

    :param wrapped_packets_fs: wrapped packets with same sample rate and from same device
    :param verbose: if True, prints statements to assess goodness of time sync
    &#34;&#34;&#34;

    # assume each packet has a best latency and offset
    latencies = []  # array of minimum latencies
    offsets = []  # array of offset applied to machine time to get sync time

    # latencies and offsets
    for packet in wrapped_packets_fs:
        if packet.has_time_synchronization_sensor():
            # set the best latency and offset based on the packet&#39;s metadata
            if packet.best_latency() is not None and packet.best_offset() is not None:
                latencies.append(packet.best_latency())
                offsets.append(packet.best_offset())
            else:
                # metadata not set, use packet contents
                timesync_channel = packet.time_synchronization_sensor()
                coeffs = timesync_channel.payload_values()
                coeffs_tuple: Tuple[
                    np.ndarray,
                    np.ndarray,
                    np.ndarray,
                    np.ndarray,
                    np.ndarray,
                    np.ndarray] = tri_message_stats.transmit_receive_timestamps_microsec(coeffs)
                a1_coeffs: np.ndarray = coeffs_tuple[0]
                a2_coeffs: np.ndarray = coeffs_tuple[1]
                a3_coeffs: np.ndarray = coeffs_tuple[2]
                b1_coeffs: np.ndarray = coeffs_tuple[3]
                b2_coeffs: np.ndarray = coeffs_tuple[4]
                b3_coeffs: np.ndarray = coeffs_tuple[5]
                # get tri message data via TriMessageStats class
                tms = tri_message_stats.TriMessageStats(packet.redvox_id(),
                                                        a1_coeffs,
                                                        a2_coeffs,
                                                        a3_coeffs,
                                                        b1_coeffs,
                                                        b2_coeffs,
                                                        b3_coeffs)
                latencies.append(tms.best_latency)
                offsets.append(tms.best_offset)
        # if there is no time sync channel (usually no communication between device and server), default to 0
        else:
            latencies.append(0)
            offsets.append(0)

    # convert NaN latencies to 0
    latencies = np.nan_to_num(latencies)
    # convert any negative latency to 0.
    latencies[latencies &lt; 0] = 0

    if len(np.nonzero(latencies)[0]) == 0:  # if no decoders synced properly, all latencies are 0
        sync_server = wrapped_packets_fs[0].time_synchronization_server()
        if verbose:
            print(&#39;\n{} did not achieve sync with time sync server {}!&#39;.format(
                wrapped_packets_fs[0].redvox_id(), sync_server))
        offset = 0
    else:
        d1_min = np.min(latencies[latencies != 0])
        best_d1_index = np.where(latencies == d1_min)[0][0]
        # correct each packet&#39;s timestamps
        offset = int(offsets[best_d1_index])

    for wrapped_packet in wrapped_packets_fs:
        # update the machine file start time and mach time zero
        wrapped_packet.set_app_file_start_timestamp_epoch_microseconds_utc(
            wrapped_packet.app_file_start_timestamp_epoch_microseconds_utc() + offset)
        wrapped_packet.set_app_file_start_timestamp_machine(
            wrapped_packet.app_file_start_timestamp_machine() + offset)
        if wrapped_packet.mach_time_zero() is not None:
            wrapped_packet.set_mach_time_zero(wrapped_packet.mach_time_zero() + offset)
        # update microphone start time
        if wrapped_packet.has_microphone_sensor():
            wrapped_packet.microphone_sensor().set_first_sample_timestamp_epoch_microseconds_utc(
                wrapped_packet.microphone_sensor().first_sample_timestamp_epoch_microseconds_utc() + offset)
        # correct the times in unevenly sampled channels using the packets&#39; best offset
        wrapped_packet.update_uneven_sensor_timestamps(offset)
        wrapped_packet.set_is_synch_corrected(True)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="redvox.api900.timesync.api900_timesync.sync_packet_time_900"><code class="name flex">
<span>def <span class="ident">sync_packet_time_900</span></span>(<span>wrapped_packets_fs: list, verbose: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Correct the timestamps for api900 data based on minimum latency and best offset of the ensemble.</p>
<p>:param wrapped_packets_fs: wrapped packets with same sample rate and from same device
:param verbose: if True, prints statements to assess goodness of time sync</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sync_packet_time_900(wrapped_packets_fs: list, verbose: bool = False):
    &#34;&#34;&#34;
    Correct the timestamps for api900 data based on minimum latency and best offset of the ensemble.

    :param wrapped_packets_fs: wrapped packets with same sample rate and from same device
    :param verbose: if True, prints statements to assess goodness of time sync
    &#34;&#34;&#34;

    # assume each packet has a best latency and offset
    latencies = []  # array of minimum latencies
    offsets = []  # array of offset applied to machine time to get sync time

    # latencies and offsets
    for packet in wrapped_packets_fs:
        if packet.has_time_synchronization_sensor():
            # set the best latency and offset based on the packet&#39;s metadata
            if packet.best_latency() is not None and packet.best_offset() is not None:
                latencies.append(packet.best_latency())
                offsets.append(packet.best_offset())
            else:
                # metadata not set, use packet contents
                timesync_channel = packet.time_synchronization_sensor()
                coeffs = timesync_channel.payload_values()
                coeffs_tuple: Tuple[
                    np.ndarray,
                    np.ndarray,
                    np.ndarray,
                    np.ndarray,
                    np.ndarray,
                    np.ndarray] = tri_message_stats.transmit_receive_timestamps_microsec(coeffs)
                a1_coeffs: np.ndarray = coeffs_tuple[0]
                a2_coeffs: np.ndarray = coeffs_tuple[1]
                a3_coeffs: np.ndarray = coeffs_tuple[2]
                b1_coeffs: np.ndarray = coeffs_tuple[3]
                b2_coeffs: np.ndarray = coeffs_tuple[4]
                b3_coeffs: np.ndarray = coeffs_tuple[5]
                # get tri message data via TriMessageStats class
                tms = tri_message_stats.TriMessageStats(packet.redvox_id(),
                                                        a1_coeffs,
                                                        a2_coeffs,
                                                        a3_coeffs,
                                                        b1_coeffs,
                                                        b2_coeffs,
                                                        b3_coeffs)
                latencies.append(tms.best_latency)
                offsets.append(tms.best_offset)
        # if there is no time sync channel (usually no communication between device and server), default to 0
        else:
            latencies.append(0)
            offsets.append(0)

    # convert NaN latencies to 0
    latencies = np.nan_to_num(latencies)
    # convert any negative latency to 0.
    latencies[latencies &lt; 0] = 0

    if len(np.nonzero(latencies)[0]) == 0:  # if no decoders synced properly, all latencies are 0
        sync_server = wrapped_packets_fs[0].time_synchronization_server()
        if verbose:
            print(&#39;\n{} did not achieve sync with time sync server {}!&#39;.format(
                wrapped_packets_fs[0].redvox_id(), sync_server))
        offset = 0
    else:
        d1_min = np.min(latencies[latencies != 0])
        best_d1_index = np.where(latencies == d1_min)[0][0]
        # correct each packet&#39;s timestamps
        offset = int(offsets[best_d1_index])

    for wrapped_packet in wrapped_packets_fs:
        # update the machine file start time and mach time zero
        wrapped_packet.set_app_file_start_timestamp_epoch_microseconds_utc(
            wrapped_packet.app_file_start_timestamp_epoch_microseconds_utc() + offset)
        wrapped_packet.set_app_file_start_timestamp_machine(
            wrapped_packet.app_file_start_timestamp_machine() + offset)
        if wrapped_packet.mach_time_zero() is not None:
            wrapped_packet.set_mach_time_zero(wrapped_packet.mach_time_zero() + offset)
        # update microphone start time
        if wrapped_packet.has_microphone_sensor():
            wrapped_packet.microphone_sensor().set_first_sample_timestamp_epoch_microseconds_utc(
                wrapped_packet.microphone_sensor().first_sample_timestamp_epoch_microseconds_utc() + offset)
        # correct the times in unevenly sampled channels using the packets&#39; best offset
        wrapped_packet.update_uneven_sensor_timestamps(offset)
        wrapped_packet.set_is_synch_corrected(True)</code></pre>
</details>
</dd>
<dt id="redvox.api900.timesync.api900_timesync.update_evenly_sampled_time_array"><code class="name flex">
<span>def <span class="ident">update_evenly_sampled_time_array</span></span>(<span>tsd: <a title="redvox.api900.timesync.api900_timesync.TimeSyncData" href="#redvox.api900.timesync.api900_timesync.TimeSyncData">TimeSyncData</a>, num_samples: float = None, time_start_array: <built-in function array> = None) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Correct evenly sampled times using updated time_start_array values as the focal point.
Expects tsd to have the same number of packets as elements in time_start_array
Inserts data gaps where necessary before building array.
Throws an exception if the number of packets in tsd does not match the length of time_start_array</p>
<p>:param tsd: TimeSyncData object that contains the information needed to update the time array
:param num_samples: number of samples in one file; optional, uses number based on sample rate if not given
:param time_start_array: the list of timestamps to correct in seconds; optional, uses the start times in the
TimeSyncData object if not given
:return: Revised time array in epoch seconds</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_evenly_sampled_time_array(tsd: TimeSyncData, num_samples: float = None,
                                     time_start_array: np.array = None) -&gt; np.ndarray:
    &#34;&#34;&#34;
    Correct evenly sampled times using updated time_start_array values as the focal point.
    Expects tsd to have the same number of packets as elements in time_start_array
    Inserts data gaps where necessary before building array.
    Throws an exception if the number of packets in tsd does not match the length of time_start_array

    :param tsd: TimeSyncData object that contains the information needed to update the time array
    :param num_samples: number of samples in one file; optional, uses number based on sample rate if not given
    :param time_start_array: the list of timestamps to correct in seconds; optional, uses the start times in the
                             TimeSyncData object if not given
    :return: Revised time array in epoch seconds
    &#34;&#34;&#34;
    if time_start_array is None:
        # replace the time_start_array with values from tsd; convert tsd times to seconds
        time_start_array = tsd.rev_start_times / dt.MICROSECONDS_IN_SECOND
    num_files = tsd.num_packets
    # the TimeSyncData must have the same number of packets as the number of elements in time_start_array
    if num_files != len(time_start_array):
        # alert the user, then quit
        raise Exception(&#34;ERROR: Attempted to update a time array that doesn&#39;t contain &#34;
                        &#34;the same number of elements as the TimeSyncData!&#34;)

    if num_samples is None:
        num_samples = fh.get_num_points_from_sample_rate(tsd.sample_rate_hz)
    t_dt = 1.0 / tsd.sample_rate_hz

    # Use TimeSyncData object to find best start index.
    # Samples before will be the number of decoders before a0 times the number of samples in a file.
    # Samples after will be the number of decoders after a0 times the number of samples in a file minus 1;
    # the minus one represents the best a0.
    decoder_idx = tsd.best_latency_index
    samples_before = int(decoder_idx * num_samples)
    samples_after = round((num_files - decoder_idx) * num_samples) - 1
    best_start_sec = time_start_array[decoder_idx]

    # build the time arrays separately in epoch seconds, then join into one
    # add 1 to include the actual a0 sample, then add 1 again to skip the a0 sample; this avoids repetition
    timesec_before = np.vectorize(lambda t: best_start_sec - t * t_dt)(list(range(int(samples_before + 1))))
    timesec_before = timesec_before[::-1]  # reverse &#39;before&#39; times so they increase from earliest start time
    timesec_after = np.vectorize(lambda t: best_start_sec + t * t_dt)(list(range(1, int(samples_after + 1))))
    timesec_rev = np.concatenate([timesec_before, timesec_after])

    return timesec_rev</code></pre>
</details>
</dd>
<dt id="redvox.api900.timesync.api900_timesync.update_time_array"><code class="name flex">
<span>def <span class="ident">update_time_array</span></span>(<span>tsd: <a title="redvox.api900.timesync.api900_timesync.TimeSyncData" href="#redvox.api900.timesync.api900_timesync.TimeSyncData">TimeSyncData</a>, time_array: <built-in function array>) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Correct timestamps in time_array using information from TimeSyncData
:param tsd: TimeSyncData object that contains the information needed to update the time array
:param time_array: the list of timestamps to correct in seconds
:return: Revised time array in epoch seconds</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_time_array(tsd: TimeSyncData, time_array: np.array) -&gt; np.ndarray:
    &#34;&#34;&#34;
    Correct timestamps in time_array using information from TimeSyncData
    :param tsd: TimeSyncData object that contains the information needed to update the time array
    :param time_array: the list of timestamps to correct in seconds
    :return: Revised time array in epoch seconds
    &#34;&#34;&#34;
    return time_array + (tsd.best_offset / dt.MICROSECONDS_IN_SECOND)</code></pre>
</details>
</dd>
<dt id="redvox.api900.timesync.api900_timesync.validate_sensors"><code class="name flex">
<span>def <span class="ident">validate_sensors</span></span>(<span>wrapped_packets: List[<a title="redvox.api900.wrapped_redvox_packet.WrappedRedvoxPacket" href="../wrapped_redvox_packet.html#redvox.api900.wrapped_redvox_packet.WrappedRedvoxPacket">WrappedRedvoxPacket</a>]) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Examine all sample rates and mach time zeros to ensure that sensor settings do not change
:param wrapped_packets: a list of wrapped redvox packets to read
:return: True if sensor settings do not change</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def validate_sensors(wrapped_packets: List[WrappedRedvoxPacket]) -&gt; bool:
    &#34;&#34;&#34;
    Examine all sample rates and mach time zeros to ensure that sensor settings do not change
    :param wrapped_packets: a list of wrapped redvox packets to read
    :return: True if sensor settings do not change
    &#34;&#34;&#34;
    # check that we have packets to read
    num_packets = len(wrapped_packets)
    if num_packets &lt; 1:
        print(&#34;ERROR: no data to validate.&#34;)
        return False
    # if we have more than one packet, we need to validate the data
    elif num_packets &gt; 1:
        sample_rates = np.zeros(num_packets)
        mach_time_zeros = np.zeros(num_packets)
        for j, wrapped_packet in enumerate(wrapped_packets):
            sample_rates[j] = wrapped_packet.microphone_sensor().sample_rate_hz()
            mach_time_zeros[j] = wrapped_packet.mach_time_zero()
        for i in range(1, len(sample_rates)):
            if sample_rates[0] != sample_rates[i]:
                print(&#34;ERROR: sample rate in data packets has changed.&#34;)
                return False
            # process only non-nan mach time zeros
            if not np.isnan(mach_time_zeros[0]) and mach_time_zeros[0] != mach_time_zeros[i]:
                print(&#34;ERROR: mach time zero in data packets has changed.&#34;)
                return False
    # we get here if all packets have the same sample rate and mach time zero
    return True</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="redvox.api900.timesync.api900_timesync.TimeSyncData"><code class="flex name class">
<span>class <span class="ident">TimeSyncData</span></span>
<span>(</span><span>wrapped_packets: List[<a title="redvox.api900.wrapped_redvox_packet.WrappedRedvoxPacket" href="../wrapped_redvox_packet.html#redvox.api900.wrapped_redvox_packet.WrappedRedvoxPacket">WrappedRedvoxPacket</a>] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Stores latencies, revised start times, time sync server offsets, and difference in adjusted machine time and
acquisition server time
Note that inputs to this must be continuous data; any change in sensor mach_time_zero or sample_rate
requires a new TimeSyncData object
ALL times in microseconds
properties:
rev_start_times: revised machine start times (per packet)
server_acquisition_times: time packet arrived at server (per packet)
latencies: latencies (per packet)
best_latency: the lowest latency among packets
best_latency_index: index in latencies array that contains the best latency
latency_stats: StatsContainer for latencies
offsets: list of calculated offsets (per packet)
best_offset: the offset that is paired with the lowest latency
offset_stats: StatsContainer for offsets
num_packets: the number of packets being analyzed
sample_rate_hz: the sample rate in Hz of all packets
packet_duration: the duration of all packets
mach_time_zero: the start time of the app in machine time
num_tri_messages: number of tri-message exchanges (per packet)
tri_message_coeffs: list of 6-tuples containing the tri-message exchange coefficients (up to 1 tuple per packet)
best_tri_msg_indices: the index of the best tri-message for each of the tri_message_coeffs tuples
acquire_travel_time: calculated time it took packet to reach server (up to 1 per packet)
bad_packets: indices of packets with an undefined or 0 latency</p>
<p>Initialize properties, assume all packets share the same sample rate and are continuous
:param wrapped_packets: list of data packets</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TimeSyncData:
    &#34;&#34;&#34;
    Stores latencies, revised start times, time sync server offsets, and difference in adjusted machine time and
    acquisition server time
    Note that inputs to this must be continuous data; any change in sensor mach_time_zero or sample_rate
    requires a new TimeSyncData object
    ALL times in microseconds
    properties:
        rev_start_times: revised machine start times (per packet)
        server_acquisition_times: time packet arrived at server (per packet)
        latencies: latencies (per packet)
        best_latency: the lowest latency among packets
        best_latency_index: index in latencies array that contains the best latency
        latency_stats: StatsContainer for latencies
        offsets: list of calculated offsets (per packet)
        best_offset: the offset that is paired with the lowest latency
        offset_stats: StatsContainer for offsets
        num_packets: the number of packets being analyzed
        sample_rate_hz: the sample rate in Hz of all packets
        packet_duration: the duration of all packets
        mach_time_zero: the start time of the app in machine time
        num_tri_messages: number of tri-message exchanges (per packet)
        tri_message_coeffs: list of 6-tuples containing the tri-message exchange coefficients (up to 1 tuple per packet)
        best_tri_msg_indices: the index of the best tri-message for each of the tri_message_coeffs tuples
        acquire_travel_time: calculated time it took packet to reach server (up to 1 per packet)
        bad_packets: indices of packets with an undefined or 0 latency
    &#34;&#34;&#34;

    def __init__(self, wrapped_packets: List[WrappedRedvoxPacket] = None):
        &#34;&#34;&#34;
        Initialize properties, assume all packets share the same sample rate and are continuous
        :param wrapped_packets: list of data packets
        &#34;&#34;&#34;
        self.latency_stats: stats_helper.StatsContainer = stats_helper.StatsContainer(&#34;latency&#34;)
        self.offset_stats: stats_helper.StatsContainer = stats_helper.StatsContainer(&#34;offset&#34;)
        if wrapped_packets is None or len(wrapped_packets) &lt; 1:
            self.rev_start_times: np.ndarray = np.ndarray((0, 0))
            self.server_acquisition_times: np.ndarray = np.ndarray((0, 0))
            self.latencies: np.ndarray = np.ndarray((0, 0))
            self.best_latency: Optional[float] = None
            self.best_latency_index: Optional[int] = None
            self.offsets: np.ndarray = np.ndarray((0, 0))
            self.best_offset: float = 0.0
            self.num_packets: int = 0
            self.sample_rate_hz: Optional[float] = None
            self.packet_duration: int = 0
            self.mach_time_zero: Optional[float] = None
            self.num_tri_messages: np.ndarray = np.ndarray((0, 0))
            self.tri_message_coeffs: List[Tuple] = []
            self.best_tri_msg_indices: List[int] = []
            self.acquire_travel_time: np.ndarray = np.ndarray((0, 0))
            self.bad_packets: List[int] = []
        else:
            self.get_time_sync_data(wrapped_packets)

    def get_time_sync_data(self, wrapped_packets: List[WrappedRedvoxPacket]):
        &#34;&#34;&#34;
        Sets the time statistics between machine, time server, and acquisition server for the packets given.
        :param wrapped_packets: wrapped packets with same sample rate
        &#34;&#34;&#34;
        self.server_acquisition_times = np.zeros(len(wrapped_packets))  # array of server acquisition times
        self.rev_start_times = np.zeros(len(wrapped_packets))   # array of app start times
        self.num_tri_messages = np.zeros(len(wrapped_packets))  # number of tri-message exchanges per packet
        self.latencies = np.zeros(len(wrapped_packets))  # array of minimum latencies
        self.offsets = np.zeros(len(wrapped_packets))  # array of offset applied to machine time to get sync time
        self.num_packets = len(wrapped_packets)  # number of packets in list
        self.tri_message_coeffs = []    # a list of tri-message coefficients
        self.best_tri_msg_indices = []  # a list of the best latency index in each set of tri-message coefficients
        self.bad_packets = []   # list of packets that contain invalid data
        sample_rates = np.zeros(len(wrapped_packets))       # list of sample rates, should all be the same
        mach_time_zeros = np.zeros(len(wrapped_packets))    # list of mach time zeros, should all the be same

        # get the server acquisition time, app start time, and tri message stats
        for i, wrapped_packet in enumerate(wrapped_packets):
            # pass the mach_time_zero and sample_rate into arrays
            sample_rates[i] = wrapped_packet.microphone_sensor().sample_rate_hz()
            mach_time_zeros[i] = wrapped_packet.mach_time_zero()
            self.server_acquisition_times[i] = wrapped_packet.server_timestamp_epoch_microseconds_utc()
            self.rev_start_times[i] = wrapped_packet.app_file_start_timestamp_epoch_microseconds_utc()
            self._compute_tri_message_stats(wrapped_packet, i)

        # check sample rate and mach time zero (if it exists) for changes.  if it changed, sync will not work.
        if not self._validate_sensor_settings(sample_rates, mach_time_zeros):
            raise Exception(&#34;ERROR: Sensor settings changed; separate data based on changes and re-analyze&#34;)
        self.find_bad_packets()
        self.evaluate_latencies_and_offsets()
        # set the packet duration
        self.packet_duration = dt.seconds_to_microseconds(fh.get_duration_seconds_from_sample_rate(
            int(self.sample_rate_hz)))
        # apply duration to app start to get packet end time, then subtract
        # that from server acquire time to get travel time to acquisition server
        # ASSUMING that acquisition and time-sync server have the same time source
        self.acquire_travel_time = self.server_acquisition_times - (self.rev_start_times + self.packet_duration)

    def evaluate_latencies_and_offsets(self):
        &#34;&#34;&#34;
        evaluates the goodness of latencies and offsets.
        adjusts rev_start_times if there is a best offset
        &#34;&#34;&#34;
        # if no decoders synced properly, all latencies are NaNs or all indices are bad
        if np.isnan(self.latencies).all() or len(self.bad_packets) == self.num_packets:
            # make everything empty or None, and best offset is 0 (no change)
            self.latencies = []
            self.offsets = []
            self.best_latency = None
            self.best_latency_index = None
            self.best_offset = 0.0
        else:
            # convert all NaN and negative values from latencies into zero
            self.latencies = np.nan_to_num(self.latencies)
            self.latencies[self.latencies &lt; 0] = 0.0
            # find and set minimum latency based on non-zero latencies
            self.best_latency = np.min(self.get_valid_latencies())
            self.latency_stats.best_value = self.best_latency
            self.best_latency_index = np.where(self.latencies == self.best_latency)[0][0]
            # find all non-NaN, non-zero offsets
            good_offsets = self.get_valid_offsets()

            if good_offsets is not None and len(good_offsets) &gt; 0:
                # there must be some good offsets; convert all NaN offsets to 0
                self.offsets = np.nan_to_num(self.offsets)
                # set best offset based on best latency
                self.best_offset = self.offsets[self.best_latency_index]
                self.offset_stats.best_value = self.best_offset
                # fix all packet start times by adding the packet&#39;s offset
                self.rev_start_times += self.best_offset
            else:
                # set offset properties to empty or None
                self.offsets = []

    def _compute_tri_message_stats(self, packet: WrappedRedvoxPacket, index: int):
        &#34;&#34;&#34;
        helper function to compute tri message stats of the time sync data
        :param packet: a packet to compute tri message stats from
        :param index: the index to add the data to
        &#34;&#34;&#34;
        # if there is a time sync channel with payload, find the minimum latency and its corresponding offset
        if packet.has_time_synchronization_sensor():
            timesync_channel = packet.time_synchronization_sensor()
            coeffs = timesync_channel.payload_values()
            # set the number of tri-message exchanges in the packet
            self.num_tri_messages[index] = int(len(coeffs) / 6)
            coeffs_tuple: Tuple[
                np.ndarray,
                np.ndarray,
                np.ndarray,
                np.ndarray,
                np.ndarray,
                np.ndarray] = tri_message_stats.transmit_receive_timestamps_microsec(coeffs)
            self.tri_message_coeffs.append(coeffs_tuple)  # save the tri-message exchanges for later
            a1_coeffs: np.ndarray = coeffs_tuple[0]
            a2_coeffs: np.ndarray = coeffs_tuple[1]
            a3_coeffs: np.ndarray = coeffs_tuple[2]
            b1_coeffs: np.ndarray = coeffs_tuple[3]
            b2_coeffs: np.ndarray = coeffs_tuple[4]
            b3_coeffs: np.ndarray = coeffs_tuple[5]
            # get tri message data via TriMessageStats class
            tms = tri_message_stats.TriMessageStats(packet.redvox_id(),
                                                    a1_coeffs,
                                                    a2_coeffs,
                                                    a3_coeffs,
                                                    b1_coeffs,
                                                    b2_coeffs,
                                                    b3_coeffs)
            # check if we actually have exchanges to evaluate
            if self.num_tri_messages[index] &gt; 0:
                # Concatenate d1 and d3 arrays, and o1 and o3 arrays when passing values into stats class
                #  note the last parameter multiplies the number of exchanges by 2, as there are two latencies
                #  and offsets calculated per exchange
                # noinspection PyTypeChecker
                self.latency_stats.add(np.mean([*tms.latency1, *tms.latency3]), np.std([*tms.latency1, *tms.latency3]),
                                       self.num_tri_messages[index] * 2)
                # noinspection PyTypeChecker
                self.offset_stats.add(np.mean([*tms.offset1, *tms.offset3]), np.std([*tms.offset1, *tms.offset3]),
                                      self.num_tri_messages[index] * 2)
                # set the best latency and offset based on the packet&#39;s metadata, or tri-message stats if no metadata
                latency: Optional[float] = packet.best_latency()
                # pass the location of the best calculated latency
                self.best_tri_msg_indices.append(tms.best_latency_index)
                if latency is None:
                    # no metadata
                    self.latencies[index] = tms.best_latency
                else:
                    self.latencies[index] = latency
                offset: Optional[float] = packet.best_offset()
                if offset is None:
                    # no metadata
                    self.offsets[index] = tms.best_offset
                else:
                    self.offsets[index] = offset
                # everything has been computed, time to return
                return
        # If here, there are no exchanges to read or there is no sync channel.
        # write default or empty values to the correct properties
        self.latencies[index] = 0.0
        self.offsets[index] = 0.0
        self.tri_message_coeffs.append((empty_array(), empty_array(), empty_array(),
                                        empty_array(), empty_array(), empty_array()))
        # pass the location of the best latency
        self.best_tri_msg_indices.append(-1)
        # noinspection PyTypeChecker
        self.latency_stats.add(0, 0, 0)
        # noinspection PyTypeChecker
        self.offset_stats.add(0, 0, 0)

    def _validate_sensor_settings(self, sample_rates: np.array, mach_time_zeros: np.array) -&gt; bool:
        &#34;&#34;&#34;
        Examine all sample rates and mach time zeros to ensure that sensor settings do not change
        Sets the sample rate and mach time zero if there is no change
        :param sample_rates: sample rates of all packets from sensor
        :param mach_time_zeros: machine time zero of all packets from sensor
        :return: True if sensor settings do not change
        &#34;&#34;&#34;
        # set the sample rate and mach time zero
        self.sample_rate_hz = sample_rates[0]
        self.mach_time_zero = mach_time_zeros[0]
        if len(sample_rates) &gt; 1:
            # if there&#39;s more than 1 value, we need to compare them
            for i in range(1, len(sample_rates)):
                if self.sample_rate_hz != sample_rates[i]:
                    print(&#34;ERROR: sample rate in data packets has changed.&#34;)
                    return False
                # process only non-nan mach time zeros
                if not np.isnan(self.mach_time_zero) and self.mach_time_zero != mach_time_zeros[i]:
                    print(&#34;ERROR: mach time zero in data packets has changed.&#34;)
                    return False
        return True

    def find_bad_packets(self):
        &#34;&#34;&#34;
        Find bad packets and mark them using the bad_packets property
        Assuming all packets have been processed and all bad packets are marked with a 0 (or are negative)
        &#34;&#34;&#34;
        for idx in range(len(self.latencies)):  # mark bad indices (they have a 0 or less value)
            if self.latencies[idx] &lt;= 0:
                self.bad_packets.append(idx)

    def get_ratio_bad_packets(self) -&gt; float:
        &#34;&#34;&#34;
        Return the ratio of packets with bad latency calculations over total packets
        :return: num packets with bad latency calculations / total packets
        &#34;&#34;&#34;
        if self.num_packets &lt; 1:
            return 0
        return len(self.bad_packets) / float(self.num_packets)

    def get_latency_mean(self) -&gt; Optional[float]:
        &#34;&#34;&#34;
        return the mean of all latencies, and None if the latencies are invalid.
        :return: the mean of all latencies
        &#34;&#34;&#34;
        if self.best_latency is None:
            return None
        else:
            return self.latency_stats.mean_of_means()

    def get_latency_std_dev(self) -&gt; Optional[float]:
        &#34;&#34;&#34;
        return the standard deviation (std_dev) of all latencies, and None if the latencies are invalid.
        :return: the std dev of all latencies
        &#34;&#34;&#34;
        if self.best_latency is None:
            return None
        else:
            return self.latency_stats.total_std_dev()

    def get_valid_latencies(self, latency_array: np.array = None) -&gt; np.array:
        &#34;&#34;&#34;
        takes latencies, converts NaNs and negatives to 0, then returns non-zero latencies
        :param latency_array: optional array to clean instead of self.latencies; default None
        :return: non-NaN, non-zero latencies
        &#34;&#34;&#34;
        if latency_array is None:
            clean_latencies = np.nan_to_num(self.latencies)  # replace NaNs with zeros
        else:
            clean_latencies = np.nan_to_num(latency_array)  # replace NaNs with zeros
        clean_latencies[clean_latencies &lt; 0] = 0  # replace negative latencies with 0
        return clean_latencies[clean_latencies != 0]  # return only non-zero latencies

    def get_offset_mean(self) -&gt; Optional[float]:
        &#34;&#34;&#34;
        return the mean of all offsets, and 0.0 if the offsets or latencies are invalid.
        :return: the mean of all offsets
        &#34;&#34;&#34;
        if self.best_latency is None or self.best_offset == 0.0:
            return 0.0
        else:
            return self.offset_stats.mean_of_means()

    def get_offset_std_dev(self) -&gt; Optional[float]:
        &#34;&#34;&#34;
        return the standard deviation (std_dev) of all offsets, and 0.0 if the offsets or latencies are invalid.
        :return: the std dev of all offsets
        &#34;&#34;&#34;
        if self.best_latency is None or self.best_offset == 0.0:
            return 0.0
        else:
            return self.offset_stats.total_std_dev()

    def get_valid_offsets(self, offset_array: np.array = None) -&gt; np.array:
        &#34;&#34;&#34;
        takes valid offsets (based on bad_packets), converts NaNs to 0, then returns non-zero offsets
        :param offset_array: optional array to clean; default None
        :return: non-NaN, non-zero offsets
        &#34;&#34;&#34;
        if offset_array is None:
            if len(self.bad_packets) &gt; 0:
                valids = []
                for i in range(len(self.offsets)):
                    if i not in self.bad_packets:
                        valids.append(self.offsets[i])
                clean_offsets = np.nan_to_num(valids)  # replace NaNs with zeros
            else:
                clean_offsets = np.nan_to_num(self.offsets)
        else:
            clean_offsets = np.nan_to_num(offset_array)
        return clean_offsets[clean_offsets != 0]  # return only non-zero offsets

    def get_valid_rev_start_times(self) -&gt; np.array:
        &#34;&#34;&#34;
        return the array of valid (based on bad_packets) revised start times
        :return: array of valid revised start times
        &#34;&#34;&#34;
        if len(self.bad_packets) &gt; 0:  # return only the start times not associated with a bad packet
            valids = []
            for i in range(len(self.rev_start_times)):
                if i not in self.bad_packets:  # this is a good packet
                    valids.append(self.rev_start_times[i])
            return np.array(valids)
        else:
            return self.rev_start_times

    def get_best_rev_start_time(self) -&gt; int:
        &#34;&#34;&#34;
        return the revised start time associated with the lowest latency
        :return: revised start time in microseconds associated with the lowest latency
        &#34;&#34;&#34;
        return self.rev_start_times[self.best_latency_index]</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="redvox.api900.timesync.api900_timesync.TimeSyncData.evaluate_latencies_and_offsets"><code class="name flex">
<span>def <span class="ident">evaluate_latencies_and_offsets</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>evaluates the goodness of latencies and offsets.
adjusts rev_start_times if there is a best offset</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate_latencies_and_offsets(self):
    &#34;&#34;&#34;
    evaluates the goodness of latencies and offsets.
    adjusts rev_start_times if there is a best offset
    &#34;&#34;&#34;
    # if no decoders synced properly, all latencies are NaNs or all indices are bad
    if np.isnan(self.latencies).all() or len(self.bad_packets) == self.num_packets:
        # make everything empty or None, and best offset is 0 (no change)
        self.latencies = []
        self.offsets = []
        self.best_latency = None
        self.best_latency_index = None
        self.best_offset = 0.0
    else:
        # convert all NaN and negative values from latencies into zero
        self.latencies = np.nan_to_num(self.latencies)
        self.latencies[self.latencies &lt; 0] = 0.0
        # find and set minimum latency based on non-zero latencies
        self.best_latency = np.min(self.get_valid_latencies())
        self.latency_stats.best_value = self.best_latency
        self.best_latency_index = np.where(self.latencies == self.best_latency)[0][0]
        # find all non-NaN, non-zero offsets
        good_offsets = self.get_valid_offsets()

        if good_offsets is not None and len(good_offsets) &gt; 0:
            # there must be some good offsets; convert all NaN offsets to 0
            self.offsets = np.nan_to_num(self.offsets)
            # set best offset based on best latency
            self.best_offset = self.offsets[self.best_latency_index]
            self.offset_stats.best_value = self.best_offset
            # fix all packet start times by adding the packet&#39;s offset
            self.rev_start_times += self.best_offset
        else:
            # set offset properties to empty or None
            self.offsets = []</code></pre>
</details>
</dd>
<dt id="redvox.api900.timesync.api900_timesync.TimeSyncData.find_bad_packets"><code class="name flex">
<span>def <span class="ident">find_bad_packets</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Find bad packets and mark them using the bad_packets property
Assuming all packets have been processed and all bad packets are marked with a 0 (or are negative)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_bad_packets(self):
    &#34;&#34;&#34;
    Find bad packets and mark them using the bad_packets property
    Assuming all packets have been processed and all bad packets are marked with a 0 (or are negative)
    &#34;&#34;&#34;
    for idx in range(len(self.latencies)):  # mark bad indices (they have a 0 or less value)
        if self.latencies[idx] &lt;= 0:
            self.bad_packets.append(idx)</code></pre>
</details>
</dd>
<dt id="redvox.api900.timesync.api900_timesync.TimeSyncData.get_best_rev_start_time"><code class="name flex">
<span>def <span class="ident">get_best_rev_start_time</span></span>(<span>self) ‑> int</span>
</code></dt>
<dd>
<div class="desc"><p>return the revised start time associated with the lowest latency
:return: revised start time in microseconds associated with the lowest latency</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_best_rev_start_time(self) -&gt; int:
    &#34;&#34;&#34;
    return the revised start time associated with the lowest latency
    :return: revised start time in microseconds associated with the lowest latency
    &#34;&#34;&#34;
    return self.rev_start_times[self.best_latency_index]</code></pre>
</details>
</dd>
<dt id="redvox.api900.timesync.api900_timesync.TimeSyncData.get_latency_mean"><code class="name flex">
<span>def <span class="ident">get_latency_mean</span></span>(<span>self) ‑> Optional[float]</span>
</code></dt>
<dd>
<div class="desc"><p>return the mean of all latencies, and None if the latencies are invalid.
:return: the mean of all latencies</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_latency_mean(self) -&gt; Optional[float]:
    &#34;&#34;&#34;
    return the mean of all latencies, and None if the latencies are invalid.
    :return: the mean of all latencies
    &#34;&#34;&#34;
    if self.best_latency is None:
        return None
    else:
        return self.latency_stats.mean_of_means()</code></pre>
</details>
</dd>
<dt id="redvox.api900.timesync.api900_timesync.TimeSyncData.get_latency_std_dev"><code class="name flex">
<span>def <span class="ident">get_latency_std_dev</span></span>(<span>self) ‑> Optional[float]</span>
</code></dt>
<dd>
<div class="desc"><p>return the standard deviation (std_dev) of all latencies, and None if the latencies are invalid.
:return: the std dev of all latencies</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_latency_std_dev(self) -&gt; Optional[float]:
    &#34;&#34;&#34;
    return the standard deviation (std_dev) of all latencies, and None if the latencies are invalid.
    :return: the std dev of all latencies
    &#34;&#34;&#34;
    if self.best_latency is None:
        return None
    else:
        return self.latency_stats.total_std_dev()</code></pre>
</details>
</dd>
<dt id="redvox.api900.timesync.api900_timesync.TimeSyncData.get_offset_mean"><code class="name flex">
<span>def <span class="ident">get_offset_mean</span></span>(<span>self) ‑> Optional[float]</span>
</code></dt>
<dd>
<div class="desc"><p>return the mean of all offsets, and 0.0 if the offsets or latencies are invalid.
:return: the mean of all offsets</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_offset_mean(self) -&gt; Optional[float]:
    &#34;&#34;&#34;
    return the mean of all offsets, and 0.0 if the offsets or latencies are invalid.
    :return: the mean of all offsets
    &#34;&#34;&#34;
    if self.best_latency is None or self.best_offset == 0.0:
        return 0.0
    else:
        return self.offset_stats.mean_of_means()</code></pre>
</details>
</dd>
<dt id="redvox.api900.timesync.api900_timesync.TimeSyncData.get_offset_std_dev"><code class="name flex">
<span>def <span class="ident">get_offset_std_dev</span></span>(<span>self) ‑> Optional[float]</span>
</code></dt>
<dd>
<div class="desc"><p>return the standard deviation (std_dev) of all offsets, and 0.0 if the offsets or latencies are invalid.
:return: the std dev of all offsets</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_offset_std_dev(self) -&gt; Optional[float]:
    &#34;&#34;&#34;
    return the standard deviation (std_dev) of all offsets, and 0.0 if the offsets or latencies are invalid.
    :return: the std dev of all offsets
    &#34;&#34;&#34;
    if self.best_latency is None or self.best_offset == 0.0:
        return 0.0
    else:
        return self.offset_stats.total_std_dev()</code></pre>
</details>
</dd>
<dt id="redvox.api900.timesync.api900_timesync.TimeSyncData.get_ratio_bad_packets"><code class="name flex">
<span>def <span class="ident">get_ratio_bad_packets</span></span>(<span>self) ‑> float</span>
</code></dt>
<dd>
<div class="desc"><p>Return the ratio of packets with bad latency calculations over total packets
:return: num packets with bad latency calculations / total packets</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_ratio_bad_packets(self) -&gt; float:
    &#34;&#34;&#34;
    Return the ratio of packets with bad latency calculations over total packets
    :return: num packets with bad latency calculations / total packets
    &#34;&#34;&#34;
    if self.num_packets &lt; 1:
        return 0
    return len(self.bad_packets) / float(self.num_packets)</code></pre>
</details>
</dd>
<dt id="redvox.api900.timesync.api900_timesync.TimeSyncData.get_time_sync_data"><code class="name flex">
<span>def <span class="ident">get_time_sync_data</span></span>(<span>self, wrapped_packets: List[<a title="redvox.api900.wrapped_redvox_packet.WrappedRedvoxPacket" href="../wrapped_redvox_packet.html#redvox.api900.wrapped_redvox_packet.WrappedRedvoxPacket">WrappedRedvoxPacket</a>])</span>
</code></dt>
<dd>
<div class="desc"><p>Sets the time statistics between machine, time server, and acquisition server for the packets given.
:param wrapped_packets: wrapped packets with same sample rate</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_time_sync_data(self, wrapped_packets: List[WrappedRedvoxPacket]):
    &#34;&#34;&#34;
    Sets the time statistics between machine, time server, and acquisition server for the packets given.
    :param wrapped_packets: wrapped packets with same sample rate
    &#34;&#34;&#34;
    self.server_acquisition_times = np.zeros(len(wrapped_packets))  # array of server acquisition times
    self.rev_start_times = np.zeros(len(wrapped_packets))   # array of app start times
    self.num_tri_messages = np.zeros(len(wrapped_packets))  # number of tri-message exchanges per packet
    self.latencies = np.zeros(len(wrapped_packets))  # array of minimum latencies
    self.offsets = np.zeros(len(wrapped_packets))  # array of offset applied to machine time to get sync time
    self.num_packets = len(wrapped_packets)  # number of packets in list
    self.tri_message_coeffs = []    # a list of tri-message coefficients
    self.best_tri_msg_indices = []  # a list of the best latency index in each set of tri-message coefficients
    self.bad_packets = []   # list of packets that contain invalid data
    sample_rates = np.zeros(len(wrapped_packets))       # list of sample rates, should all be the same
    mach_time_zeros = np.zeros(len(wrapped_packets))    # list of mach time zeros, should all the be same

    # get the server acquisition time, app start time, and tri message stats
    for i, wrapped_packet in enumerate(wrapped_packets):
        # pass the mach_time_zero and sample_rate into arrays
        sample_rates[i] = wrapped_packet.microphone_sensor().sample_rate_hz()
        mach_time_zeros[i] = wrapped_packet.mach_time_zero()
        self.server_acquisition_times[i] = wrapped_packet.server_timestamp_epoch_microseconds_utc()
        self.rev_start_times[i] = wrapped_packet.app_file_start_timestamp_epoch_microseconds_utc()
        self._compute_tri_message_stats(wrapped_packet, i)

    # check sample rate and mach time zero (if it exists) for changes.  if it changed, sync will not work.
    if not self._validate_sensor_settings(sample_rates, mach_time_zeros):
        raise Exception(&#34;ERROR: Sensor settings changed; separate data based on changes and re-analyze&#34;)
    self.find_bad_packets()
    self.evaluate_latencies_and_offsets()
    # set the packet duration
    self.packet_duration = dt.seconds_to_microseconds(fh.get_duration_seconds_from_sample_rate(
        int(self.sample_rate_hz)))
    # apply duration to app start to get packet end time, then subtract
    # that from server acquire time to get travel time to acquisition server
    # ASSUMING that acquisition and time-sync server have the same time source
    self.acquire_travel_time = self.server_acquisition_times - (self.rev_start_times + self.packet_duration)</code></pre>
</details>
</dd>
<dt id="redvox.api900.timesync.api900_timesync.TimeSyncData.get_valid_latencies"><code class="name flex">
<span>def <span class="ident">get_valid_latencies</span></span>(<span>self, latency_array: <built-in function array> = None) ‑> <built-in function array></span>
</code></dt>
<dd>
<div class="desc"><p>takes latencies, converts NaNs and negatives to 0, then returns non-zero latencies
:param latency_array: optional array to clean instead of self.latencies; default None
:return: non-NaN, non-zero latencies</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_valid_latencies(self, latency_array: np.array = None) -&gt; np.array:
    &#34;&#34;&#34;
    takes latencies, converts NaNs and negatives to 0, then returns non-zero latencies
    :param latency_array: optional array to clean instead of self.latencies; default None
    :return: non-NaN, non-zero latencies
    &#34;&#34;&#34;
    if latency_array is None:
        clean_latencies = np.nan_to_num(self.latencies)  # replace NaNs with zeros
    else:
        clean_latencies = np.nan_to_num(latency_array)  # replace NaNs with zeros
    clean_latencies[clean_latencies &lt; 0] = 0  # replace negative latencies with 0
    return clean_latencies[clean_latencies != 0]  # return only non-zero latencies</code></pre>
</details>
</dd>
<dt id="redvox.api900.timesync.api900_timesync.TimeSyncData.get_valid_offsets"><code class="name flex">
<span>def <span class="ident">get_valid_offsets</span></span>(<span>self, offset_array: <built-in function array> = None) ‑> <built-in function array></span>
</code></dt>
<dd>
<div class="desc"><p>takes valid offsets (based on bad_packets), converts NaNs to 0, then returns non-zero offsets
:param offset_array: optional array to clean; default None
:return: non-NaN, non-zero offsets</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_valid_offsets(self, offset_array: np.array = None) -&gt; np.array:
    &#34;&#34;&#34;
    takes valid offsets (based on bad_packets), converts NaNs to 0, then returns non-zero offsets
    :param offset_array: optional array to clean; default None
    :return: non-NaN, non-zero offsets
    &#34;&#34;&#34;
    if offset_array is None:
        if len(self.bad_packets) &gt; 0:
            valids = []
            for i in range(len(self.offsets)):
                if i not in self.bad_packets:
                    valids.append(self.offsets[i])
            clean_offsets = np.nan_to_num(valids)  # replace NaNs with zeros
        else:
            clean_offsets = np.nan_to_num(self.offsets)
    else:
        clean_offsets = np.nan_to_num(offset_array)
    return clean_offsets[clean_offsets != 0]  # return only non-zero offsets</code></pre>
</details>
</dd>
<dt id="redvox.api900.timesync.api900_timesync.TimeSyncData.get_valid_rev_start_times"><code class="name flex">
<span>def <span class="ident">get_valid_rev_start_times</span></span>(<span>self) ‑> <built-in function array></span>
</code></dt>
<dd>
<div class="desc"><p>return the array of valid (based on bad_packets) revised start times
:return: array of valid revised start times</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_valid_rev_start_times(self) -&gt; np.array:
    &#34;&#34;&#34;
    return the array of valid (based on bad_packets) revised start times
    :return: array of valid revised start times
    &#34;&#34;&#34;
    if len(self.bad_packets) &gt; 0:  # return only the start times not associated with a bad packet
        valids = []
        for i in range(len(self.rev_start_times)):
            if i not in self.bad_packets:  # this is a good packet
                valids.append(self.rev_start_times[i])
        return np.array(valids)
    else:
        return self.rev_start_times</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="redvox.api900.timesync" href="index.html">redvox.api900.timesync</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="redvox.api900.timesync.api900_timesync.sync_packet_time_900" href="#redvox.api900.timesync.api900_timesync.sync_packet_time_900">sync_packet_time_900</a></code></li>
<li><code><a title="redvox.api900.timesync.api900_timesync.update_evenly_sampled_time_array" href="#redvox.api900.timesync.api900_timesync.update_evenly_sampled_time_array">update_evenly_sampled_time_array</a></code></li>
<li><code><a title="redvox.api900.timesync.api900_timesync.update_time_array" href="#redvox.api900.timesync.api900_timesync.update_time_array">update_time_array</a></code></li>
<li><code><a title="redvox.api900.timesync.api900_timesync.validate_sensors" href="#redvox.api900.timesync.api900_timesync.validate_sensors">validate_sensors</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="redvox.api900.timesync.api900_timesync.TimeSyncData" href="#redvox.api900.timesync.api900_timesync.TimeSyncData">TimeSyncData</a></code></h4>
<ul class="">
<li><code><a title="redvox.api900.timesync.api900_timesync.TimeSyncData.evaluate_latencies_and_offsets" href="#redvox.api900.timesync.api900_timesync.TimeSyncData.evaluate_latencies_and_offsets">evaluate_latencies_and_offsets</a></code></li>
<li><code><a title="redvox.api900.timesync.api900_timesync.TimeSyncData.find_bad_packets" href="#redvox.api900.timesync.api900_timesync.TimeSyncData.find_bad_packets">find_bad_packets</a></code></li>
<li><code><a title="redvox.api900.timesync.api900_timesync.TimeSyncData.get_best_rev_start_time" href="#redvox.api900.timesync.api900_timesync.TimeSyncData.get_best_rev_start_time">get_best_rev_start_time</a></code></li>
<li><code><a title="redvox.api900.timesync.api900_timesync.TimeSyncData.get_latency_mean" href="#redvox.api900.timesync.api900_timesync.TimeSyncData.get_latency_mean">get_latency_mean</a></code></li>
<li><code><a title="redvox.api900.timesync.api900_timesync.TimeSyncData.get_latency_std_dev" href="#redvox.api900.timesync.api900_timesync.TimeSyncData.get_latency_std_dev">get_latency_std_dev</a></code></li>
<li><code><a title="redvox.api900.timesync.api900_timesync.TimeSyncData.get_offset_mean" href="#redvox.api900.timesync.api900_timesync.TimeSyncData.get_offset_mean">get_offset_mean</a></code></li>
<li><code><a title="redvox.api900.timesync.api900_timesync.TimeSyncData.get_offset_std_dev" href="#redvox.api900.timesync.api900_timesync.TimeSyncData.get_offset_std_dev">get_offset_std_dev</a></code></li>
<li><code><a title="redvox.api900.timesync.api900_timesync.TimeSyncData.get_ratio_bad_packets" href="#redvox.api900.timesync.api900_timesync.TimeSyncData.get_ratio_bad_packets">get_ratio_bad_packets</a></code></li>
<li><code><a title="redvox.api900.timesync.api900_timesync.TimeSyncData.get_time_sync_data" href="#redvox.api900.timesync.api900_timesync.TimeSyncData.get_time_sync_data">get_time_sync_data</a></code></li>
<li><code><a title="redvox.api900.timesync.api900_timesync.TimeSyncData.get_valid_latencies" href="#redvox.api900.timesync.api900_timesync.TimeSyncData.get_valid_latencies">get_valid_latencies</a></code></li>
<li><code><a title="redvox.api900.timesync.api900_timesync.TimeSyncData.get_valid_offsets" href="#redvox.api900.timesync.api900_timesync.TimeSyncData.get_valid_offsets">get_valid_offsets</a></code></li>
<li><code><a title="redvox.api900.timesync.api900_timesync.TimeSyncData.get_valid_rev_start_times" href="#redvox.api900.timesync.api900_timesync.TimeSyncData.get_valid_rev_start_times">get_valid_rev_start_times</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>