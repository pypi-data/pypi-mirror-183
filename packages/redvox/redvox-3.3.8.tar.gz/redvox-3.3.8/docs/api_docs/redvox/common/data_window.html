<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>redvox.common.data_window API documentation</title>
<meta name="description" content="This module creates specific time-bounded segments of data for users
combines the base data files into a single composite object based on the user â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>redvox.common.data_window</code></h1>
</header>
<section id="section-intro">
<p>This module creates specific time-bounded segments of data for users
combines the base data files into a single composite object based on the user parameters</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This module creates specific time-bounded segments of data for users
combines the base data files into a single composite object based on the user parameters
&#34;&#34;&#34;
from pathlib import Path
from typing import Optional, Set, List, Dict, Iterable
from datetime import timedelta
import shutil
import os
import inspect
from redvox.common import run_me

import pprint
import multiprocessing
import multiprocessing.pool
import numpy as np
import pyarrow as pa

import redvox
from redvox.common import date_time_utils as dtu
from redvox.common.date_time_utils import (
    datetime_to_epoch_microseconds_utc as us_dt,
)
from redvox.common import io
from redvox.common import data_window_io as dw_io
from redvox.common.data_window_configuration import DataWindowConfigFile
from redvox.common.parallel_utils import maybe_parallel_map
from redvox.common.station import Station
from redvox.common.sensor_data import SensorType, SensorData
from redvox.common.api_reader_dw import ApiReaderDw
from redvox.common import gap_and_pad_utils as gpu
from redvox.common.errors import RedVoxExceptions

DEFAULT_START_BUFFER_TD: timedelta = timedelta(minutes=2.0)  # default padding to start time of data
DEFAULT_END_BUFFER_TD: timedelta = timedelta(minutes=2.0)  # default padding to end time of data
# minimum default length of time in seconds for data to be off by to be considered suspicious
DATA_DROP_DURATION_S: float = 0.2


class EventOrigin:
    &#34;&#34;&#34;
    The origin event&#39;s latitude, longitude, altitude and their standard deviations, the device used to measure
    the location data and the radius of the event

    Properties:
        provider: str, source of the location data (i.e. &#34;GPS&#34; or &#34;NETWORK&#34;), default &#34;UNKNOWN&#34;

        latitude: float, best estimate of latitude in degrees, default np.nan

        latitude_std: float, standard deviation of best estimate of latitude, default np.nan

        longitude: float, best estimate of longitude in degrees, default np.nan

        longitude_std: float, standard deviation of best estimate of longitude, default np.nan

        altitude: float, best estimate of altitude in meters, default np.nan

        altitude_std: float, standard deviation of best estimate of altitude, default np.nan

        event_radius_m: float, radius of event in meters, default 0.0
    &#34;&#34;&#34;
    def __init__(self,
                 provider: str = &#34;UNKNOWN&#34;,
                 lat: float = np.nan,
                 lat_std: float = np.nan,
                 lon: float = np.nan,
                 lon_std: float = np.nan,
                 alt: float = np.nan,
                 alt_std: float = np.nan,
                 event_radius_m: float = 0.0):
        &#34;&#34;&#34;
        :param provider: name of device that provided the information
        :param lat: latitude in +/- degrees
        :param lat_std: standard deviation of latitude
        :param lon: longitude in +/- degrees
        :param lon_std: standard deviation of longitude
        :param alt: altitude in meters
        :param alt_std: standard deviation of altitude
        :param event_radius_m: radius of event in meters
        &#34;&#34;&#34;
        self.provider = provider
        self.latitude = lat
        self.longitude = lon
        self.altitude = alt
        self.latitude_std = lat_std
        self.longitude_std = lon_std
        self.altitude_std = alt_std
        self.event_radius_m = event_radius_m

    def __repr__(self):
        return str(self.as_dict())

    def __str__(self):
        return str(self.as_dict())

    def as_dict(self) -&gt; Dict:
        &#34;&#34;&#34;
        :return: self as dict
        &#34;&#34;&#34;
        return {
            &#34;provider&#34;: self.provider,
            &#34;latitude&#34;: self.latitude,
            &#34;latitude_std&#34;: self.latitude_std,
            &#34;longitude&#34;: self.longitude,
            &#34;longitude_std&#34;: self.longitude_std,
            &#34;altitude&#34;: self.altitude,
            &#34;altitude_std&#34;: self.altitude_std,
            &#34;event_radius_m&#34;: self.event_radius_m
        }

    @staticmethod
    def from_dict(data_dict: Dict) -&gt; &#34;EventOrigin&#34;:
        return EventOrigin(data_dict[&#34;provider&#34;], data_dict[&#34;latitude&#34;], data_dict[&#34;latitude_std&#34;],
                           data_dict[&#34;longitude&#34;], data_dict[&#34;longitude_std&#34;], data_dict[&#34;altitude&#34;],
                           data_dict[&#34;altitude_std&#34;], data_dict[&#34;event_radius_m&#34;])


class DataWindowConfig:
    &#34;&#34;&#34;
    Properties:
        input_dir: str, the directory that contains all the data.  REQUIRED

        structured_layout: bool, if True, the input_dir contains specially named and organized
        directories of data.  Default True

        start_datetime: optional datetime, start datetime of the window.
        If None, uses the first timestamp of the filtered data.  Default None

        end_datetime: optional datetime, non-inclusive end datetime of the window.
        If None, uses the last timestamp of the filtered data + 1.  Default None

        start_buffer_td: timedelta, the amount of time to include before the start_datetime when filtering data.
        Negative values are converted to 0.  Default DEFAULT_START_BUFFER_TD (2 minutes)

        end_buffer_td: timedelta, the amount of time to include after the end_datetime when filtering data.
        Negative values are converted to 0.  Default DEFAULT_END_BUFFER_TD (2 minutes)

        drop_time_s: float, the minimum amount of seconds between data files that would indicate a gap.
        Negative values are converted to default value.  Default DATA_DROP_DURATION_S (0.2 seconds)

        station_ids: optional set of strings, representing the station ids to filter on.
        If empty or None, get any ids found in the input directory.  Default None

        extensions: optional set of strings, representing file extensions to filter on.
        If None, gets as much data as it can in the input directory.  Default None

        api_versions: optional set of ApiVersions, representing api versions to filter on.
        If None, get as much data as it can in the input directory.  Default None

        apply_correction: bool, if True, update the timestamps in the data based on best station offset.  Default True

        copy_edge_points: enumeration of DataPointCreationMode.  Determines how new points are created.
        Valid values are NAN, COPY, and INTERPOLATE.  Default COPY

        use_model_correction: bool, if True, use the offset model&#39;s correction functions, otherwise use the best
        offset.  Default True
    &#34;&#34;&#34;
    def __init__(
            self,
            input_dir: str,
            structured_layout: bool = True,
            start_datetime: Optional[dtu.datetime] = None,
            end_datetime: Optional[dtu.datetime] = None,
            start_buffer_td: timedelta = DEFAULT_START_BUFFER_TD,
            end_buffer_td: timedelta = DEFAULT_END_BUFFER_TD,
            drop_time_s: float = DATA_DROP_DURATION_S,
            station_ids: Optional[Iterable[str]] = None,
            extensions: Optional[Set[str]] = None,
            api_versions: Optional[Set[io.ApiVersion]] = None,
            apply_correction: bool = True,
            use_model_correction: bool = True,
            copy_edge_points: gpu.DataPointCreationMode = gpu.DataPointCreationMode.COPY,
    ):
        self.input_dir: str = input_dir
        self.structured_layout: bool = structured_layout
        self.start_datetime: Optional[dtu.datetime] = start_datetime
        self.end_datetime: Optional[dtu.datetime] = end_datetime
        self.start_buffer_td: timedelta = start_buffer_td if start_buffer_td &gt; timedelta(seconds=0) \
            else timedelta(seconds=0)
        self.end_buffer_td: timedelta = end_buffer_td if end_buffer_td &gt; timedelta(seconds=0) \
            else timedelta(seconds=0)
        self.drop_time_s: float = drop_time_s if drop_time_s &gt; 0 else DATA_DROP_DURATION_S
        self.station_ids: Optional[Set[str]] = set(station_ids) if station_ids else None
        self.extensions: Optional[Set[str]] = extensions
        self.api_versions: Optional[Set[io.ApiVersion]] = api_versions
        self.apply_correction: bool = apply_correction
        self.use_model_correction = use_model_correction
        self.copy_edge_points = copy_edge_points

    def __repr__(self):
        return f&#34;input_dir: {self.input_dir}, &#34; \
               f&#34;structured_layout: {self.structured_layout}, &#34; \
               f&#34;start_datetime: {self.start_datetime.__repr__()}, &#34; \
               f&#34;end_datetime: {self.end_datetime.__repr__()}, &#34; \
               f&#34;start_buffer_td: {self.start_buffer_td.__repr__()}, &#34; \
               f&#34;end_buffer_td: {self.end_buffer_td.__repr__()}, &#34; \
               f&#34;drop_time_s: {self.drop_time_s}, &#34; \
               f&#34;station_ids: {list(self.station_ids) if self.station_ids else []}, &#34; \
               f&#34;extensions: {list(self.extensions) if self.extensions else []}, &#34; \
               f&#34;api_versions: {[a_v.value for a_v in self.api_versions] if self.api_versions else []}, &#34; \
               f&#34;apply_correction: {self.apply_correction}, &#34; \
               f&#34;use_model_correction: {self.use_model_correction}, &#34; \
               f&#34;copy_edge_points: {self.copy_edge_points.value}&#34;

    def __str__(self):
        return f&#34;input_dir: {self.input_dir}, &#34; \
               f&#34;structured_layout: {self.structured_layout}, &#34; \
               f&#34;start_datetime: &#34; \
               f&#34;{self.start_datetime.strftime(&#39;%Y-%m-%dT%H:%M:%S.%fZ&#39;) if self.start_datetime else None}, &#34; \
               f&#34;end_datetime: {self.end_datetime.strftime(&#39;%Y-%m-%dT%H:%M:%S.%fZ&#39;) if self.end_datetime else None}, &#34; \
               f&#34;start_buffer_td (in s): {self.start_buffer_td.total_seconds()}, &#34; \
               f&#34;end_buffer_td (in s): {self.end_buffer_td.total_seconds()}, &#34; \
               f&#34;drop_time_s: {self.drop_time_s}, &#34; \
               f&#34;station_ids: {list(self.station_ids) if self.station_ids else []}, &#34; \
               f&#34;extensions: {list(self.extensions) if self.extensions else []}, &#34; \
               f&#34;api_versions: {[a_v.value for a_v in self.api_versions] if self.api_versions else []}, &#34; \
               f&#34;apply_correction: {self.apply_correction}, &#34; \
               f&#34;use_model_correction: {self.use_model_correction}, &#34; \
               f&#34;copy_edge_points: {self.copy_edge_points.name}&#34;

    def as_dict(self) -&gt; Dict:
        return {&#34;input_dir&#34;: self.input_dir,
                &#34;structured_layout&#34;: self.structured_layout,
                &#34;start_datetime&#34;: us_dt(self.start_datetime),
                &#34;end_datetime&#34;: us_dt(self.end_datetime),
                &#34;start_buffer_td&#34;: self.start_buffer_td.total_seconds(),
                &#34;end_buffer_td&#34;: self.end_buffer_td.total_seconds(),
                &#34;drop_time_s&#34;: self.drop_time_s,
                &#34;station_ids&#34;: list(self.station_ids) if self.station_ids else [],
                &#34;extensions&#34;: list(self.extensions) if self.extensions else [],
                &#34;api_versions&#34;: [a_v.value for a_v in self.api_versions] if self.api_versions else [],
                &#34;apply_correction&#34;: self.apply_correction,
                &#34;use_model_correction&#34;: self.use_model_correction,
                &#34;copy_edge_points&#34;: self.copy_edge_points.value
                }

    @staticmethod
    def from_dict(data_dict: Dict) -&gt; &#34;DataWindowConfig&#34;:
        return DataWindowConfig(data_dict[&#34;input_dir&#34;], data_dict[&#34;structured_layout&#34;],
                                dtu.datetime_from_epoch_microseconds_utc(data_dict[&#34;start_datetime&#34;]),
                                dtu.datetime_from_epoch_microseconds_utc(data_dict[&#34;end_datetime&#34;]),
                                timedelta(seconds=data_dict[&#34;start_buffer_td&#34;]),
                                timedelta(seconds=data_dict[&#34;end_buffer_td&#34;]),
                                data_dict[&#34;drop_time_s&#34;], data_dict[&#34;station_ids&#34;], set(data_dict[&#34;extensions&#34;]),
                                set([io.ApiVersion.from_str(v) for v in data_dict[&#34;api_versions&#34;]]),
                                data_dict[&#34;apply_correction&#34;], data_dict[&#34;use_model_correction&#34;],
                                gpu.DataPointCreationMode(data_dict[&#34;copy_edge_points&#34;])
                                )


class DataWindow:
    &#34;&#34;&#34;
    Holds the data for a given time window; adds interpolated timestamps to fill gaps and pad start and end values

    Properties:
        event_name: str, name of the DataWindow.  defaults to &#34;dw&#34;

        event_origin: Optional EventOrigin which describes the physical location and radius of the
        origin event.  Default empty EventOrigin (no valid data)

        config: optional DataWindowConfig with information on how to construct DataWindow from
        Redvox (.rdvx*) files.  Default None

        sdk_version: str, the version of the Redvox SDK used to create the DataWindow

        debug: bool, if True, outputs additional information during initialization. Default False

    Protected:
        _fs_writer: DataWindowFileSystemWriter; includes event_name, output directory (Default &#34;.&#34;),
        output type (options: &#34;PARQUET&#34;, &#34;LZ4&#34;, &#34;NONE&#34;.  Default NONE), and option to make a
        runme.py example file (Default False)

        _stations: List of Stations that belong to the DataWindow

        _errors: RedVoxExceptions; contains a list of all errors encountered by the DataWindow
    &#34;&#34;&#34;
    def __init__(
            self,
            event_name: str = &#34;dw&#34;,
            event_origin: Optional[EventOrigin] = None,
            config: Optional[DataWindowConfig] = None,
            output_dir: str = &#34;.&#34;,
            out_type: str = &#34;NONE&#34;,
            make_runme: bool = False,
            debug: bool = False,
    ):
        &#34;&#34;&#34;
        Initialize the DataWindow

        :param event_name: name of the DataWindow.  defaults to &#34;dw&#34;
        :param event_origin: Optional EventOrigin which describes the physical location and radius of the
                                origin event.  Default empty EventOrigin (no valid data)
        :param config: Optional DataWindowConfig which describes how to extract data from Redvox files.
                        Default None
        :param output_dir: output directory for saving files.  Default &#34;.&#34; (current directory)
        :param out_type: type of file to save the DataWindow as.  Options: &#34;PARQUET&#34;, &#34;LZ4&#34;, &#34;NONE&#34;.
                            Default &#34;NONE&#34; (no saving)
        :param make_runme: if True, saves an example runme.py file with the data.  Default False
        :param debug: if True, outputs additional information during initialization.  Default False
        &#34;&#34;&#34;
        self.event_name: str = event_name
        self.event_origin: EventOrigin = event_origin if event_origin else EventOrigin()
        self._fs_writer = dw_io.DataWindowFileSystemWriter(self.event_name, out_type, output_dir, make_runme)
        self.debug: bool = debug
        self._sdk_version: str = redvox.VERSION
        self._errors = RedVoxExceptions(&#34;DataWindow&#34;)
        self._stations: List[Station] = []
        self._config = config
        if config:
            if config.start_datetime and config.end_datetime and (config.end_datetime &lt;= config.start_datetime):
                self._errors.append(&#34;DataWindow will not work when end datetime is before or equal to start datetime.\n&#34;
                                    f&#34;Your times: {config.end_datetime} &lt;= {config.start_datetime}&#34;)
            else:
                self.create_data_window()
        if self.debug:
            self.print_errors()

    def __repr__(self):
        return f&#34;event_name: {self.event_name}, &#34; \
               f&#34;event_origin: {self.event_origin.__repr__()}, &#34; \
               f&#34;config: {self._config.__repr__()}, &#34; \
               f&#34;output_dir: {os.path.abspath(self.save_dir())}, &#34; \
               f&#34;out_type: {self._fs_writer.file_extension}, &#34; \
               f&#34;make_runme: {self._fs_writer.make_run_me}, &#34; \
               f&#34;sdk_version: {self._sdk_version}, &#34; \
               f&#34;debug: {self.debug}&#34;

    def __str__(self):
        return f&#34;event_name: {self.event_name}, &#34; \
               f&#34;event_origin: {self.event_origin.__str__()}, &#34; \
               f&#34;config: {self._config.__str__()}, &#34; \
               f&#34;output_dir: {os.path.abspath(self.save_dir())}, &#34; \
               f&#34;out_type: {self._fs_writer.file_extension}, &#34; \
               f&#34;make_runme: {self._fs_writer.make_run_me}, &#34; \
               f&#34;sdk_version: {self._sdk_version}, &#34; \
               f&#34;debug: {self.debug}&#34;
        # &#34;stations&#34;: [s.__str__() for s in self._stations],

    def save_dir(self) -&gt; str:
        &#34;&#34;&#34;
        :return: directory data is saved to (empty string means saving to memory)
        &#34;&#34;&#34;
        return self._fs_writer.save_dir()

    def set_save_dir(self, new_save_dir: Optional[str] = &#34;.&#34;):
        &#34;&#34;&#34;
        :param new_save_dir: directory to save data to; default current directory, or &#34;.&#34;
        &#34;&#34;&#34;
        self._fs_writer.base_dir = new_save_dir

    def is_make_runme(self) -&gt; bool:
        &#34;&#34;&#34;
        :return: if DataWindow will be saved with a runme file
        &#34;&#34;&#34;
        return self._fs_writer.make_run_me

    def set_make_runme(self, make_runme: bool = False):
        &#34;&#34;&#34;
        :param make_runme: if True, DataWindow will create a runme file when saved.  Default False
        &#34;&#34;&#34;
        self._fs_writer.make_run_me = make_runme

    def fs_writer(self) -&gt; dw_io.DataWindowFileSystemWriter:
        &#34;&#34;&#34;
        :return: DataWindowFileSystemWriter for DataWindow
        &#34;&#34;&#34;
        return self._fs_writer

    def out_type(self) -&gt; str:
        &#34;&#34;&#34;
        :return: string of the output type of the DataWindow
        &#34;&#34;&#34;
        return self._fs_writer.file_extension

    def set_out_type(self, new_out_type: str):
        &#34;&#34;&#34;
        set the output type of the DataWindow.  options are &#34;NONE&#34;, &#34;PARQUET&#34; and &#34;LZ4&#34;.  invalid values become &#34;NONE&#34;

        :param new_out_type: new output type of the DataWindow
        &#34;&#34;&#34;
        self._fs_writer.set_extension(new_out_type)

    def as_dict(self) -&gt; Dict:
        &#34;&#34;&#34;
        :return: DataWindow properties as dictionary
        &#34;&#34;&#34;
        return {&#34;event_name&#34;: self.event_name,
                &#34;event_origin&#34;: self.event_origin.as_dict(),
                &#34;start_time&#34;: self.start_date(),
                &#34;end_time&#34;: self.end_date(),
                &#34;base_dir&#34;: self.save_dir(),
                &#34;stations&#34;: [s.default_station_json_file_name() for s in self._stations],
                &#34;config&#34;: self._config.as_dict(),
                &#34;debug&#34;: self.debug,
                &#34;errors&#34;: self._errors.as_dict(),
                &#34;sdk_version&#34;: self._sdk_version,
                &#34;out_type&#34;: self._fs_writer.file_extension,
                &#34;make_runme&#34;: self._fs_writer.make_run_me
                }

    def pretty(self) -&gt; str:
        &#34;&#34;&#34;
        :return: DataWindow as dictionary, but easier to read
        &#34;&#34;&#34;
        # noinspection Mypy
        return pprint.pformat(self.as_dict())

    @staticmethod
    def from_config(config: DataWindowConfigFile) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        Use a config file to create a DataWindow

        :param config: DataWindowConfigFile to load from
        :return: DataWindow
        &#34;&#34;&#34;
        event_origin = EventOrigin(config.origin_provider, config.origin_latitude, config.origin_latitude_std,
                                   config.origin_longitude, config.origin_longitude_std, config.origin_altitude,
                                   config.origin_altitude_std, config.origin_event_radius_m)
        dw_config = DataWindowConfig(config.input_directory, config.structured_layout, config.start_dt(),
                                     config.end_dt(), config.start_buffer_td(), config.end_buffer_td(),
                                     config.drop_time_seconds, config.station_ids, config.extensions,
                                     config.api_versions, config.apply_correction, config.use_model_correction,
                                     config.copy_edge_points())
        return DataWindow(config.event_name, event_origin, dw_config, config.output_dir, config.output_type,
                          config.make_runme, config.debug)

    @staticmethod
    def from_config_file(file: str) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        Loads a configuration file to create the DataWindow

        :param file: full path to config file
        :return: DataWindow
        &#34;&#34;&#34;
        return DataWindow.from_config(DataWindowConfigFile.from_path(file))

    @staticmethod
    def deserialize(path: str) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        Decompresses and deserializes a DataWindow written to disk.

        :param path: Path to the serialized and compressed DataWindow.
        :return: An instance of a DataWindow.
        &#34;&#34;&#34;
        return dw_io.deserialize_data_window(path)

    def serialize(self, compression_factor: int = 4) -&gt; Path:
        &#34;&#34;&#34;
        Serializes and compresses this DataWindow to a file.
        Uses the event_name and out_dir to name the file.

        :param compression_factor: A value between 1 and 12. Higher values provide better compression, but take
        longer. (default=4).
        :return: The path to the written file.
        &#34;&#34;&#34;
        return dw_io.serialize_data_window(self, self.save_dir(), f&#34;{self.event_name}.pkl.lz4&#34;, compression_factor)

    def _to_json_file(self) -&gt; Path:
        &#34;&#34;&#34;
        Converts the DataWindow metadata into a JSON file and compresses the DataWindow and writes it to disk.

        :return: The path to the written file
        &#34;&#34;&#34;
        return dw_io.data_window_to_json(self, self.save_dir())

    def to_json(self) -&gt; str:
        &#34;&#34;&#34;
        :return: The DataWindow metadata into a JSON string.
        &#34;&#34;&#34;
        return dw_io.data_window_as_json(self)

    @staticmethod
    def from_json(json_str: str) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        Read the DataWindow from a JSON string.  If file is improperly formatted, raises a ValueError.

        :param json_str: the JSON to read
        :return: The DataWindow as defined by the JSON
        &#34;&#34;&#34;
        return DataWindow.from_json_dict(dw_io.json_to_dict(json_str))

    @staticmethod
    def from_json_dict(json_dict: Dict) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        Reads a JSON dictionary and loads the data into the DataWindow.
        If dictionary is improperly formatted, raises a ValueError.

        :param json_dict: the dictionary to read
        :return: The DataWindow as defined by the JSON
        &#34;&#34;&#34;
        if &#34;out_type&#34; not in json_dict.keys() \
                or json_dict[&#34;out_type&#34;].upper() not in dw_io.DataWindowOutputType.list_names():
            raise ValueError(&#39;Dictionary loading type is invalid or unknown.  &#39;
                             &#39;Check the value &#34;out_type&#34;; it must be one of: &#39;
                             f&#39;{dw_io.DataWindowOutputType.list_non_none_names()}&#39;)
        else:
            out_type = dw_io.DataWindowOutputType.str_to_type(json_dict[&#34;out_type&#34;])
            if out_type == dw_io.DataWindowOutputType.PARQUET:
                dwin = DataWindow(json_dict[&#34;event_name&#34;], EventOrigin.from_dict(json_dict[&#34;event_origin&#34;]),
                                  None, json_dict[&#34;base_dir&#34;], json_dict[&#34;out_type&#34;], json_dict[&#34;make_runme&#34;],
                                  json_dict[&#34;debug&#34;])
                dwin._config = DataWindowConfig.from_dict(json_dict[&#34;config&#34;])
                dwin._errors = RedVoxExceptions.from_dict(json_dict[&#34;errors&#34;])
                dwin._sdk_version = json_dict[&#34;sdk_version&#34;]
                for st in json_dict[&#34;stations&#34;]:
                    dwin.add_station(Station.from_json_file(os.path.join(json_dict[&#34;base_dir&#34;], st), f&#34;{st}.json&#34;))
            elif out_type == dw_io.DataWindowOutputType.LZ4:
                dwin = DataWindow.deserialize(os.path.join(json_dict[&#34;base_dir&#34;],
                                                           f&#34;{json_dict[&#39;event_name&#39;]}.pkl.lz4&#34;))
            else:
                dwin = DataWindow()
            return dwin

    def save(self) -&gt; Path:
        &#34;&#34;&#34;
        save the DataWindow to disk if saving is enabled
        if saving is not enabled, adds an error to the DataWindow and returns an empty path.

        :return: the path to where the files exist; an empty path means no files were saved
        &#34;&#34;&#34;
        if self._fs_writer.is_save_disk():
            if self._fs_writer.is_use_disk() and self._fs_writer.make_run_me:
                shutil.copyfile(os.path.abspath(inspect.getfile(run_me)),
                                os.path.join(self._fs_writer.save_dir(), &#34;runme.py&#34;))
            if self._fs_writer.file_extension == &#34;parquet&#34;:
                return self._to_json_file()
            elif self._fs_writer.file_extension == &#34;lz4&#34;:
                return self.serialize()
        else:
            self._errors.append(&#34;Saving not enabled.&#34;)
            print(&#34;WARNING: Cannot save data window without knowing extension.&#34;)
            return Path()

    @staticmethod
    def load(file_path: str) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        load from json metadata and lz4 compressed file or directory of files

        :param file_path: full path of file to load
        :return: DataWindow from json metadata
        &#34;&#34;&#34;
        cur_path = os.getcwd()
        os.chdir(os.path.dirname(file_path))
        result = DataWindow.from_json_dict(dw_io.json_file_to_data_window(file_path))
        os.chdir(cur_path)
        return result

    def config(self) -&gt; DataWindowConfig:
        &#34;&#34;&#34;
        :return: settings used to create the DataWindow
        &#34;&#34;&#34;
        return self._config

    def sdk_version(self) -&gt; str:
        &#34;&#34;&#34;
        :return: sdk version used to create the DataWindow
        &#34;&#34;&#34;
        return self._sdk_version

    def set_sdk_version(self, version: str):
        &#34;&#34;&#34;
        :param version: the sdk version to set
        &#34;&#34;&#34;
        self._sdk_version = version

    def start_date(self) -&gt; float:
        &#34;&#34;&#34;
        :return: minimum start timestamp of the data or np.nan if no data
        &#34;&#34;&#34;
        if len(self._stations) &gt; 0:
            return np.min([s.first_data_timestamp() for s in self._stations])
        return np.nan

    def end_date(self) -&gt; float:
        &#34;&#34;&#34;
        :return: maximum end timestamp of the data or np.nan if no data
        &#34;&#34;&#34;
        if len(self._stations) &gt; 0:
            return np.max([s.last_data_timestamp() for s in self._stations])
        return np.nan

    def stations(self) -&gt; List[Station]:
        &#34;&#34;&#34;
        :return: list of stations in the DataWindow
        &#34;&#34;&#34;
        return self._stations

    def station_ids(self) -&gt; List[str]:
        &#34;&#34;&#34;
        :return: ids of stations in the DataWindow
        &#34;&#34;&#34;
        return [s.id() for s in self._stations]

    def add_station(self, station: Station):
        &#34;&#34;&#34;
        add a station to the DataWindow
        :param station: Station to add
        &#34;&#34;&#34;
        self._stations.append(station)

    def remove_station(self, station_id: Optional[str] = None, start_date: Optional[float] = None):
        &#34;&#34;&#34;
        remove the first station from the DataWindow, or a specific station if given the id and/or start date
        if an id is given, the first station with that id will be removed
        if a start date is given, the removed station will start at or after the start date
        start date is in microseconds since epoch UTC

        :param station_id: id of station to remove
        :param start_date: start date that is at or before the station to remove
        &#34;&#34;&#34;
        id_removals = []
        sd_removals = []
        if station_id is None and start_date is None:
            self._stations.pop()
        else:
            if station_id is not None:
                for s in range(len(self._stations)):
                    if self._stations[s].id == station_id:
                        id_removals.append(s)
            if start_date is not None:
                for s in range(len(self._stations)):
                    if self._stations[s].start_date() &gt;= start_date:
                        sd_removals.append(s)
            if len(id_removals) &gt; 0 and start_date is None:
                self._stations.pop(id_removals.pop())
            elif len(sd_removals) &gt; 0 and station_id is None:
                self._stations.pop(sd_removals.pop())
            elif len(id_removals) &gt; 0 and len(sd_removals) &gt; 0:
                for a in id_removals:
                    for b in sd_removals:
                        if a == b:
                            self._stations.pop(a)
                            return
                        if a &lt; b:
                            continue

    def first_station(self, station_id: Optional[str] = None) -&gt; Optional[Station]:
        &#34;&#34;&#34;
        :param station_id: optional station id to filter on
        :return: first station matching params; if no params given, gets first station in list.
                    returns None if no station with given station_id exists.
        &#34;&#34;&#34;
        if len(self._stations) &lt; 1:
            self._errors.append(f&#34;Attempted to get a station, but there are no stations in the data window!&#34;)
            if self.debug:
                print(f&#34;Attempted to get a station, but there are no stations in the data window!&#34;)
            return None
        elif station_id:
            result = [s for s in self._stations if s.get_key().check_key(station_id, None, None)]
            if len(result) &gt; 0:
                return result[0]
            self._errors.append(f&#34;Attempted to get station {station_id}, but that station is not in this data window!&#34;)
            if self.debug:
                print(f&#34;Attempted to get station {station_id}, but that station is not in this data window!&#34;)
            return None
        return self._stations[0]

    def get_station(self, station_id: str, station_uuid: Optional[str] = None,
                    start_timestamp: Optional[float] = None) -&gt; Optional[List[Station]]:
        &#34;&#34;&#34;
        Get stations from the DataWindow.  Must give at least the station&#39;s id.  Other parameters may be None,
        which means the value will be ignored when searching.  Results will match all non-None parameters given.

        :param station_id: station id
        :param station_uuid: station uuid, default None
        :param start_timestamp: station start timestamp in microseconds since UTC epoch, default None
        :return: A list of valid stations or None if the station cannot be found
        &#34;&#34;&#34;
        result = [s for s in self._stations if s.get_key().check_key(station_id, station_uuid, start_timestamp)]
        if len(result) &gt; 0:
            return result
        self._errors.append(f&#34;Attempted to get station {station_id}, but that station is not in this data window!&#34;)
        if self.debug:
            print(f&#34;Attempted to get station {station_id}, but that station is not in this data window!&#34;)
        return None

    # def _add_sensor_to_window(self, station: Station):
        # set the window start and end if they were specified, otherwise use the bounds of the data
        # self.create_window_in_sensors(station, self._config.start_datetime, self._config.end_datetime)

    def create_data_window(self, pool: Optional[multiprocessing.pool.Pool] = None):
        &#34;&#34;&#34;
        updates the DataWindow to contain only the data within the window parameters
        stations without audio or any data outside the window are removed
        &#34;&#34;&#34;
        # Let&#39;s create and manage a single pool of workers that we can utilize throughout
        # the instantiation of the data window.
        _pool: multiprocessing.pool.Pool = multiprocessing.Pool() if pool is None else pool

        r_f = io.ReadFilter()
        if self._config.start_datetime:
            r_f.with_start_dt(self._config.start_datetime)
        if self._config.end_datetime:
            r_f.with_end_dt(self._config.end_datetime)
        if self._config.station_ids:
            r_f.with_station_ids(self._config.station_ids)
        if self._config.extensions:
            r_f.with_extensions(self._config.extensions)
        else:
            self._config.extensions = r_f.extensions
        if self._config.api_versions:
            r_f.with_api_versions(self._config.api_versions)
        else:
            self._config.api_versions = r_f.api_versions
        r_f.with_start_dt_buf(self._config.start_buffer_td)
        r_f.with_end_dt_buf(self._config.end_buffer_td)

        if self.debug:
            print(&#34;Reading files from disk.  This may take a few minutes to complete.&#34;)

        # get the data to convert into a window
        a_r = ApiReaderDw(self._config.input_dir, self._config.structured_layout, r_f,
                          correct_timestamps=self._config.apply_correction,
                          use_model_correction=self._config.use_model_correction,
                          dw_base_dir=self.save_dir(),
                          dw_save_mode=self._fs_writer.save_mode(),
                          debug=self.debug, pool=_pool)

        # self._errors.extend_error(a_r.errors)

        if self._fs_writer.is_use_mem() and a_r.dw_save_mode != self._fs_writer.save_mode():
            if self.debug:
                print(&#34;Estimated size of files exceeds available memory.&#34;)
                print(&#34;Automatically using temporary directory to store data.&#34;)
            self._fs_writer.set_use_temp(True)

        # Parallel update
        # Apply timing correction in parallel by station
        sts = a_r.get_stations()
        if self.debug:
            print(&#34;num stations loaded: &#34;, len(sts))

        for st in maybe_parallel_map(_pool, Station.update_timestamps, iter(sts), chunk_size=1):
            self.create_window_in_sensors(st, self._config.start_datetime, self._config.end_datetime)
            if self.debug:
                print(&#34;station processed: &#34;, st.id())

        # check for stations without data
        self._check_for_audio()
        self._check_valid_ids()

        # update the default data window name if we have data and the default name exists
        if self.event_name == &#34;dw&#34; and len(self._stations) &gt; 0:
            self.event_name = f&#34;dw_{int(self.start_date())}_{len(self._stations)}&#34;

        # must update the start and end in order for the data to be saved
        # update remaining data window values if they&#39;re still default
        if not self._config.start_datetime and len(self._stations) &gt; 0:
            self._config.start_datetime = dtu.datetime_from_epoch_microseconds_utc(
                np.min([t.first_data_timestamp() for t in self._stations]))
        # end_datetime is non-inclusive, so it must be greater than our latest timestamp
        if not self._config.end_datetime and len(self._stations) &gt; 0:
            self._config.end_datetime = dtu.datetime_from_epoch_microseconds_utc(
                np.max([t.last_data_timestamp() for t in self._stations]) + 1)

        # If the pool was created by this function, then it needs to managed by this function.
        if pool is None:
            _pool.close()

    def _check_for_audio(self):
        &#34;&#34;&#34;
        removes any station without audio data from the DataWindow
        &#34;&#34;&#34;
        remove = []
        for s in self._stations:
            if not s.has_audio_sensor():
                remove.append(s.get_key())
        if len(remove) &gt; 0:
            self._stations = [s for s in self._stations if s.get_key() not in remove]

    def _check_valid_ids(self):
        &#34;&#34;&#34;
        if there are stations, searches the station_ids for any ids not in the data collected
        and creates an error message for each id requested but has no data
        if there are no stations, creates a single error message declaring no data found
        &#34;&#34;&#34;
        if len(self._stations) &lt; 1 and self._config.station_ids:
            if len(self._config.station_ids) &gt; 1:
                add_ids = f&#34;for all stations {self._config.station_ids} &#34;
            else:
                add_ids = &#34;&#34;
            self._errors.append(f&#34;No data matching criteria {add_ids}in {self._config.input_dir}&#34;
                                f&#34;\nPlease adjust parameters of DataWindow&#34;)
        elif len(self._stations) &gt; 0 and self._config.station_ids:
            for ids in self._config.station_ids:
                if ids.zfill(10) not in [i.id() for i in self._stations]:
                    self._errors.append(
                        f&#34;Requested {ids} but there is no data to read for that station&#34;
                    )

    def create_window_in_sensors(
            self, station: Station, start_datetime: Optional[dtu.datetime] = None,
            end_datetime: Optional[dtu.datetime] = None
    ):
        &#34;&#34;&#34;
        truncate the sensors in the station to only contain data from start_date_timestamp to end_date_timestamp
        if the start and/or end are not specified, keeps all audio data that fits and uses it
        to truncate the other sensors.
        returns nothing, updates the station in place

        :param station: station object to truncate sensors of
        :param start_datetime: datetime of start of window, default None
        :param end_datetime: datetime of end of window, default None
        &#34;&#34;&#34;
        if start_datetime:
            start_datetime = dtu.datetime_to_epoch_microseconds_utc(start_datetime)
        else:
            start_datetime = 0
        if end_datetime:
            end_datetime = dtu.datetime_to_epoch_microseconds_utc(end_datetime)
        else:
            end_datetime = dtu.datetime_to_epoch_microseconds_utc(dtu.datetime.max)
        self.process_sensor(station.audio_sensor(), station.id(), start_datetime, end_datetime)
        if station.has_audio_data():
            for sensor in [s for s in station.data() if s.type() != SensorType.AUDIO]:
                self.process_sensor(sensor, station.id(), station.audio_sensor().first_data_timestamp(),
                                    station.audio_sensor().last_data_timestamp())
            # recalculate metadata
            station.update_first_and_last_data_timestamps()
            station.set_packet_metadata([meta for meta in station.packet_metadata()
                                         if meta.packet_start_mach_timestamp &lt; station.last_data_timestamp() and
                                         meta.packet_end_mach_timestamp &gt;= station.first_data_timestamp()])
            if self._fs_writer.is_save_disk():
                station.set_save_mode(io.FileSystemSaveMode.DISK)
                station.set_save_dir(self.save_dir() if self._fs_writer.is_use_disk() else self._fs_writer.get_temp())
            self._stations.append(station)

    def process_sensor(self, sensor: SensorData, station_id: str, start_date_timestamp: float,
                       end_date_timestamp: float):
        &#34;&#34;&#34;
        process a non audio sensor to fit within the DataWindow.  Updates sensor in place, returns nothing.

        :param sensor: sensor to process
        :param station_id: station id
        :param start_date_timestamp: start of DataWindow
        :param end_date_timestamp: end of DataWindow
        &#34;&#34;&#34;
        if sensor.num_samples() &gt; 0:
            # get only the timestamps between the start and end timestamps
            before_start = np.where(sensor.data_timestamps() &lt; start_date_timestamp)[0]
            after_end = np.where(end_date_timestamp &lt;= sensor.data_timestamps())[0]
            # start_index is inclusive of window start
            if len(before_start) &gt; 0:
                last_before_start = before_start[-1]
                start_index = last_before_start + 1
            else:
                last_before_start = None
                start_index = 0
            # end_index is non-inclusive of window end
            if len(after_end) &gt; 0:
                first_after_end = after_end[0]
                end_index = first_after_end
            else:
                first_after_end = None
                end_index = sensor.num_samples()
            # check if all the samples have been cut off
            is_audio = sensor.type() == SensorType.AUDIO
            if end_index &lt;= start_index:
                self._errors.append(
                    f&#34;Data window for {station_id} {&#39;Audio&#39; if is_audio else sensor.type().name} &#34;
                    f&#34;sensor has truncated all data points&#34;
                )
                if is_audio:
                    sensor.empty_data_table()
                elif last_before_start is not None and first_after_end is None:
                    first_entry = sensor.pyarrow_table().slice(last_before_start, 1).to_pydict()
                    first_entry[&#34;timestamps&#34;] = [start_date_timestamp]
                    sensor.write_pyarrow_table(pa.Table.from_pydict(first_entry))
                elif last_before_start is None and first_after_end is not None:
                    last_entry = sensor.pyarrow_table().slice(first_after_end, 1).to_pydict()
                    last_entry[&#34;timestamps&#34;] = [start_date_timestamp]
                    sensor.write_pyarrow_table(pa.Table.from_pydict(last_entry))
                elif last_before_start is not None and first_after_end is not None:
                    sensor.write_pyarrow_table(
                        sensor.interpolate(start_date_timestamp, last_before_start, 1,
                                           self._config.copy_edge_points == gpu.DataPointCreationMode.COPY))
            else:
                _arrow = sensor.pyarrow_table().slice(start_index, end_index-start_index)
                # if sensor is audio or location, we want nan&#39;d edge points
                if sensor.type() in [SensorType.LOCATION, SensorType.AUDIO]:
                    new_point_mode = gpu.DataPointCreationMode.NAN
                else:
                    new_point_mode = self._config.copy_edge_points
                # add in the data points at the edges of the window if there are defined start and/or end times
                slice_start = _arrow[&#34;timestamps&#34;].to_numpy()[0]
                slice_end = _arrow[&#34;timestamps&#34;].to_numpy()[-1]
                if not is_audio:
                    end_sample_interval = end_date_timestamp - slice_end
                    end_samples_to_add = 1
                    start_sample_interval = start_date_timestamp - slice_start
                    start_samples_to_add = 1
                else:
                    end_sample_interval = dtu.seconds_to_microseconds(sensor.sample_interval_s())
                    start_sample_interval = -end_sample_interval
                    if self._config.end_datetime:
                        end_samples_to_add = int((dtu.datetime_to_epoch_microseconds_utc(self._config.end_datetime)
                                                  - slice_end) / end_sample_interval)
                    else:
                        end_samples_to_add = 0
                    if self._config.start_datetime:
                        start_samples_to_add = int((slice_start -
                                                    dtu.datetime_to_epoch_microseconds_utc(self._config.start_datetime))
                                                   / end_sample_interval)
                    else:
                        start_samples_to_add = 0
                # add to end
                _arrow = (gpu.add_data_points_to_df(data_table=_arrow, start_index=_arrow.num_rows - 1,
                                                    sample_interval_micros=end_sample_interval,
                                                    num_samples_to_add=end_samples_to_add,
                                                    point_creation_mode=new_point_mode))
                # add to begin
                _arrow = (gpu.add_data_points_to_df(data_table=_arrow, start_index=0,
                                                    sample_interval_micros=start_sample_interval,
                                                    num_samples_to_add=start_samples_to_add,
                                                    point_creation_mode=new_point_mode))
                sensor.sort_by_data_timestamps(_arrow)
        else:
            self._errors.append(f&#34;Data window for {station_id} {sensor.type().name} &#34;
                                f&#34;sensor has no data points!&#34;)

    def print_errors(self):
        &#34;&#34;&#34;
        prints errors to screen
        &#34;&#34;&#34;
        self._errors.print()
        for stn in self._stations:
            stn.print_errors()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="redvox.common.data_window.DataWindow"><code class="flex name class">
<span>class <span class="ident">DataWindow</span></span>
<span>(</span><span>event_name:Â strÂ =Â 'dw', event_origin:Â Optional[<a title="redvox.common.data_window.EventOrigin" href="#redvox.common.data_window.EventOrigin">EventOrigin</a>]Â =Â None, config:Â Optional[<a title="redvox.common.data_window.DataWindowConfig" href="#redvox.common.data_window.DataWindowConfig">DataWindowConfig</a>]Â =Â None, output_dir:Â strÂ =Â '.', out_type:Â strÂ =Â 'NONE', make_runme:Â boolÂ =Â False, debug:Â boolÂ =Â False)</span>
</code></dt>
<dd>
<div class="desc"><p>Holds the data for a given time window; adds interpolated timestamps to fill gaps and pad start and end values</p>
<h2 id="properties">Properties</h2>
<p>event_name: str, name of the DataWindow.
defaults to "dw"</p>
<p>event_origin: Optional EventOrigin which describes the physical location and radius of the
origin event.
Default empty EventOrigin (no valid data)</p>
<p>config: optional DataWindowConfig with information on how to construct DataWindow from
Redvox (.rdvx*) files.
Default None</p>
<p>sdk_version: str, the version of the Redvox SDK used to create the DataWindow</p>
<p>debug: bool, if True, outputs additional information during initialization. Default False</p>
<h2 id="protected">Protected</h2>
<p>_fs_writer: DataWindowFileSystemWriter; includes event_name, output directory (Default "."),
output type (options: "PARQUET", "LZ4", "NONE".
Default NONE), and option to make a
runme.py example file (Default False)</p>
<p>_stations: List of Stations that belong to the DataWindow</p>
<p>_errors: RedVoxExceptions; contains a list of all errors encountered by the DataWindow</p>
<p>Initialize the DataWindow</p>
<p>:param event_name: name of the DataWindow.
defaults to "dw"
:param event_origin: Optional EventOrigin which describes the physical location and radius of the
origin event.
Default empty EventOrigin (no valid data)
:param config: Optional DataWindowConfig which describes how to extract data from Redvox files.
Default None
:param output_dir: output directory for saving files.
Default "." (current directory)
:param out_type: type of file to save the DataWindow as.
Options: "PARQUET", "LZ4", "NONE".
Default "NONE" (no saving)
:param make_runme: if True, saves an example runme.py file with the data.
Default False
:param debug: if True, outputs additional information during initialization.
Default False</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DataWindow:
    &#34;&#34;&#34;
    Holds the data for a given time window; adds interpolated timestamps to fill gaps and pad start and end values

    Properties:
        event_name: str, name of the DataWindow.  defaults to &#34;dw&#34;

        event_origin: Optional EventOrigin which describes the physical location and radius of the
        origin event.  Default empty EventOrigin (no valid data)

        config: optional DataWindowConfig with information on how to construct DataWindow from
        Redvox (.rdvx*) files.  Default None

        sdk_version: str, the version of the Redvox SDK used to create the DataWindow

        debug: bool, if True, outputs additional information during initialization. Default False

    Protected:
        _fs_writer: DataWindowFileSystemWriter; includes event_name, output directory (Default &#34;.&#34;),
        output type (options: &#34;PARQUET&#34;, &#34;LZ4&#34;, &#34;NONE&#34;.  Default NONE), and option to make a
        runme.py example file (Default False)

        _stations: List of Stations that belong to the DataWindow

        _errors: RedVoxExceptions; contains a list of all errors encountered by the DataWindow
    &#34;&#34;&#34;
    def __init__(
            self,
            event_name: str = &#34;dw&#34;,
            event_origin: Optional[EventOrigin] = None,
            config: Optional[DataWindowConfig] = None,
            output_dir: str = &#34;.&#34;,
            out_type: str = &#34;NONE&#34;,
            make_runme: bool = False,
            debug: bool = False,
    ):
        &#34;&#34;&#34;
        Initialize the DataWindow

        :param event_name: name of the DataWindow.  defaults to &#34;dw&#34;
        :param event_origin: Optional EventOrigin which describes the physical location and radius of the
                                origin event.  Default empty EventOrigin (no valid data)
        :param config: Optional DataWindowConfig which describes how to extract data from Redvox files.
                        Default None
        :param output_dir: output directory for saving files.  Default &#34;.&#34; (current directory)
        :param out_type: type of file to save the DataWindow as.  Options: &#34;PARQUET&#34;, &#34;LZ4&#34;, &#34;NONE&#34;.
                            Default &#34;NONE&#34; (no saving)
        :param make_runme: if True, saves an example runme.py file with the data.  Default False
        :param debug: if True, outputs additional information during initialization.  Default False
        &#34;&#34;&#34;
        self.event_name: str = event_name
        self.event_origin: EventOrigin = event_origin if event_origin else EventOrigin()
        self._fs_writer = dw_io.DataWindowFileSystemWriter(self.event_name, out_type, output_dir, make_runme)
        self.debug: bool = debug
        self._sdk_version: str = redvox.VERSION
        self._errors = RedVoxExceptions(&#34;DataWindow&#34;)
        self._stations: List[Station] = []
        self._config = config
        if config:
            if config.start_datetime and config.end_datetime and (config.end_datetime &lt;= config.start_datetime):
                self._errors.append(&#34;DataWindow will not work when end datetime is before or equal to start datetime.\n&#34;
                                    f&#34;Your times: {config.end_datetime} &lt;= {config.start_datetime}&#34;)
            else:
                self.create_data_window()
        if self.debug:
            self.print_errors()

    def __repr__(self):
        return f&#34;event_name: {self.event_name}, &#34; \
               f&#34;event_origin: {self.event_origin.__repr__()}, &#34; \
               f&#34;config: {self._config.__repr__()}, &#34; \
               f&#34;output_dir: {os.path.abspath(self.save_dir())}, &#34; \
               f&#34;out_type: {self._fs_writer.file_extension}, &#34; \
               f&#34;make_runme: {self._fs_writer.make_run_me}, &#34; \
               f&#34;sdk_version: {self._sdk_version}, &#34; \
               f&#34;debug: {self.debug}&#34;

    def __str__(self):
        return f&#34;event_name: {self.event_name}, &#34; \
               f&#34;event_origin: {self.event_origin.__str__()}, &#34; \
               f&#34;config: {self._config.__str__()}, &#34; \
               f&#34;output_dir: {os.path.abspath(self.save_dir())}, &#34; \
               f&#34;out_type: {self._fs_writer.file_extension}, &#34; \
               f&#34;make_runme: {self._fs_writer.make_run_me}, &#34; \
               f&#34;sdk_version: {self._sdk_version}, &#34; \
               f&#34;debug: {self.debug}&#34;
        # &#34;stations&#34;: [s.__str__() for s in self._stations],

    def save_dir(self) -&gt; str:
        &#34;&#34;&#34;
        :return: directory data is saved to (empty string means saving to memory)
        &#34;&#34;&#34;
        return self._fs_writer.save_dir()

    def set_save_dir(self, new_save_dir: Optional[str] = &#34;.&#34;):
        &#34;&#34;&#34;
        :param new_save_dir: directory to save data to; default current directory, or &#34;.&#34;
        &#34;&#34;&#34;
        self._fs_writer.base_dir = new_save_dir

    def is_make_runme(self) -&gt; bool:
        &#34;&#34;&#34;
        :return: if DataWindow will be saved with a runme file
        &#34;&#34;&#34;
        return self._fs_writer.make_run_me

    def set_make_runme(self, make_runme: bool = False):
        &#34;&#34;&#34;
        :param make_runme: if True, DataWindow will create a runme file when saved.  Default False
        &#34;&#34;&#34;
        self._fs_writer.make_run_me = make_runme

    def fs_writer(self) -&gt; dw_io.DataWindowFileSystemWriter:
        &#34;&#34;&#34;
        :return: DataWindowFileSystemWriter for DataWindow
        &#34;&#34;&#34;
        return self._fs_writer

    def out_type(self) -&gt; str:
        &#34;&#34;&#34;
        :return: string of the output type of the DataWindow
        &#34;&#34;&#34;
        return self._fs_writer.file_extension

    def set_out_type(self, new_out_type: str):
        &#34;&#34;&#34;
        set the output type of the DataWindow.  options are &#34;NONE&#34;, &#34;PARQUET&#34; and &#34;LZ4&#34;.  invalid values become &#34;NONE&#34;

        :param new_out_type: new output type of the DataWindow
        &#34;&#34;&#34;
        self._fs_writer.set_extension(new_out_type)

    def as_dict(self) -&gt; Dict:
        &#34;&#34;&#34;
        :return: DataWindow properties as dictionary
        &#34;&#34;&#34;
        return {&#34;event_name&#34;: self.event_name,
                &#34;event_origin&#34;: self.event_origin.as_dict(),
                &#34;start_time&#34;: self.start_date(),
                &#34;end_time&#34;: self.end_date(),
                &#34;base_dir&#34;: self.save_dir(),
                &#34;stations&#34;: [s.default_station_json_file_name() for s in self._stations],
                &#34;config&#34;: self._config.as_dict(),
                &#34;debug&#34;: self.debug,
                &#34;errors&#34;: self._errors.as_dict(),
                &#34;sdk_version&#34;: self._sdk_version,
                &#34;out_type&#34;: self._fs_writer.file_extension,
                &#34;make_runme&#34;: self._fs_writer.make_run_me
                }

    def pretty(self) -&gt; str:
        &#34;&#34;&#34;
        :return: DataWindow as dictionary, but easier to read
        &#34;&#34;&#34;
        # noinspection Mypy
        return pprint.pformat(self.as_dict())

    @staticmethod
    def from_config(config: DataWindowConfigFile) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        Use a config file to create a DataWindow

        :param config: DataWindowConfigFile to load from
        :return: DataWindow
        &#34;&#34;&#34;
        event_origin = EventOrigin(config.origin_provider, config.origin_latitude, config.origin_latitude_std,
                                   config.origin_longitude, config.origin_longitude_std, config.origin_altitude,
                                   config.origin_altitude_std, config.origin_event_radius_m)
        dw_config = DataWindowConfig(config.input_directory, config.structured_layout, config.start_dt(),
                                     config.end_dt(), config.start_buffer_td(), config.end_buffer_td(),
                                     config.drop_time_seconds, config.station_ids, config.extensions,
                                     config.api_versions, config.apply_correction, config.use_model_correction,
                                     config.copy_edge_points())
        return DataWindow(config.event_name, event_origin, dw_config, config.output_dir, config.output_type,
                          config.make_runme, config.debug)

    @staticmethod
    def from_config_file(file: str) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        Loads a configuration file to create the DataWindow

        :param file: full path to config file
        :return: DataWindow
        &#34;&#34;&#34;
        return DataWindow.from_config(DataWindowConfigFile.from_path(file))

    @staticmethod
    def deserialize(path: str) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        Decompresses and deserializes a DataWindow written to disk.

        :param path: Path to the serialized and compressed DataWindow.
        :return: An instance of a DataWindow.
        &#34;&#34;&#34;
        return dw_io.deserialize_data_window(path)

    def serialize(self, compression_factor: int = 4) -&gt; Path:
        &#34;&#34;&#34;
        Serializes and compresses this DataWindow to a file.
        Uses the event_name and out_dir to name the file.

        :param compression_factor: A value between 1 and 12. Higher values provide better compression, but take
        longer. (default=4).
        :return: The path to the written file.
        &#34;&#34;&#34;
        return dw_io.serialize_data_window(self, self.save_dir(), f&#34;{self.event_name}.pkl.lz4&#34;, compression_factor)

    def _to_json_file(self) -&gt; Path:
        &#34;&#34;&#34;
        Converts the DataWindow metadata into a JSON file and compresses the DataWindow and writes it to disk.

        :return: The path to the written file
        &#34;&#34;&#34;
        return dw_io.data_window_to_json(self, self.save_dir())

    def to_json(self) -&gt; str:
        &#34;&#34;&#34;
        :return: The DataWindow metadata into a JSON string.
        &#34;&#34;&#34;
        return dw_io.data_window_as_json(self)

    @staticmethod
    def from_json(json_str: str) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        Read the DataWindow from a JSON string.  If file is improperly formatted, raises a ValueError.

        :param json_str: the JSON to read
        :return: The DataWindow as defined by the JSON
        &#34;&#34;&#34;
        return DataWindow.from_json_dict(dw_io.json_to_dict(json_str))

    @staticmethod
    def from_json_dict(json_dict: Dict) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        Reads a JSON dictionary and loads the data into the DataWindow.
        If dictionary is improperly formatted, raises a ValueError.

        :param json_dict: the dictionary to read
        :return: The DataWindow as defined by the JSON
        &#34;&#34;&#34;
        if &#34;out_type&#34; not in json_dict.keys() \
                or json_dict[&#34;out_type&#34;].upper() not in dw_io.DataWindowOutputType.list_names():
            raise ValueError(&#39;Dictionary loading type is invalid or unknown.  &#39;
                             &#39;Check the value &#34;out_type&#34;; it must be one of: &#39;
                             f&#39;{dw_io.DataWindowOutputType.list_non_none_names()}&#39;)
        else:
            out_type = dw_io.DataWindowOutputType.str_to_type(json_dict[&#34;out_type&#34;])
            if out_type == dw_io.DataWindowOutputType.PARQUET:
                dwin = DataWindow(json_dict[&#34;event_name&#34;], EventOrigin.from_dict(json_dict[&#34;event_origin&#34;]),
                                  None, json_dict[&#34;base_dir&#34;], json_dict[&#34;out_type&#34;], json_dict[&#34;make_runme&#34;],
                                  json_dict[&#34;debug&#34;])
                dwin._config = DataWindowConfig.from_dict(json_dict[&#34;config&#34;])
                dwin._errors = RedVoxExceptions.from_dict(json_dict[&#34;errors&#34;])
                dwin._sdk_version = json_dict[&#34;sdk_version&#34;]
                for st in json_dict[&#34;stations&#34;]:
                    dwin.add_station(Station.from_json_file(os.path.join(json_dict[&#34;base_dir&#34;], st), f&#34;{st}.json&#34;))
            elif out_type == dw_io.DataWindowOutputType.LZ4:
                dwin = DataWindow.deserialize(os.path.join(json_dict[&#34;base_dir&#34;],
                                                           f&#34;{json_dict[&#39;event_name&#39;]}.pkl.lz4&#34;))
            else:
                dwin = DataWindow()
            return dwin

    def save(self) -&gt; Path:
        &#34;&#34;&#34;
        save the DataWindow to disk if saving is enabled
        if saving is not enabled, adds an error to the DataWindow and returns an empty path.

        :return: the path to where the files exist; an empty path means no files were saved
        &#34;&#34;&#34;
        if self._fs_writer.is_save_disk():
            if self._fs_writer.is_use_disk() and self._fs_writer.make_run_me:
                shutil.copyfile(os.path.abspath(inspect.getfile(run_me)),
                                os.path.join(self._fs_writer.save_dir(), &#34;runme.py&#34;))
            if self._fs_writer.file_extension == &#34;parquet&#34;:
                return self._to_json_file()
            elif self._fs_writer.file_extension == &#34;lz4&#34;:
                return self.serialize()
        else:
            self._errors.append(&#34;Saving not enabled.&#34;)
            print(&#34;WARNING: Cannot save data window without knowing extension.&#34;)
            return Path()

    @staticmethod
    def load(file_path: str) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        load from json metadata and lz4 compressed file or directory of files

        :param file_path: full path of file to load
        :return: DataWindow from json metadata
        &#34;&#34;&#34;
        cur_path = os.getcwd()
        os.chdir(os.path.dirname(file_path))
        result = DataWindow.from_json_dict(dw_io.json_file_to_data_window(file_path))
        os.chdir(cur_path)
        return result

    def config(self) -&gt; DataWindowConfig:
        &#34;&#34;&#34;
        :return: settings used to create the DataWindow
        &#34;&#34;&#34;
        return self._config

    def sdk_version(self) -&gt; str:
        &#34;&#34;&#34;
        :return: sdk version used to create the DataWindow
        &#34;&#34;&#34;
        return self._sdk_version

    def set_sdk_version(self, version: str):
        &#34;&#34;&#34;
        :param version: the sdk version to set
        &#34;&#34;&#34;
        self._sdk_version = version

    def start_date(self) -&gt; float:
        &#34;&#34;&#34;
        :return: minimum start timestamp of the data or np.nan if no data
        &#34;&#34;&#34;
        if len(self._stations) &gt; 0:
            return np.min([s.first_data_timestamp() for s in self._stations])
        return np.nan

    def end_date(self) -&gt; float:
        &#34;&#34;&#34;
        :return: maximum end timestamp of the data or np.nan if no data
        &#34;&#34;&#34;
        if len(self._stations) &gt; 0:
            return np.max([s.last_data_timestamp() for s in self._stations])
        return np.nan

    def stations(self) -&gt; List[Station]:
        &#34;&#34;&#34;
        :return: list of stations in the DataWindow
        &#34;&#34;&#34;
        return self._stations

    def station_ids(self) -&gt; List[str]:
        &#34;&#34;&#34;
        :return: ids of stations in the DataWindow
        &#34;&#34;&#34;
        return [s.id() for s in self._stations]

    def add_station(self, station: Station):
        &#34;&#34;&#34;
        add a station to the DataWindow
        :param station: Station to add
        &#34;&#34;&#34;
        self._stations.append(station)

    def remove_station(self, station_id: Optional[str] = None, start_date: Optional[float] = None):
        &#34;&#34;&#34;
        remove the first station from the DataWindow, or a specific station if given the id and/or start date
        if an id is given, the first station with that id will be removed
        if a start date is given, the removed station will start at or after the start date
        start date is in microseconds since epoch UTC

        :param station_id: id of station to remove
        :param start_date: start date that is at or before the station to remove
        &#34;&#34;&#34;
        id_removals = []
        sd_removals = []
        if station_id is None and start_date is None:
            self._stations.pop()
        else:
            if station_id is not None:
                for s in range(len(self._stations)):
                    if self._stations[s].id == station_id:
                        id_removals.append(s)
            if start_date is not None:
                for s in range(len(self._stations)):
                    if self._stations[s].start_date() &gt;= start_date:
                        sd_removals.append(s)
            if len(id_removals) &gt; 0 and start_date is None:
                self._stations.pop(id_removals.pop())
            elif len(sd_removals) &gt; 0 and station_id is None:
                self._stations.pop(sd_removals.pop())
            elif len(id_removals) &gt; 0 and len(sd_removals) &gt; 0:
                for a in id_removals:
                    for b in sd_removals:
                        if a == b:
                            self._stations.pop(a)
                            return
                        if a &lt; b:
                            continue

    def first_station(self, station_id: Optional[str] = None) -&gt; Optional[Station]:
        &#34;&#34;&#34;
        :param station_id: optional station id to filter on
        :return: first station matching params; if no params given, gets first station in list.
                    returns None if no station with given station_id exists.
        &#34;&#34;&#34;
        if len(self._stations) &lt; 1:
            self._errors.append(f&#34;Attempted to get a station, but there are no stations in the data window!&#34;)
            if self.debug:
                print(f&#34;Attempted to get a station, but there are no stations in the data window!&#34;)
            return None
        elif station_id:
            result = [s for s in self._stations if s.get_key().check_key(station_id, None, None)]
            if len(result) &gt; 0:
                return result[0]
            self._errors.append(f&#34;Attempted to get station {station_id}, but that station is not in this data window!&#34;)
            if self.debug:
                print(f&#34;Attempted to get station {station_id}, but that station is not in this data window!&#34;)
            return None
        return self._stations[0]

    def get_station(self, station_id: str, station_uuid: Optional[str] = None,
                    start_timestamp: Optional[float] = None) -&gt; Optional[List[Station]]:
        &#34;&#34;&#34;
        Get stations from the DataWindow.  Must give at least the station&#39;s id.  Other parameters may be None,
        which means the value will be ignored when searching.  Results will match all non-None parameters given.

        :param station_id: station id
        :param station_uuid: station uuid, default None
        :param start_timestamp: station start timestamp in microseconds since UTC epoch, default None
        :return: A list of valid stations or None if the station cannot be found
        &#34;&#34;&#34;
        result = [s for s in self._stations if s.get_key().check_key(station_id, station_uuid, start_timestamp)]
        if len(result) &gt; 0:
            return result
        self._errors.append(f&#34;Attempted to get station {station_id}, but that station is not in this data window!&#34;)
        if self.debug:
            print(f&#34;Attempted to get station {station_id}, but that station is not in this data window!&#34;)
        return None

    # def _add_sensor_to_window(self, station: Station):
        # set the window start and end if they were specified, otherwise use the bounds of the data
        # self.create_window_in_sensors(station, self._config.start_datetime, self._config.end_datetime)

    def create_data_window(self, pool: Optional[multiprocessing.pool.Pool] = None):
        &#34;&#34;&#34;
        updates the DataWindow to contain only the data within the window parameters
        stations without audio or any data outside the window are removed
        &#34;&#34;&#34;
        # Let&#39;s create and manage a single pool of workers that we can utilize throughout
        # the instantiation of the data window.
        _pool: multiprocessing.pool.Pool = multiprocessing.Pool() if pool is None else pool

        r_f = io.ReadFilter()
        if self._config.start_datetime:
            r_f.with_start_dt(self._config.start_datetime)
        if self._config.end_datetime:
            r_f.with_end_dt(self._config.end_datetime)
        if self._config.station_ids:
            r_f.with_station_ids(self._config.station_ids)
        if self._config.extensions:
            r_f.with_extensions(self._config.extensions)
        else:
            self._config.extensions = r_f.extensions
        if self._config.api_versions:
            r_f.with_api_versions(self._config.api_versions)
        else:
            self._config.api_versions = r_f.api_versions
        r_f.with_start_dt_buf(self._config.start_buffer_td)
        r_f.with_end_dt_buf(self._config.end_buffer_td)

        if self.debug:
            print(&#34;Reading files from disk.  This may take a few minutes to complete.&#34;)

        # get the data to convert into a window
        a_r = ApiReaderDw(self._config.input_dir, self._config.structured_layout, r_f,
                          correct_timestamps=self._config.apply_correction,
                          use_model_correction=self._config.use_model_correction,
                          dw_base_dir=self.save_dir(),
                          dw_save_mode=self._fs_writer.save_mode(),
                          debug=self.debug, pool=_pool)

        # self._errors.extend_error(a_r.errors)

        if self._fs_writer.is_use_mem() and a_r.dw_save_mode != self._fs_writer.save_mode():
            if self.debug:
                print(&#34;Estimated size of files exceeds available memory.&#34;)
                print(&#34;Automatically using temporary directory to store data.&#34;)
            self._fs_writer.set_use_temp(True)

        # Parallel update
        # Apply timing correction in parallel by station
        sts = a_r.get_stations()
        if self.debug:
            print(&#34;num stations loaded: &#34;, len(sts))

        for st in maybe_parallel_map(_pool, Station.update_timestamps, iter(sts), chunk_size=1):
            self.create_window_in_sensors(st, self._config.start_datetime, self._config.end_datetime)
            if self.debug:
                print(&#34;station processed: &#34;, st.id())

        # check for stations without data
        self._check_for_audio()
        self._check_valid_ids()

        # update the default data window name if we have data and the default name exists
        if self.event_name == &#34;dw&#34; and len(self._stations) &gt; 0:
            self.event_name = f&#34;dw_{int(self.start_date())}_{len(self._stations)}&#34;

        # must update the start and end in order for the data to be saved
        # update remaining data window values if they&#39;re still default
        if not self._config.start_datetime and len(self._stations) &gt; 0:
            self._config.start_datetime = dtu.datetime_from_epoch_microseconds_utc(
                np.min([t.first_data_timestamp() for t in self._stations]))
        # end_datetime is non-inclusive, so it must be greater than our latest timestamp
        if not self._config.end_datetime and len(self._stations) &gt; 0:
            self._config.end_datetime = dtu.datetime_from_epoch_microseconds_utc(
                np.max([t.last_data_timestamp() for t in self._stations]) + 1)

        # If the pool was created by this function, then it needs to managed by this function.
        if pool is None:
            _pool.close()

    def _check_for_audio(self):
        &#34;&#34;&#34;
        removes any station without audio data from the DataWindow
        &#34;&#34;&#34;
        remove = []
        for s in self._stations:
            if not s.has_audio_sensor():
                remove.append(s.get_key())
        if len(remove) &gt; 0:
            self._stations = [s for s in self._stations if s.get_key() not in remove]

    def _check_valid_ids(self):
        &#34;&#34;&#34;
        if there are stations, searches the station_ids for any ids not in the data collected
        and creates an error message for each id requested but has no data
        if there are no stations, creates a single error message declaring no data found
        &#34;&#34;&#34;
        if len(self._stations) &lt; 1 and self._config.station_ids:
            if len(self._config.station_ids) &gt; 1:
                add_ids = f&#34;for all stations {self._config.station_ids} &#34;
            else:
                add_ids = &#34;&#34;
            self._errors.append(f&#34;No data matching criteria {add_ids}in {self._config.input_dir}&#34;
                                f&#34;\nPlease adjust parameters of DataWindow&#34;)
        elif len(self._stations) &gt; 0 and self._config.station_ids:
            for ids in self._config.station_ids:
                if ids.zfill(10) not in [i.id() for i in self._stations]:
                    self._errors.append(
                        f&#34;Requested {ids} but there is no data to read for that station&#34;
                    )

    def create_window_in_sensors(
            self, station: Station, start_datetime: Optional[dtu.datetime] = None,
            end_datetime: Optional[dtu.datetime] = None
    ):
        &#34;&#34;&#34;
        truncate the sensors in the station to only contain data from start_date_timestamp to end_date_timestamp
        if the start and/or end are not specified, keeps all audio data that fits and uses it
        to truncate the other sensors.
        returns nothing, updates the station in place

        :param station: station object to truncate sensors of
        :param start_datetime: datetime of start of window, default None
        :param end_datetime: datetime of end of window, default None
        &#34;&#34;&#34;
        if start_datetime:
            start_datetime = dtu.datetime_to_epoch_microseconds_utc(start_datetime)
        else:
            start_datetime = 0
        if end_datetime:
            end_datetime = dtu.datetime_to_epoch_microseconds_utc(end_datetime)
        else:
            end_datetime = dtu.datetime_to_epoch_microseconds_utc(dtu.datetime.max)
        self.process_sensor(station.audio_sensor(), station.id(), start_datetime, end_datetime)
        if station.has_audio_data():
            for sensor in [s for s in station.data() if s.type() != SensorType.AUDIO]:
                self.process_sensor(sensor, station.id(), station.audio_sensor().first_data_timestamp(),
                                    station.audio_sensor().last_data_timestamp())
            # recalculate metadata
            station.update_first_and_last_data_timestamps()
            station.set_packet_metadata([meta for meta in station.packet_metadata()
                                         if meta.packet_start_mach_timestamp &lt; station.last_data_timestamp() and
                                         meta.packet_end_mach_timestamp &gt;= station.first_data_timestamp()])
            if self._fs_writer.is_save_disk():
                station.set_save_mode(io.FileSystemSaveMode.DISK)
                station.set_save_dir(self.save_dir() if self._fs_writer.is_use_disk() else self._fs_writer.get_temp())
            self._stations.append(station)

    def process_sensor(self, sensor: SensorData, station_id: str, start_date_timestamp: float,
                       end_date_timestamp: float):
        &#34;&#34;&#34;
        process a non audio sensor to fit within the DataWindow.  Updates sensor in place, returns nothing.

        :param sensor: sensor to process
        :param station_id: station id
        :param start_date_timestamp: start of DataWindow
        :param end_date_timestamp: end of DataWindow
        &#34;&#34;&#34;
        if sensor.num_samples() &gt; 0:
            # get only the timestamps between the start and end timestamps
            before_start = np.where(sensor.data_timestamps() &lt; start_date_timestamp)[0]
            after_end = np.where(end_date_timestamp &lt;= sensor.data_timestamps())[0]
            # start_index is inclusive of window start
            if len(before_start) &gt; 0:
                last_before_start = before_start[-1]
                start_index = last_before_start + 1
            else:
                last_before_start = None
                start_index = 0
            # end_index is non-inclusive of window end
            if len(after_end) &gt; 0:
                first_after_end = after_end[0]
                end_index = first_after_end
            else:
                first_after_end = None
                end_index = sensor.num_samples()
            # check if all the samples have been cut off
            is_audio = sensor.type() == SensorType.AUDIO
            if end_index &lt;= start_index:
                self._errors.append(
                    f&#34;Data window for {station_id} {&#39;Audio&#39; if is_audio else sensor.type().name} &#34;
                    f&#34;sensor has truncated all data points&#34;
                )
                if is_audio:
                    sensor.empty_data_table()
                elif last_before_start is not None and first_after_end is None:
                    first_entry = sensor.pyarrow_table().slice(last_before_start, 1).to_pydict()
                    first_entry[&#34;timestamps&#34;] = [start_date_timestamp]
                    sensor.write_pyarrow_table(pa.Table.from_pydict(first_entry))
                elif last_before_start is None and first_after_end is not None:
                    last_entry = sensor.pyarrow_table().slice(first_after_end, 1).to_pydict()
                    last_entry[&#34;timestamps&#34;] = [start_date_timestamp]
                    sensor.write_pyarrow_table(pa.Table.from_pydict(last_entry))
                elif last_before_start is not None and first_after_end is not None:
                    sensor.write_pyarrow_table(
                        sensor.interpolate(start_date_timestamp, last_before_start, 1,
                                           self._config.copy_edge_points == gpu.DataPointCreationMode.COPY))
            else:
                _arrow = sensor.pyarrow_table().slice(start_index, end_index-start_index)
                # if sensor is audio or location, we want nan&#39;d edge points
                if sensor.type() in [SensorType.LOCATION, SensorType.AUDIO]:
                    new_point_mode = gpu.DataPointCreationMode.NAN
                else:
                    new_point_mode = self._config.copy_edge_points
                # add in the data points at the edges of the window if there are defined start and/or end times
                slice_start = _arrow[&#34;timestamps&#34;].to_numpy()[0]
                slice_end = _arrow[&#34;timestamps&#34;].to_numpy()[-1]
                if not is_audio:
                    end_sample_interval = end_date_timestamp - slice_end
                    end_samples_to_add = 1
                    start_sample_interval = start_date_timestamp - slice_start
                    start_samples_to_add = 1
                else:
                    end_sample_interval = dtu.seconds_to_microseconds(sensor.sample_interval_s())
                    start_sample_interval = -end_sample_interval
                    if self._config.end_datetime:
                        end_samples_to_add = int((dtu.datetime_to_epoch_microseconds_utc(self._config.end_datetime)
                                                  - slice_end) / end_sample_interval)
                    else:
                        end_samples_to_add = 0
                    if self._config.start_datetime:
                        start_samples_to_add = int((slice_start -
                                                    dtu.datetime_to_epoch_microseconds_utc(self._config.start_datetime))
                                                   / end_sample_interval)
                    else:
                        start_samples_to_add = 0
                # add to end
                _arrow = (gpu.add_data_points_to_df(data_table=_arrow, start_index=_arrow.num_rows - 1,
                                                    sample_interval_micros=end_sample_interval,
                                                    num_samples_to_add=end_samples_to_add,
                                                    point_creation_mode=new_point_mode))
                # add to begin
                _arrow = (gpu.add_data_points_to_df(data_table=_arrow, start_index=0,
                                                    sample_interval_micros=start_sample_interval,
                                                    num_samples_to_add=start_samples_to_add,
                                                    point_creation_mode=new_point_mode))
                sensor.sort_by_data_timestamps(_arrow)
        else:
            self._errors.append(f&#34;Data window for {station_id} {sensor.type().name} &#34;
                                f&#34;sensor has no data points!&#34;)

    def print_errors(self):
        &#34;&#34;&#34;
        prints errors to screen
        &#34;&#34;&#34;
        self._errors.print()
        for stn in self._stations:
            stn.print_errors()</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="redvox.common.data_window.DataWindow.deserialize"><code class="name flex">
<span>def <span class="ident">deserialize</span></span>(<span>path:Â str) â€‘>Â <a title="redvox.common.data_window.DataWindow" href="#redvox.common.data_window.DataWindow">DataWindow</a></span>
</code></dt>
<dd>
<div class="desc"><p>Decompresses and deserializes a DataWindow written to disk.</p>
<p>:param path: Path to the serialized and compressed DataWindow.
:return: An instance of a DataWindow.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def deserialize(path: str) -&gt; &#34;DataWindow&#34;:
    &#34;&#34;&#34;
    Decompresses and deserializes a DataWindow written to disk.

    :param path: Path to the serialized and compressed DataWindow.
    :return: An instance of a DataWindow.
    &#34;&#34;&#34;
    return dw_io.deserialize_data_window(path)</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.from_config"><code class="name flex">
<span>def <span class="ident">from_config</span></span>(<span>config:Â <a title="redvox.common.data_window_configuration.DataWindowConfigFile" href="data_window_configuration.html#redvox.common.data_window_configuration.DataWindowConfigFile">DataWindowConfigFile</a>) â€‘>Â <a title="redvox.common.data_window.DataWindow" href="#redvox.common.data_window.DataWindow">DataWindow</a></span>
</code></dt>
<dd>
<div class="desc"><p>Use a config file to create a DataWindow</p>
<p>:param config: DataWindowConfigFile to load from
:return: DataWindow</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_config(config: DataWindowConfigFile) -&gt; &#34;DataWindow&#34;:
    &#34;&#34;&#34;
    Use a config file to create a DataWindow

    :param config: DataWindowConfigFile to load from
    :return: DataWindow
    &#34;&#34;&#34;
    event_origin = EventOrigin(config.origin_provider, config.origin_latitude, config.origin_latitude_std,
                               config.origin_longitude, config.origin_longitude_std, config.origin_altitude,
                               config.origin_altitude_std, config.origin_event_radius_m)
    dw_config = DataWindowConfig(config.input_directory, config.structured_layout, config.start_dt(),
                                 config.end_dt(), config.start_buffer_td(), config.end_buffer_td(),
                                 config.drop_time_seconds, config.station_ids, config.extensions,
                                 config.api_versions, config.apply_correction, config.use_model_correction,
                                 config.copy_edge_points())
    return DataWindow(config.event_name, event_origin, dw_config, config.output_dir, config.output_type,
                      config.make_runme, config.debug)</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.from_config_file"><code class="name flex">
<span>def <span class="ident">from_config_file</span></span>(<span>file:Â str) â€‘>Â <a title="redvox.common.data_window.DataWindow" href="#redvox.common.data_window.DataWindow">DataWindow</a></span>
</code></dt>
<dd>
<div class="desc"><p>Loads a configuration file to create the DataWindow</p>
<p>:param file: full path to config file
:return: DataWindow</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_config_file(file: str) -&gt; &#34;DataWindow&#34;:
    &#34;&#34;&#34;
    Loads a configuration file to create the DataWindow

    :param file: full path to config file
    :return: DataWindow
    &#34;&#34;&#34;
    return DataWindow.from_config(DataWindowConfigFile.from_path(file))</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.from_json"><code class="name flex">
<span>def <span class="ident">from_json</span></span>(<span>json_str:Â str) â€‘>Â <a title="redvox.common.data_window.DataWindow" href="#redvox.common.data_window.DataWindow">DataWindow</a></span>
</code></dt>
<dd>
<div class="desc"><p>Read the DataWindow from a JSON string.
If file is improperly formatted, raises a ValueError.</p>
<p>:param json_str: the JSON to read
:return: The DataWindow as defined by the JSON</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_json(json_str: str) -&gt; &#34;DataWindow&#34;:
    &#34;&#34;&#34;
    Read the DataWindow from a JSON string.  If file is improperly formatted, raises a ValueError.

    :param json_str: the JSON to read
    :return: The DataWindow as defined by the JSON
    &#34;&#34;&#34;
    return DataWindow.from_json_dict(dw_io.json_to_dict(json_str))</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.from_json_dict"><code class="name flex">
<span>def <span class="ident">from_json_dict</span></span>(<span>json_dict:Â Dict) â€‘>Â <a title="redvox.common.data_window.DataWindow" href="#redvox.common.data_window.DataWindow">DataWindow</a></span>
</code></dt>
<dd>
<div class="desc"><p>Reads a JSON dictionary and loads the data into the DataWindow.
If dictionary is improperly formatted, raises a ValueError.</p>
<p>:param json_dict: the dictionary to read
:return: The DataWindow as defined by the JSON</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_json_dict(json_dict: Dict) -&gt; &#34;DataWindow&#34;:
    &#34;&#34;&#34;
    Reads a JSON dictionary and loads the data into the DataWindow.
    If dictionary is improperly formatted, raises a ValueError.

    :param json_dict: the dictionary to read
    :return: The DataWindow as defined by the JSON
    &#34;&#34;&#34;
    if &#34;out_type&#34; not in json_dict.keys() \
            or json_dict[&#34;out_type&#34;].upper() not in dw_io.DataWindowOutputType.list_names():
        raise ValueError(&#39;Dictionary loading type is invalid or unknown.  &#39;
                         &#39;Check the value &#34;out_type&#34;; it must be one of: &#39;
                         f&#39;{dw_io.DataWindowOutputType.list_non_none_names()}&#39;)
    else:
        out_type = dw_io.DataWindowOutputType.str_to_type(json_dict[&#34;out_type&#34;])
        if out_type == dw_io.DataWindowOutputType.PARQUET:
            dwin = DataWindow(json_dict[&#34;event_name&#34;], EventOrigin.from_dict(json_dict[&#34;event_origin&#34;]),
                              None, json_dict[&#34;base_dir&#34;], json_dict[&#34;out_type&#34;], json_dict[&#34;make_runme&#34;],
                              json_dict[&#34;debug&#34;])
            dwin._config = DataWindowConfig.from_dict(json_dict[&#34;config&#34;])
            dwin._errors = RedVoxExceptions.from_dict(json_dict[&#34;errors&#34;])
            dwin._sdk_version = json_dict[&#34;sdk_version&#34;]
            for st in json_dict[&#34;stations&#34;]:
                dwin.add_station(Station.from_json_file(os.path.join(json_dict[&#34;base_dir&#34;], st), f&#34;{st}.json&#34;))
        elif out_type == dw_io.DataWindowOutputType.LZ4:
            dwin = DataWindow.deserialize(os.path.join(json_dict[&#34;base_dir&#34;],
                                                       f&#34;{json_dict[&#39;event_name&#39;]}.pkl.lz4&#34;))
        else:
            dwin = DataWindow()
        return dwin</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>file_path:Â str) â€‘>Â <a title="redvox.common.data_window.DataWindow" href="#redvox.common.data_window.DataWindow">DataWindow</a></span>
</code></dt>
<dd>
<div class="desc"><p>load from json metadata and lz4 compressed file or directory of files</p>
<p>:param file_path: full path of file to load
:return: DataWindow from json metadata</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def load(file_path: str) -&gt; &#34;DataWindow&#34;:
    &#34;&#34;&#34;
    load from json metadata and lz4 compressed file or directory of files

    :param file_path: full path of file to load
    :return: DataWindow from json metadata
    &#34;&#34;&#34;
    cur_path = os.getcwd()
    os.chdir(os.path.dirname(file_path))
    result = DataWindow.from_json_dict(dw_io.json_file_to_data_window(file_path))
    os.chdir(cur_path)
    return result</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="redvox.common.data_window.DataWindow.add_station"><code class="name flex">
<span>def <span class="ident">add_station</span></span>(<span>self, station:Â <a title="redvox.common.station.Station" href="station.html#redvox.common.station.Station">Station</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>add a station to the DataWindow
:param station: Station to add</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_station(self, station: Station):
    &#34;&#34;&#34;
    add a station to the DataWindow
    :param station: Station to add
    &#34;&#34;&#34;
    self._stations.append(station)</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.as_dict"><code class="name flex">
<span>def <span class="ident">as_dict</span></span>(<span>self) â€‘>Â Dict</span>
</code></dt>
<dd>
<div class="desc"><p>:return: DataWindow properties as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def as_dict(self) -&gt; Dict:
    &#34;&#34;&#34;
    :return: DataWindow properties as dictionary
    &#34;&#34;&#34;
    return {&#34;event_name&#34;: self.event_name,
            &#34;event_origin&#34;: self.event_origin.as_dict(),
            &#34;start_time&#34;: self.start_date(),
            &#34;end_time&#34;: self.end_date(),
            &#34;base_dir&#34;: self.save_dir(),
            &#34;stations&#34;: [s.default_station_json_file_name() for s in self._stations],
            &#34;config&#34;: self._config.as_dict(),
            &#34;debug&#34;: self.debug,
            &#34;errors&#34;: self._errors.as_dict(),
            &#34;sdk_version&#34;: self._sdk_version,
            &#34;out_type&#34;: self._fs_writer.file_extension,
            &#34;make_runme&#34;: self._fs_writer.make_run_me
            }</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.config"><code class="name flex">
<span>def <span class="ident">config</span></span>(<span>self) â€‘>Â <a title="redvox.common.data_window.DataWindowConfig" href="#redvox.common.data_window.DataWindowConfig">DataWindowConfig</a></span>
</code></dt>
<dd>
<div class="desc"><p>:return: settings used to create the DataWindow</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def config(self) -&gt; DataWindowConfig:
    &#34;&#34;&#34;
    :return: settings used to create the DataWindow
    &#34;&#34;&#34;
    return self._config</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.create_data_window"><code class="name flex">
<span>def <span class="ident">create_data_window</span></span>(<span>self, pool:Â Optional[multiprocessing.pool.Pool]Â =Â None)</span>
</code></dt>
<dd>
<div class="desc"><p>updates the DataWindow to contain only the data within the window parameters
stations without audio or any data outside the window are removed</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_data_window(self, pool: Optional[multiprocessing.pool.Pool] = None):
    &#34;&#34;&#34;
    updates the DataWindow to contain only the data within the window parameters
    stations without audio or any data outside the window are removed
    &#34;&#34;&#34;
    # Let&#39;s create and manage a single pool of workers that we can utilize throughout
    # the instantiation of the data window.
    _pool: multiprocessing.pool.Pool = multiprocessing.Pool() if pool is None else pool

    r_f = io.ReadFilter()
    if self._config.start_datetime:
        r_f.with_start_dt(self._config.start_datetime)
    if self._config.end_datetime:
        r_f.with_end_dt(self._config.end_datetime)
    if self._config.station_ids:
        r_f.with_station_ids(self._config.station_ids)
    if self._config.extensions:
        r_f.with_extensions(self._config.extensions)
    else:
        self._config.extensions = r_f.extensions
    if self._config.api_versions:
        r_f.with_api_versions(self._config.api_versions)
    else:
        self._config.api_versions = r_f.api_versions
    r_f.with_start_dt_buf(self._config.start_buffer_td)
    r_f.with_end_dt_buf(self._config.end_buffer_td)

    if self.debug:
        print(&#34;Reading files from disk.  This may take a few minutes to complete.&#34;)

    # get the data to convert into a window
    a_r = ApiReaderDw(self._config.input_dir, self._config.structured_layout, r_f,
                      correct_timestamps=self._config.apply_correction,
                      use_model_correction=self._config.use_model_correction,
                      dw_base_dir=self.save_dir(),
                      dw_save_mode=self._fs_writer.save_mode(),
                      debug=self.debug, pool=_pool)

    # self._errors.extend_error(a_r.errors)

    if self._fs_writer.is_use_mem() and a_r.dw_save_mode != self._fs_writer.save_mode():
        if self.debug:
            print(&#34;Estimated size of files exceeds available memory.&#34;)
            print(&#34;Automatically using temporary directory to store data.&#34;)
        self._fs_writer.set_use_temp(True)

    # Parallel update
    # Apply timing correction in parallel by station
    sts = a_r.get_stations()
    if self.debug:
        print(&#34;num stations loaded: &#34;, len(sts))

    for st in maybe_parallel_map(_pool, Station.update_timestamps, iter(sts), chunk_size=1):
        self.create_window_in_sensors(st, self._config.start_datetime, self._config.end_datetime)
        if self.debug:
            print(&#34;station processed: &#34;, st.id())

    # check for stations without data
    self._check_for_audio()
    self._check_valid_ids()

    # update the default data window name if we have data and the default name exists
    if self.event_name == &#34;dw&#34; and len(self._stations) &gt; 0:
        self.event_name = f&#34;dw_{int(self.start_date())}_{len(self._stations)}&#34;

    # must update the start and end in order for the data to be saved
    # update remaining data window values if they&#39;re still default
    if not self._config.start_datetime and len(self._stations) &gt; 0:
        self._config.start_datetime = dtu.datetime_from_epoch_microseconds_utc(
            np.min([t.first_data_timestamp() for t in self._stations]))
    # end_datetime is non-inclusive, so it must be greater than our latest timestamp
    if not self._config.end_datetime and len(self._stations) &gt; 0:
        self._config.end_datetime = dtu.datetime_from_epoch_microseconds_utc(
            np.max([t.last_data_timestamp() for t in self._stations]) + 1)

    # If the pool was created by this function, then it needs to managed by this function.
    if pool is None:
        _pool.close()</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.create_window_in_sensors"><code class="name flex">
<span>def <span class="ident">create_window_in_sensors</span></span>(<span>self, station:Â <a title="redvox.common.station.Station" href="station.html#redvox.common.station.Station">Station</a>, start_datetime:Â Optional[datetime.datetime]Â =Â None, end_datetime:Â Optional[datetime.datetime]Â =Â None)</span>
</code></dt>
<dd>
<div class="desc"><p>truncate the sensors in the station to only contain data from start_date_timestamp to end_date_timestamp
if the start and/or end are not specified, keeps all audio data that fits and uses it
to truncate the other sensors.
returns nothing, updates the station in place</p>
<p>:param station: station object to truncate sensors of
:param start_datetime: datetime of start of window, default None
:param end_datetime: datetime of end of window, default None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_window_in_sensors(
        self, station: Station, start_datetime: Optional[dtu.datetime] = None,
        end_datetime: Optional[dtu.datetime] = None
):
    &#34;&#34;&#34;
    truncate the sensors in the station to only contain data from start_date_timestamp to end_date_timestamp
    if the start and/or end are not specified, keeps all audio data that fits and uses it
    to truncate the other sensors.
    returns nothing, updates the station in place

    :param station: station object to truncate sensors of
    :param start_datetime: datetime of start of window, default None
    :param end_datetime: datetime of end of window, default None
    &#34;&#34;&#34;
    if start_datetime:
        start_datetime = dtu.datetime_to_epoch_microseconds_utc(start_datetime)
    else:
        start_datetime = 0
    if end_datetime:
        end_datetime = dtu.datetime_to_epoch_microseconds_utc(end_datetime)
    else:
        end_datetime = dtu.datetime_to_epoch_microseconds_utc(dtu.datetime.max)
    self.process_sensor(station.audio_sensor(), station.id(), start_datetime, end_datetime)
    if station.has_audio_data():
        for sensor in [s for s in station.data() if s.type() != SensorType.AUDIO]:
            self.process_sensor(sensor, station.id(), station.audio_sensor().first_data_timestamp(),
                                station.audio_sensor().last_data_timestamp())
        # recalculate metadata
        station.update_first_and_last_data_timestamps()
        station.set_packet_metadata([meta for meta in station.packet_metadata()
                                     if meta.packet_start_mach_timestamp &lt; station.last_data_timestamp() and
                                     meta.packet_end_mach_timestamp &gt;= station.first_data_timestamp()])
        if self._fs_writer.is_save_disk():
            station.set_save_mode(io.FileSystemSaveMode.DISK)
            station.set_save_dir(self.save_dir() if self._fs_writer.is_use_disk() else self._fs_writer.get_temp())
        self._stations.append(station)</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.end_date"><code class="name flex">
<span>def <span class="ident">end_date</span></span>(<span>self) â€‘>Â float</span>
</code></dt>
<dd>
<div class="desc"><p>:return: maximum end timestamp of the data or np.nan if no data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def end_date(self) -&gt; float:
    &#34;&#34;&#34;
    :return: maximum end timestamp of the data or np.nan if no data
    &#34;&#34;&#34;
    if len(self._stations) &gt; 0:
        return np.max([s.last_data_timestamp() for s in self._stations])
    return np.nan</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.first_station"><code class="name flex">
<span>def <span class="ident">first_station</span></span>(<span>self, station_id:Â Optional[str]Â =Â None) â€‘>Â Optional[<a title="redvox.common.station.Station" href="station.html#redvox.common.station.Station">Station</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>:param station_id: optional station id to filter on
:return: first station matching params; if no params given, gets first station in list.
returns None if no station with given station_id exists.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def first_station(self, station_id: Optional[str] = None) -&gt; Optional[Station]:
    &#34;&#34;&#34;
    :param station_id: optional station id to filter on
    :return: first station matching params; if no params given, gets first station in list.
                returns None if no station with given station_id exists.
    &#34;&#34;&#34;
    if len(self._stations) &lt; 1:
        self._errors.append(f&#34;Attempted to get a station, but there are no stations in the data window!&#34;)
        if self.debug:
            print(f&#34;Attempted to get a station, but there are no stations in the data window!&#34;)
        return None
    elif station_id:
        result = [s for s in self._stations if s.get_key().check_key(station_id, None, None)]
        if len(result) &gt; 0:
            return result[0]
        self._errors.append(f&#34;Attempted to get station {station_id}, but that station is not in this data window!&#34;)
        if self.debug:
            print(f&#34;Attempted to get station {station_id}, but that station is not in this data window!&#34;)
        return None
    return self._stations[0]</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.fs_writer"><code class="name flex">
<span>def <span class="ident">fs_writer</span></span>(<span>self) â€‘>Â <a title="redvox.common.data_window_io.DataWindowFileSystemWriter" href="data_window_io.html#redvox.common.data_window_io.DataWindowFileSystemWriter">DataWindowFileSystemWriter</a></span>
</code></dt>
<dd>
<div class="desc"><p>:return: DataWindowFileSystemWriter for DataWindow</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fs_writer(self) -&gt; dw_io.DataWindowFileSystemWriter:
    &#34;&#34;&#34;
    :return: DataWindowFileSystemWriter for DataWindow
    &#34;&#34;&#34;
    return self._fs_writer</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.get_station"><code class="name flex">
<span>def <span class="ident">get_station</span></span>(<span>self, station_id:Â str, station_uuid:Â Optional[str]Â =Â None, start_timestamp:Â Optional[float]Â =Â None) â€‘>Â Optional[List[<a title="redvox.common.station.Station" href="station.html#redvox.common.station.Station">Station</a>]]</span>
</code></dt>
<dd>
<div class="desc"><p>Get stations from the DataWindow.
Must give at least the station's id.
Other parameters may be None,
which means the value will be ignored when searching.
Results will match all non-None parameters given.</p>
<p>:param station_id: station id
:param station_uuid: station uuid, default None
:param start_timestamp: station start timestamp in microseconds since UTC epoch, default None
:return: A list of valid stations or None if the station cannot be found</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_station(self, station_id: str, station_uuid: Optional[str] = None,
                start_timestamp: Optional[float] = None) -&gt; Optional[List[Station]]:
    &#34;&#34;&#34;
    Get stations from the DataWindow.  Must give at least the station&#39;s id.  Other parameters may be None,
    which means the value will be ignored when searching.  Results will match all non-None parameters given.

    :param station_id: station id
    :param station_uuid: station uuid, default None
    :param start_timestamp: station start timestamp in microseconds since UTC epoch, default None
    :return: A list of valid stations or None if the station cannot be found
    &#34;&#34;&#34;
    result = [s for s in self._stations if s.get_key().check_key(station_id, station_uuid, start_timestamp)]
    if len(result) &gt; 0:
        return result
    self._errors.append(f&#34;Attempted to get station {station_id}, but that station is not in this data window!&#34;)
    if self.debug:
        print(f&#34;Attempted to get station {station_id}, but that station is not in this data window!&#34;)
    return None

# def _add_sensor_to_window(self, station: Station):
    # set the window start and end if they were specified, otherwise use the bounds of the data
    # self.create_window_in_sensors(station, self._config.start_datetime, self._config.end_datetime)</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.is_make_runme"><code class="name flex">
<span>def <span class="ident">is_make_runme</span></span>(<span>self) â€‘>Â bool</span>
</code></dt>
<dd>
<div class="desc"><p>:return: if DataWindow will be saved with a runme file</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_make_runme(self) -&gt; bool:
    &#34;&#34;&#34;
    :return: if DataWindow will be saved with a runme file
    &#34;&#34;&#34;
    return self._fs_writer.make_run_me</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.out_type"><code class="name flex">
<span>def <span class="ident">out_type</span></span>(<span>self) â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>:return: string of the output type of the DataWindow</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def out_type(self) -&gt; str:
    &#34;&#34;&#34;
    :return: string of the output type of the DataWindow
    &#34;&#34;&#34;
    return self._fs_writer.file_extension</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.pretty"><code class="name flex">
<span>def <span class="ident">pretty</span></span>(<span>self) â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>:return: DataWindow as dictionary, but easier to read</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pretty(self) -&gt; str:
    &#34;&#34;&#34;
    :return: DataWindow as dictionary, but easier to read
    &#34;&#34;&#34;
    # noinspection Mypy
    return pprint.pformat(self.as_dict())</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.print_errors"><code class="name flex">
<span>def <span class="ident">print_errors</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>prints errors to screen</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def print_errors(self):
    &#34;&#34;&#34;
    prints errors to screen
    &#34;&#34;&#34;
    self._errors.print()
    for stn in self._stations:
        stn.print_errors()</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.process_sensor"><code class="name flex">
<span>def <span class="ident">process_sensor</span></span>(<span>self, sensor:Â <a title="redvox.common.sensor_data.SensorData" href="sensor_data.html#redvox.common.sensor_data.SensorData">SensorData</a>, station_id:Â str, start_date_timestamp:Â float, end_date_timestamp:Â float)</span>
</code></dt>
<dd>
<div class="desc"><p>process a non audio sensor to fit within the DataWindow.
Updates sensor in place, returns nothing.</p>
<p>:param sensor: sensor to process
:param station_id: station id
:param start_date_timestamp: start of DataWindow
:param end_date_timestamp: end of DataWindow</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_sensor(self, sensor: SensorData, station_id: str, start_date_timestamp: float,
                   end_date_timestamp: float):
    &#34;&#34;&#34;
    process a non audio sensor to fit within the DataWindow.  Updates sensor in place, returns nothing.

    :param sensor: sensor to process
    :param station_id: station id
    :param start_date_timestamp: start of DataWindow
    :param end_date_timestamp: end of DataWindow
    &#34;&#34;&#34;
    if sensor.num_samples() &gt; 0:
        # get only the timestamps between the start and end timestamps
        before_start = np.where(sensor.data_timestamps() &lt; start_date_timestamp)[0]
        after_end = np.where(end_date_timestamp &lt;= sensor.data_timestamps())[0]
        # start_index is inclusive of window start
        if len(before_start) &gt; 0:
            last_before_start = before_start[-1]
            start_index = last_before_start + 1
        else:
            last_before_start = None
            start_index = 0
        # end_index is non-inclusive of window end
        if len(after_end) &gt; 0:
            first_after_end = after_end[0]
            end_index = first_after_end
        else:
            first_after_end = None
            end_index = sensor.num_samples()
        # check if all the samples have been cut off
        is_audio = sensor.type() == SensorType.AUDIO
        if end_index &lt;= start_index:
            self._errors.append(
                f&#34;Data window for {station_id} {&#39;Audio&#39; if is_audio else sensor.type().name} &#34;
                f&#34;sensor has truncated all data points&#34;
            )
            if is_audio:
                sensor.empty_data_table()
            elif last_before_start is not None and first_after_end is None:
                first_entry = sensor.pyarrow_table().slice(last_before_start, 1).to_pydict()
                first_entry[&#34;timestamps&#34;] = [start_date_timestamp]
                sensor.write_pyarrow_table(pa.Table.from_pydict(first_entry))
            elif last_before_start is None and first_after_end is not None:
                last_entry = sensor.pyarrow_table().slice(first_after_end, 1).to_pydict()
                last_entry[&#34;timestamps&#34;] = [start_date_timestamp]
                sensor.write_pyarrow_table(pa.Table.from_pydict(last_entry))
            elif last_before_start is not None and first_after_end is not None:
                sensor.write_pyarrow_table(
                    sensor.interpolate(start_date_timestamp, last_before_start, 1,
                                       self._config.copy_edge_points == gpu.DataPointCreationMode.COPY))
        else:
            _arrow = sensor.pyarrow_table().slice(start_index, end_index-start_index)
            # if sensor is audio or location, we want nan&#39;d edge points
            if sensor.type() in [SensorType.LOCATION, SensorType.AUDIO]:
                new_point_mode = gpu.DataPointCreationMode.NAN
            else:
                new_point_mode = self._config.copy_edge_points
            # add in the data points at the edges of the window if there are defined start and/or end times
            slice_start = _arrow[&#34;timestamps&#34;].to_numpy()[0]
            slice_end = _arrow[&#34;timestamps&#34;].to_numpy()[-1]
            if not is_audio:
                end_sample_interval = end_date_timestamp - slice_end
                end_samples_to_add = 1
                start_sample_interval = start_date_timestamp - slice_start
                start_samples_to_add = 1
            else:
                end_sample_interval = dtu.seconds_to_microseconds(sensor.sample_interval_s())
                start_sample_interval = -end_sample_interval
                if self._config.end_datetime:
                    end_samples_to_add = int((dtu.datetime_to_epoch_microseconds_utc(self._config.end_datetime)
                                              - slice_end) / end_sample_interval)
                else:
                    end_samples_to_add = 0
                if self._config.start_datetime:
                    start_samples_to_add = int((slice_start -
                                                dtu.datetime_to_epoch_microseconds_utc(self._config.start_datetime))
                                               / end_sample_interval)
                else:
                    start_samples_to_add = 0
            # add to end
            _arrow = (gpu.add_data_points_to_df(data_table=_arrow, start_index=_arrow.num_rows - 1,
                                                sample_interval_micros=end_sample_interval,
                                                num_samples_to_add=end_samples_to_add,
                                                point_creation_mode=new_point_mode))
            # add to begin
            _arrow = (gpu.add_data_points_to_df(data_table=_arrow, start_index=0,
                                                sample_interval_micros=start_sample_interval,
                                                num_samples_to_add=start_samples_to_add,
                                                point_creation_mode=new_point_mode))
            sensor.sort_by_data_timestamps(_arrow)
    else:
        self._errors.append(f&#34;Data window for {station_id} {sensor.type().name} &#34;
                            f&#34;sensor has no data points!&#34;)</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.remove_station"><code class="name flex">
<span>def <span class="ident">remove_station</span></span>(<span>self, station_id:Â Optional[str]Â =Â None, start_date:Â Optional[float]Â =Â None)</span>
</code></dt>
<dd>
<div class="desc"><p>remove the first station from the DataWindow, or a specific station if given the id and/or start date
if an id is given, the first station with that id will be removed
if a start date is given, the removed station will start at or after the start date
start date is in microseconds since epoch UTC</p>
<p>:param station_id: id of station to remove
:param start_date: start date that is at or before the station to remove</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_station(self, station_id: Optional[str] = None, start_date: Optional[float] = None):
    &#34;&#34;&#34;
    remove the first station from the DataWindow, or a specific station if given the id and/or start date
    if an id is given, the first station with that id will be removed
    if a start date is given, the removed station will start at or after the start date
    start date is in microseconds since epoch UTC

    :param station_id: id of station to remove
    :param start_date: start date that is at or before the station to remove
    &#34;&#34;&#34;
    id_removals = []
    sd_removals = []
    if station_id is None and start_date is None:
        self._stations.pop()
    else:
        if station_id is not None:
            for s in range(len(self._stations)):
                if self._stations[s].id == station_id:
                    id_removals.append(s)
        if start_date is not None:
            for s in range(len(self._stations)):
                if self._stations[s].start_date() &gt;= start_date:
                    sd_removals.append(s)
        if len(id_removals) &gt; 0 and start_date is None:
            self._stations.pop(id_removals.pop())
        elif len(sd_removals) &gt; 0 and station_id is None:
            self._stations.pop(sd_removals.pop())
        elif len(id_removals) &gt; 0 and len(sd_removals) &gt; 0:
            for a in id_removals:
                for b in sd_removals:
                    if a == b:
                        self._stations.pop(a)
                        return
                    if a &lt; b:
                        continue</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self) â€‘>Â pathlib.Path</span>
</code></dt>
<dd>
<div class="desc"><p>save the DataWindow to disk if saving is enabled
if saving is not enabled, adds an error to the DataWindow and returns an empty path.</p>
<p>:return: the path to where the files exist; an empty path means no files were saved</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self) -&gt; Path:
    &#34;&#34;&#34;
    save the DataWindow to disk if saving is enabled
    if saving is not enabled, adds an error to the DataWindow and returns an empty path.

    :return: the path to where the files exist; an empty path means no files were saved
    &#34;&#34;&#34;
    if self._fs_writer.is_save_disk():
        if self._fs_writer.is_use_disk() and self._fs_writer.make_run_me:
            shutil.copyfile(os.path.abspath(inspect.getfile(run_me)),
                            os.path.join(self._fs_writer.save_dir(), &#34;runme.py&#34;))
        if self._fs_writer.file_extension == &#34;parquet&#34;:
            return self._to_json_file()
        elif self._fs_writer.file_extension == &#34;lz4&#34;:
            return self.serialize()
    else:
        self._errors.append(&#34;Saving not enabled.&#34;)
        print(&#34;WARNING: Cannot save data window without knowing extension.&#34;)
        return Path()</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.save_dir"><code class="name flex">
<span>def <span class="ident">save_dir</span></span>(<span>self) â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>:return: directory data is saved to (empty string means saving to memory)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_dir(self) -&gt; str:
    &#34;&#34;&#34;
    :return: directory data is saved to (empty string means saving to memory)
    &#34;&#34;&#34;
    return self._fs_writer.save_dir()</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.sdk_version"><code class="name flex">
<span>def <span class="ident">sdk_version</span></span>(<span>self) â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>:return: sdk version used to create the DataWindow</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sdk_version(self) -&gt; str:
    &#34;&#34;&#34;
    :return: sdk version used to create the DataWindow
    &#34;&#34;&#34;
    return self._sdk_version</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.serialize"><code class="name flex">
<span>def <span class="ident">serialize</span></span>(<span>self, compression_factor:Â intÂ =Â 4) â€‘>Â pathlib.Path</span>
</code></dt>
<dd>
<div class="desc"><p>Serializes and compresses this DataWindow to a file.
Uses the event_name and out_dir to name the file.</p>
<p>:param compression_factor: A value between 1 and 12. Higher values provide better compression, but take
longer. (default=4).
:return: The path to the written file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def serialize(self, compression_factor: int = 4) -&gt; Path:
    &#34;&#34;&#34;
    Serializes and compresses this DataWindow to a file.
    Uses the event_name and out_dir to name the file.

    :param compression_factor: A value between 1 and 12. Higher values provide better compression, but take
    longer. (default=4).
    :return: The path to the written file.
    &#34;&#34;&#34;
    return dw_io.serialize_data_window(self, self.save_dir(), f&#34;{self.event_name}.pkl.lz4&#34;, compression_factor)</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.set_make_runme"><code class="name flex">
<span>def <span class="ident">set_make_runme</span></span>(<span>self, make_runme:Â boolÂ =Â False)</span>
</code></dt>
<dd>
<div class="desc"><p>:param make_runme: if True, DataWindow will create a runme file when saved.
Default False</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_make_runme(self, make_runme: bool = False):
    &#34;&#34;&#34;
    :param make_runme: if True, DataWindow will create a runme file when saved.  Default False
    &#34;&#34;&#34;
    self._fs_writer.make_run_me = make_runme</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.set_out_type"><code class="name flex">
<span>def <span class="ident">set_out_type</span></span>(<span>self, new_out_type:Â str)</span>
</code></dt>
<dd>
<div class="desc"><p>set the output type of the DataWindow.
options are "NONE", "PARQUET" and "LZ4".
invalid values become "NONE"</p>
<p>:param new_out_type: new output type of the DataWindow</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_out_type(self, new_out_type: str):
    &#34;&#34;&#34;
    set the output type of the DataWindow.  options are &#34;NONE&#34;, &#34;PARQUET&#34; and &#34;LZ4&#34;.  invalid values become &#34;NONE&#34;

    :param new_out_type: new output type of the DataWindow
    &#34;&#34;&#34;
    self._fs_writer.set_extension(new_out_type)</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.set_save_dir"><code class="name flex">
<span>def <span class="ident">set_save_dir</span></span>(<span>self, new_save_dir:Â Optional[str]Â =Â '.')</span>
</code></dt>
<dd>
<div class="desc"><p>:param new_save_dir: directory to save data to; default current directory, or "."</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_save_dir(self, new_save_dir: Optional[str] = &#34;.&#34;):
    &#34;&#34;&#34;
    :param new_save_dir: directory to save data to; default current directory, or &#34;.&#34;
    &#34;&#34;&#34;
    self._fs_writer.base_dir = new_save_dir</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.set_sdk_version"><code class="name flex">
<span>def <span class="ident">set_sdk_version</span></span>(<span>self, version:Â str)</span>
</code></dt>
<dd>
<div class="desc"><p>:param version: the sdk version to set</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_sdk_version(self, version: str):
    &#34;&#34;&#34;
    :param version: the sdk version to set
    &#34;&#34;&#34;
    self._sdk_version = version</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.start_date"><code class="name flex">
<span>def <span class="ident">start_date</span></span>(<span>self) â€‘>Â float</span>
</code></dt>
<dd>
<div class="desc"><p>:return: minimum start timestamp of the data or np.nan if no data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def start_date(self) -&gt; float:
    &#34;&#34;&#34;
    :return: minimum start timestamp of the data or np.nan if no data
    &#34;&#34;&#34;
    if len(self._stations) &gt; 0:
        return np.min([s.first_data_timestamp() for s in self._stations])
    return np.nan</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.station_ids"><code class="name flex">
<span>def <span class="ident">station_ids</span></span>(<span>self) â€‘>Â List[str]</span>
</code></dt>
<dd>
<div class="desc"><p>:return: ids of stations in the DataWindow</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def station_ids(self) -&gt; List[str]:
    &#34;&#34;&#34;
    :return: ids of stations in the DataWindow
    &#34;&#34;&#34;
    return [s.id() for s in self._stations]</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.stations"><code class="name flex">
<span>def <span class="ident">stations</span></span>(<span>self) â€‘>Â List[<a title="redvox.common.station.Station" href="station.html#redvox.common.station.Station">Station</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>:return: list of stations in the DataWindow</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stations(self) -&gt; List[Station]:
    &#34;&#34;&#34;
    :return: list of stations in the DataWindow
    &#34;&#34;&#34;
    return self._stations</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.to_json"><code class="name flex">
<span>def <span class="ident">to_json</span></span>(<span>self) â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>:return: The DataWindow metadata into a JSON string.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_json(self) -&gt; str:
    &#34;&#34;&#34;
    :return: The DataWindow metadata into a JSON string.
    &#34;&#34;&#34;
    return dw_io.data_window_as_json(self)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="redvox.common.data_window.DataWindowConfig"><code class="flex name class">
<span>class <span class="ident">DataWindowConfig</span></span>
<span>(</span><span>input_dir:Â str, structured_layout:Â boolÂ =Â True, start_datetime:Â Optional[datetime.datetime]Â =Â None, end_datetime:Â Optional[datetime.datetime]Â =Â None, start_buffer_td:Â datetime.timedeltaÂ =Â datetime.timedelta(seconds=120), end_buffer_td:Â datetime.timedeltaÂ =Â datetime.timedelta(seconds=120), drop_time_s:Â floatÂ =Â 0.2, station_ids:Â Optional[Iterable[str]]Â =Â None, extensions:Â Optional[Set[str]]Â =Â None, api_versions:Â Optional[Set[<a title="redvox.common.versioning.ApiVersion" href="versioning.html#redvox.common.versioning.ApiVersion">ApiVersion</a>]]Â =Â None, apply_correction:Â boolÂ =Â True, use_model_correction:Â boolÂ =Â True, copy_edge_points:Â <a title="redvox.common.gap_and_pad_utils.DataPointCreationMode" href="gap_and_pad_utils.html#redvox.common.gap_and_pad_utils.DataPointCreationMode">DataPointCreationMode</a>Â =Â DataPointCreationMode.COPY)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="properties">Properties</h2>
<p>input_dir: str, the directory that contains all the data.
REQUIRED</p>
<p>structured_layout: bool, if True, the input_dir contains specially named and organized
directories of data.
Default True</p>
<p>start_datetime: optional datetime, start datetime of the window.
If None, uses the first timestamp of the filtered data.
Default None</p>
<p>end_datetime: optional datetime, non-inclusive end datetime of the window.
If None, uses the last timestamp of the filtered data + 1.
Default None</p>
<p>start_buffer_td: timedelta, the amount of time to include before the start_datetime when filtering data.
Negative values are converted to 0.
Default DEFAULT_START_BUFFER_TD (2 minutes)</p>
<p>end_buffer_td: timedelta, the amount of time to include after the end_datetime when filtering data.
Negative values are converted to 0.
Default DEFAULT_END_BUFFER_TD (2 minutes)</p>
<p>drop_time_s: float, the minimum amount of seconds between data files that would indicate a gap.
Negative values are converted to default value.
Default DATA_DROP_DURATION_S (0.2 seconds)</p>
<p>station_ids: optional set of strings, representing the station ids to filter on.
If empty or None, get any ids found in the input directory.
Default None</p>
<p>extensions: optional set of strings, representing file extensions to filter on.
If None, gets as much data as it can in the input directory.
Default None</p>
<p>api_versions: optional set of ApiVersions, representing api versions to filter on.
If None, get as much data as it can in the input directory.
Default None</p>
<p>apply_correction: bool, if True, update the timestamps in the data based on best station offset.
Default True</p>
<p>copy_edge_points: enumeration of DataPointCreationMode.
Determines how new points are created.
Valid values are NAN, COPY, and INTERPOLATE.
Default COPY</p>
<p>use_model_correction: bool, if True, use the offset model's correction functions, otherwise use the best
offset.
Default True</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DataWindowConfig:
    &#34;&#34;&#34;
    Properties:
        input_dir: str, the directory that contains all the data.  REQUIRED

        structured_layout: bool, if True, the input_dir contains specially named and organized
        directories of data.  Default True

        start_datetime: optional datetime, start datetime of the window.
        If None, uses the first timestamp of the filtered data.  Default None

        end_datetime: optional datetime, non-inclusive end datetime of the window.
        If None, uses the last timestamp of the filtered data + 1.  Default None

        start_buffer_td: timedelta, the amount of time to include before the start_datetime when filtering data.
        Negative values are converted to 0.  Default DEFAULT_START_BUFFER_TD (2 minutes)

        end_buffer_td: timedelta, the amount of time to include after the end_datetime when filtering data.
        Negative values are converted to 0.  Default DEFAULT_END_BUFFER_TD (2 minutes)

        drop_time_s: float, the minimum amount of seconds between data files that would indicate a gap.
        Negative values are converted to default value.  Default DATA_DROP_DURATION_S (0.2 seconds)

        station_ids: optional set of strings, representing the station ids to filter on.
        If empty or None, get any ids found in the input directory.  Default None

        extensions: optional set of strings, representing file extensions to filter on.
        If None, gets as much data as it can in the input directory.  Default None

        api_versions: optional set of ApiVersions, representing api versions to filter on.
        If None, get as much data as it can in the input directory.  Default None

        apply_correction: bool, if True, update the timestamps in the data based on best station offset.  Default True

        copy_edge_points: enumeration of DataPointCreationMode.  Determines how new points are created.
        Valid values are NAN, COPY, and INTERPOLATE.  Default COPY

        use_model_correction: bool, if True, use the offset model&#39;s correction functions, otherwise use the best
        offset.  Default True
    &#34;&#34;&#34;
    def __init__(
            self,
            input_dir: str,
            structured_layout: bool = True,
            start_datetime: Optional[dtu.datetime] = None,
            end_datetime: Optional[dtu.datetime] = None,
            start_buffer_td: timedelta = DEFAULT_START_BUFFER_TD,
            end_buffer_td: timedelta = DEFAULT_END_BUFFER_TD,
            drop_time_s: float = DATA_DROP_DURATION_S,
            station_ids: Optional[Iterable[str]] = None,
            extensions: Optional[Set[str]] = None,
            api_versions: Optional[Set[io.ApiVersion]] = None,
            apply_correction: bool = True,
            use_model_correction: bool = True,
            copy_edge_points: gpu.DataPointCreationMode = gpu.DataPointCreationMode.COPY,
    ):
        self.input_dir: str = input_dir
        self.structured_layout: bool = structured_layout
        self.start_datetime: Optional[dtu.datetime] = start_datetime
        self.end_datetime: Optional[dtu.datetime] = end_datetime
        self.start_buffer_td: timedelta = start_buffer_td if start_buffer_td &gt; timedelta(seconds=0) \
            else timedelta(seconds=0)
        self.end_buffer_td: timedelta = end_buffer_td if end_buffer_td &gt; timedelta(seconds=0) \
            else timedelta(seconds=0)
        self.drop_time_s: float = drop_time_s if drop_time_s &gt; 0 else DATA_DROP_DURATION_S
        self.station_ids: Optional[Set[str]] = set(station_ids) if station_ids else None
        self.extensions: Optional[Set[str]] = extensions
        self.api_versions: Optional[Set[io.ApiVersion]] = api_versions
        self.apply_correction: bool = apply_correction
        self.use_model_correction = use_model_correction
        self.copy_edge_points = copy_edge_points

    def __repr__(self):
        return f&#34;input_dir: {self.input_dir}, &#34; \
               f&#34;structured_layout: {self.structured_layout}, &#34; \
               f&#34;start_datetime: {self.start_datetime.__repr__()}, &#34; \
               f&#34;end_datetime: {self.end_datetime.__repr__()}, &#34; \
               f&#34;start_buffer_td: {self.start_buffer_td.__repr__()}, &#34; \
               f&#34;end_buffer_td: {self.end_buffer_td.__repr__()}, &#34; \
               f&#34;drop_time_s: {self.drop_time_s}, &#34; \
               f&#34;station_ids: {list(self.station_ids) if self.station_ids else []}, &#34; \
               f&#34;extensions: {list(self.extensions) if self.extensions else []}, &#34; \
               f&#34;api_versions: {[a_v.value for a_v in self.api_versions] if self.api_versions else []}, &#34; \
               f&#34;apply_correction: {self.apply_correction}, &#34; \
               f&#34;use_model_correction: {self.use_model_correction}, &#34; \
               f&#34;copy_edge_points: {self.copy_edge_points.value}&#34;

    def __str__(self):
        return f&#34;input_dir: {self.input_dir}, &#34; \
               f&#34;structured_layout: {self.structured_layout}, &#34; \
               f&#34;start_datetime: &#34; \
               f&#34;{self.start_datetime.strftime(&#39;%Y-%m-%dT%H:%M:%S.%fZ&#39;) if self.start_datetime else None}, &#34; \
               f&#34;end_datetime: {self.end_datetime.strftime(&#39;%Y-%m-%dT%H:%M:%S.%fZ&#39;) if self.end_datetime else None}, &#34; \
               f&#34;start_buffer_td (in s): {self.start_buffer_td.total_seconds()}, &#34; \
               f&#34;end_buffer_td (in s): {self.end_buffer_td.total_seconds()}, &#34; \
               f&#34;drop_time_s: {self.drop_time_s}, &#34; \
               f&#34;station_ids: {list(self.station_ids) if self.station_ids else []}, &#34; \
               f&#34;extensions: {list(self.extensions) if self.extensions else []}, &#34; \
               f&#34;api_versions: {[a_v.value for a_v in self.api_versions] if self.api_versions else []}, &#34; \
               f&#34;apply_correction: {self.apply_correction}, &#34; \
               f&#34;use_model_correction: {self.use_model_correction}, &#34; \
               f&#34;copy_edge_points: {self.copy_edge_points.name}&#34;

    def as_dict(self) -&gt; Dict:
        return {&#34;input_dir&#34;: self.input_dir,
                &#34;structured_layout&#34;: self.structured_layout,
                &#34;start_datetime&#34;: us_dt(self.start_datetime),
                &#34;end_datetime&#34;: us_dt(self.end_datetime),
                &#34;start_buffer_td&#34;: self.start_buffer_td.total_seconds(),
                &#34;end_buffer_td&#34;: self.end_buffer_td.total_seconds(),
                &#34;drop_time_s&#34;: self.drop_time_s,
                &#34;station_ids&#34;: list(self.station_ids) if self.station_ids else [],
                &#34;extensions&#34;: list(self.extensions) if self.extensions else [],
                &#34;api_versions&#34;: [a_v.value for a_v in self.api_versions] if self.api_versions else [],
                &#34;apply_correction&#34;: self.apply_correction,
                &#34;use_model_correction&#34;: self.use_model_correction,
                &#34;copy_edge_points&#34;: self.copy_edge_points.value
                }

    @staticmethod
    def from_dict(data_dict: Dict) -&gt; &#34;DataWindowConfig&#34;:
        return DataWindowConfig(data_dict[&#34;input_dir&#34;], data_dict[&#34;structured_layout&#34;],
                                dtu.datetime_from_epoch_microseconds_utc(data_dict[&#34;start_datetime&#34;]),
                                dtu.datetime_from_epoch_microseconds_utc(data_dict[&#34;end_datetime&#34;]),
                                timedelta(seconds=data_dict[&#34;start_buffer_td&#34;]),
                                timedelta(seconds=data_dict[&#34;end_buffer_td&#34;]),
                                data_dict[&#34;drop_time_s&#34;], data_dict[&#34;station_ids&#34;], set(data_dict[&#34;extensions&#34;]),
                                set([io.ApiVersion.from_str(v) for v in data_dict[&#34;api_versions&#34;]]),
                                data_dict[&#34;apply_correction&#34;], data_dict[&#34;use_model_correction&#34;],
                                gpu.DataPointCreationMode(data_dict[&#34;copy_edge_points&#34;])
                                )</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="redvox.common.data_window.DataWindowConfig.from_dict"><code class="name flex">
<span>def <span class="ident">from_dict</span></span>(<span>data_dict:Â Dict) â€‘>Â <a title="redvox.common.data_window.DataWindowConfig" href="#redvox.common.data_window.DataWindowConfig">DataWindowConfig</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_dict(data_dict: Dict) -&gt; &#34;DataWindowConfig&#34;:
    return DataWindowConfig(data_dict[&#34;input_dir&#34;], data_dict[&#34;structured_layout&#34;],
                            dtu.datetime_from_epoch_microseconds_utc(data_dict[&#34;start_datetime&#34;]),
                            dtu.datetime_from_epoch_microseconds_utc(data_dict[&#34;end_datetime&#34;]),
                            timedelta(seconds=data_dict[&#34;start_buffer_td&#34;]),
                            timedelta(seconds=data_dict[&#34;end_buffer_td&#34;]),
                            data_dict[&#34;drop_time_s&#34;], data_dict[&#34;station_ids&#34;], set(data_dict[&#34;extensions&#34;]),
                            set([io.ApiVersion.from_str(v) for v in data_dict[&#34;api_versions&#34;]]),
                            data_dict[&#34;apply_correction&#34;], data_dict[&#34;use_model_correction&#34;],
                            gpu.DataPointCreationMode(data_dict[&#34;copy_edge_points&#34;])
                            )</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="redvox.common.data_window.DataWindowConfig.as_dict"><code class="name flex">
<span>def <span class="ident">as_dict</span></span>(<span>self) â€‘>Â Dict</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def as_dict(self) -&gt; Dict:
    return {&#34;input_dir&#34;: self.input_dir,
            &#34;structured_layout&#34;: self.structured_layout,
            &#34;start_datetime&#34;: us_dt(self.start_datetime),
            &#34;end_datetime&#34;: us_dt(self.end_datetime),
            &#34;start_buffer_td&#34;: self.start_buffer_td.total_seconds(),
            &#34;end_buffer_td&#34;: self.end_buffer_td.total_seconds(),
            &#34;drop_time_s&#34;: self.drop_time_s,
            &#34;station_ids&#34;: list(self.station_ids) if self.station_ids else [],
            &#34;extensions&#34;: list(self.extensions) if self.extensions else [],
            &#34;api_versions&#34;: [a_v.value for a_v in self.api_versions] if self.api_versions else [],
            &#34;apply_correction&#34;: self.apply_correction,
            &#34;use_model_correction&#34;: self.use_model_correction,
            &#34;copy_edge_points&#34;: self.copy_edge_points.value
            }</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="redvox.common.data_window.EventOrigin"><code class="flex name class">
<span>class <span class="ident">EventOrigin</span></span>
<span>(</span><span>provider:Â strÂ =Â 'UNKNOWN', lat:Â floatÂ =Â nan, lat_std:Â floatÂ =Â nan, lon:Â floatÂ =Â nan, lon_std:Â floatÂ =Â nan, alt:Â floatÂ =Â nan, alt_std:Â floatÂ =Â nan, event_radius_m:Â floatÂ =Â 0.0)</span>
</code></dt>
<dd>
<div class="desc"><p>The origin event's latitude, longitude, altitude and their standard deviations, the device used to measure
the location data and the radius of the event</p>
<h2 id="properties">Properties</h2>
<p>provider: str, source of the location data (i.e. "GPS" or "NETWORK"), default "UNKNOWN"</p>
<p>latitude: float, best estimate of latitude in degrees, default np.nan</p>
<p>latitude_std: float, standard deviation of best estimate of latitude, default np.nan</p>
<p>longitude: float, best estimate of longitude in degrees, default np.nan</p>
<p>longitude_std: float, standard deviation of best estimate of longitude, default np.nan</p>
<p>altitude: float, best estimate of altitude in meters, default np.nan</p>
<p>altitude_std: float, standard deviation of best estimate of altitude, default np.nan</p>
<p>event_radius_m: float, radius of event in meters, default 0.0</p>
<p>:param provider: name of device that provided the information
:param lat: latitude in +/- degrees
:param lat_std: standard deviation of latitude
:param lon: longitude in +/- degrees
:param lon_std: standard deviation of longitude
:param alt: altitude in meters
:param alt_std: standard deviation of altitude
:param event_radius_m: radius of event in meters</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EventOrigin:
    &#34;&#34;&#34;
    The origin event&#39;s latitude, longitude, altitude and their standard deviations, the device used to measure
    the location data and the radius of the event

    Properties:
        provider: str, source of the location data (i.e. &#34;GPS&#34; or &#34;NETWORK&#34;), default &#34;UNKNOWN&#34;

        latitude: float, best estimate of latitude in degrees, default np.nan

        latitude_std: float, standard deviation of best estimate of latitude, default np.nan

        longitude: float, best estimate of longitude in degrees, default np.nan

        longitude_std: float, standard deviation of best estimate of longitude, default np.nan

        altitude: float, best estimate of altitude in meters, default np.nan

        altitude_std: float, standard deviation of best estimate of altitude, default np.nan

        event_radius_m: float, radius of event in meters, default 0.0
    &#34;&#34;&#34;
    def __init__(self,
                 provider: str = &#34;UNKNOWN&#34;,
                 lat: float = np.nan,
                 lat_std: float = np.nan,
                 lon: float = np.nan,
                 lon_std: float = np.nan,
                 alt: float = np.nan,
                 alt_std: float = np.nan,
                 event_radius_m: float = 0.0):
        &#34;&#34;&#34;
        :param provider: name of device that provided the information
        :param lat: latitude in +/- degrees
        :param lat_std: standard deviation of latitude
        :param lon: longitude in +/- degrees
        :param lon_std: standard deviation of longitude
        :param alt: altitude in meters
        :param alt_std: standard deviation of altitude
        :param event_radius_m: radius of event in meters
        &#34;&#34;&#34;
        self.provider = provider
        self.latitude = lat
        self.longitude = lon
        self.altitude = alt
        self.latitude_std = lat_std
        self.longitude_std = lon_std
        self.altitude_std = alt_std
        self.event_radius_m = event_radius_m

    def __repr__(self):
        return str(self.as_dict())

    def __str__(self):
        return str(self.as_dict())

    def as_dict(self) -&gt; Dict:
        &#34;&#34;&#34;
        :return: self as dict
        &#34;&#34;&#34;
        return {
            &#34;provider&#34;: self.provider,
            &#34;latitude&#34;: self.latitude,
            &#34;latitude_std&#34;: self.latitude_std,
            &#34;longitude&#34;: self.longitude,
            &#34;longitude_std&#34;: self.longitude_std,
            &#34;altitude&#34;: self.altitude,
            &#34;altitude_std&#34;: self.altitude_std,
            &#34;event_radius_m&#34;: self.event_radius_m
        }

    @staticmethod
    def from_dict(data_dict: Dict) -&gt; &#34;EventOrigin&#34;:
        return EventOrigin(data_dict[&#34;provider&#34;], data_dict[&#34;latitude&#34;], data_dict[&#34;latitude_std&#34;],
                           data_dict[&#34;longitude&#34;], data_dict[&#34;longitude_std&#34;], data_dict[&#34;altitude&#34;],
                           data_dict[&#34;altitude_std&#34;], data_dict[&#34;event_radius_m&#34;])</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="redvox.common.data_window.EventOrigin.from_dict"><code class="name flex">
<span>def <span class="ident">from_dict</span></span>(<span>data_dict:Â Dict) â€‘>Â <a title="redvox.common.data_window.EventOrigin" href="#redvox.common.data_window.EventOrigin">EventOrigin</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_dict(data_dict: Dict) -&gt; &#34;EventOrigin&#34;:
    return EventOrigin(data_dict[&#34;provider&#34;], data_dict[&#34;latitude&#34;], data_dict[&#34;latitude_std&#34;],
                       data_dict[&#34;longitude&#34;], data_dict[&#34;longitude_std&#34;], data_dict[&#34;altitude&#34;],
                       data_dict[&#34;altitude_std&#34;], data_dict[&#34;event_radius_m&#34;])</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="redvox.common.data_window.EventOrigin.as_dict"><code class="name flex">
<span>def <span class="ident">as_dict</span></span>(<span>self) â€‘>Â Dict</span>
</code></dt>
<dd>
<div class="desc"><p>:return: self as dict</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def as_dict(self) -&gt; Dict:
    &#34;&#34;&#34;
    :return: self as dict
    &#34;&#34;&#34;
    return {
        &#34;provider&#34;: self.provider,
        &#34;latitude&#34;: self.latitude,
        &#34;latitude_std&#34;: self.latitude_std,
        &#34;longitude&#34;: self.longitude,
        &#34;longitude_std&#34;: self.longitude_std,
        &#34;altitude&#34;: self.altitude,
        &#34;altitude_std&#34;: self.altitude_std,
        &#34;event_radius_m&#34;: self.event_radius_m
    }</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="redvox.common" href="index.html">redvox.common</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="redvox.common.data_window.DataWindow" href="#redvox.common.data_window.DataWindow">DataWindow</a></code></h4>
<ul class="">
<li><code><a title="redvox.common.data_window.DataWindow.add_station" href="#redvox.common.data_window.DataWindow.add_station">add_station</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.as_dict" href="#redvox.common.data_window.DataWindow.as_dict">as_dict</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.config" href="#redvox.common.data_window.DataWindow.config">config</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.create_data_window" href="#redvox.common.data_window.DataWindow.create_data_window">create_data_window</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.create_window_in_sensors" href="#redvox.common.data_window.DataWindow.create_window_in_sensors">create_window_in_sensors</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.deserialize" href="#redvox.common.data_window.DataWindow.deserialize">deserialize</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.end_date" href="#redvox.common.data_window.DataWindow.end_date">end_date</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.first_station" href="#redvox.common.data_window.DataWindow.first_station">first_station</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.from_config" href="#redvox.common.data_window.DataWindow.from_config">from_config</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.from_config_file" href="#redvox.common.data_window.DataWindow.from_config_file">from_config_file</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.from_json" href="#redvox.common.data_window.DataWindow.from_json">from_json</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.from_json_dict" href="#redvox.common.data_window.DataWindow.from_json_dict">from_json_dict</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.fs_writer" href="#redvox.common.data_window.DataWindow.fs_writer">fs_writer</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.get_station" href="#redvox.common.data_window.DataWindow.get_station">get_station</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.is_make_runme" href="#redvox.common.data_window.DataWindow.is_make_runme">is_make_runme</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.load" href="#redvox.common.data_window.DataWindow.load">load</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.out_type" href="#redvox.common.data_window.DataWindow.out_type">out_type</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.pretty" href="#redvox.common.data_window.DataWindow.pretty">pretty</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.print_errors" href="#redvox.common.data_window.DataWindow.print_errors">print_errors</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.process_sensor" href="#redvox.common.data_window.DataWindow.process_sensor">process_sensor</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.remove_station" href="#redvox.common.data_window.DataWindow.remove_station">remove_station</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.save" href="#redvox.common.data_window.DataWindow.save">save</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.save_dir" href="#redvox.common.data_window.DataWindow.save_dir">save_dir</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.sdk_version" href="#redvox.common.data_window.DataWindow.sdk_version">sdk_version</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.serialize" href="#redvox.common.data_window.DataWindow.serialize">serialize</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.set_make_runme" href="#redvox.common.data_window.DataWindow.set_make_runme">set_make_runme</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.set_out_type" href="#redvox.common.data_window.DataWindow.set_out_type">set_out_type</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.set_save_dir" href="#redvox.common.data_window.DataWindow.set_save_dir">set_save_dir</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.set_sdk_version" href="#redvox.common.data_window.DataWindow.set_sdk_version">set_sdk_version</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.start_date" href="#redvox.common.data_window.DataWindow.start_date">start_date</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.station_ids" href="#redvox.common.data_window.DataWindow.station_ids">station_ids</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.stations" href="#redvox.common.data_window.DataWindow.stations">stations</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.to_json" href="#redvox.common.data_window.DataWindow.to_json">to_json</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="redvox.common.data_window.DataWindowConfig" href="#redvox.common.data_window.DataWindowConfig">DataWindowConfig</a></code></h4>
<ul class="">
<li><code><a title="redvox.common.data_window.DataWindowConfig.as_dict" href="#redvox.common.data_window.DataWindowConfig.as_dict">as_dict</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindowConfig.from_dict" href="#redvox.common.data_window.DataWindowConfig.from_dict">from_dict</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="redvox.common.data_window.EventOrigin" href="#redvox.common.data_window.EventOrigin">EventOrigin</a></code></h4>
<ul class="">
<li><code><a title="redvox.common.data_window.EventOrigin.as_dict" href="#redvox.common.data_window.EventOrigin.as_dict">as_dict</a></code></li>
<li><code><a title="redvox.common.data_window.EventOrigin.from_dict" href="#redvox.common.data_window.EventOrigin.from_dict">from_dict</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>